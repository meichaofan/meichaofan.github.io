<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[go range]]></title>
    <url>%2F2019%2F07%2F06%2Fgo-range%2F</url>
    <content type="text"><![CDATA[1.前言range是Golang提供的一种迭代遍历手段，可操作的类型有数组、切片、Map和channel等，实际使用频率非常高。 探索range的实现机制是很有意思的事情，这可能会改变你使用range的习惯。 2.热身2.1 题目一：切片遍历下面函数通过遍历切片，打印切片的下标和元素值，请问性能上有没有可优化的空间 12345func RangeSlice(slice []int)&#123; for index,value := range slice &#123; _,_ := index,value &#125;&#125; 程序解释： 函数中使用for-range对切片进行遍历，获取切片的下标和元素值，这里忽略函数的实际意义。 参考答案： 遍历过程中，每次迭代会对index和value进行赋值，如果数据量大或者value类型为string时，对value的赋值操作可能是多余的，可以在for-range中忽略value值，使用slice[index]引用value值。 2.2 题目二：Map遍历下面函数通过遍历Map，打印Map的key和value，请问性能上有没有可以优化的空间 12345func RangeMap(myMap map[int]string) &#123; for key, _ := range myMap &#123; _, _ = key, myMap[key] &#125;&#125; 程序解释： 函数中使用for-range对map进行遍历，获取map的key值，并根据key值获取value值，这里忽略函数的实际意义。 参考答案： 函数中for-range语句中值获取key值，然后根据key值获取value值，虽然看似减少了一次赋值，但通过key值查找value值的性能可能高于赋值消耗。能否优化取决于map所存储数据结构特征、结合实际情况进行判断。 2.3 题目三：动态遍历请问如下程序是否能正常结束？ 123456func main() &#123; v := []int&#123;1, 2, 3&#125; for i:= range v &#123; v = append(v, i) &#125;&#125; 程序解释： main()函数中定义一个切片v，通过range遍历v，遍历过程中不断向v中添加新的元素。 参考答案： 能够正常结束。循环内改变切片的长度，不影响循环次数，循环次效在循环开始前就已经确定了。 3. 实现原理对于for-range语句的实现，可以从编译器源码中找到答案。 编译器源码 gofrontend/go/statements.cc/For_range_statement::do_lower() 方法中有如下注释。 1234567// Arrange to do a loop appropriate for the type. We will produce// for INIT ; COND ; POST &#123;// ITER_INIT// INDEX = INDEX_TEMP// VALUE = VALUE_TEMP // If there is a value// original statements// &#125; 可见range实际上是一个C风格的循环结构。range支持数组、数组指针、切片、map和channel类型，对于不同类型有些细节上的差异。 3.1 range for slice下面的注释解释了遍历slice的过程 123456789// The loop we generate:// for_temp := range// len_temp := len(for_temp)// for index_temp = 0; index_temp &lt; len_temp; index_temp++ &#123;// value_temp = for_temp[index_temp]// index = index_temp// value = value_temp// original body// &#125; 遍历slice前会先获以slice的长度len_temp作为循环次数，循环体中，每次循环会先获取元素值，如果for-range中接收index和value的话，则会对index和value进行一次赋值。 由于循环开始前循环次数就已经确定了，所以循环过程中新添加的元素是没办法遍历到的。 另外，数组与数组指针的遍历过程与slice基本一致，不再赘述。 3.2 range for map下面的注释解释了遍历map的过程： 123456789// The loop we generate:// var hiter map_iteration_struct// for mapiterinit(type, range, &amp;hiter); hiter.key != nil; mapiternext(&amp;hiter) &#123;// index_temp = *hiter.key// value_temp = *hiter.val// index = index_temp// value = value_temp// original body// &#125; 遍历map时没有指定循环次数，循环体与遍历slice类似。由于map底层实现与slice不同，map底层使用hash表实现，插入数据位置是随机的，所以遍历过程中新插入的数据不能保证遍历到。 3.3 range for channel遍历channel是最特殊的，这是由channel的实现机制决定的： 123456789// The loop we generate:// for &#123;// index_temp, ok_temp = &lt;-range// if !ok_temp &#123;// break// &#125;// index = index_temp// original body// &#125; channel遍历是依次从channel中读取数据,读取前是不知道里面有多少个元素的。如果channel中没有元素，则会阻塞等待，如果channel已被关闭，则会解除阻塞并退出循环。 注 上述注释中index_temp实际上描述是有误的，应该为value_temp，因为index对于channel是没有意义的。 使用for-range遍历channel时只能获取一个返回值。 4.编程Tips 遍历过程中可以视情况放弃接收index或value，可以在一定程度上提升性能 遍历channel时，避免channel没有数据，可能会阻塞 尽量避免遍历过程中修改原数据 5.总结 for-range的实现实际上是C风格的for循环 使用index、value接收range返回值会发生一次数据拷贝。]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go select]]></title>
    <url>%2F2019%2F07%2F06%2Fgo-select%2F</url>
    <content type="text"><![CDATA[1. 前言select是Golang在语言层面提供的多路IO复用的机制，其可以检测多个channel是否ready（即是否可读或可写），使用起来非常方便。 本章试图根据源码总结其实现原理，从而发现一些使用误区或解释一些不太常见的现象。 2. 热身环节2.1 题目1下面的程序输出是什么？ 1234567891011121314151617181920212223242526272829303132package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() &#123; chan1 := make(chan int) chan2 := make(chan int) go func() &#123; chan1 &lt;- 1 time.Sleep(5 * time.Second) &#125;() go func() &#123; chan2 &lt;- 1 time.Sleep(5 * time.Second) &#125;() select &#123; case &lt;-chan1: fmt.Println(&quot;chan1 ready.&quot;) case &lt;-chan2: fmt.Println(&quot;chan2 ready.&quot;) default: fmt.Println(&quot;default&quot;) &#125; fmt.Println(&quot;main exit.&quot;)&#125; 程序中声明两个channel，分别为chan1和chan2，依次启动两个协程，分别向两个channel中写入一个数据就进入睡眠。select语句两个case分别检测chan1和chan2是否可读，如果都不可读则执行default语句。 参考答案： select中各个case执行顺序是随机的，如果某个case中的channel已经ready，则执行相应的语句并退出select流程，如果所有case中的channel都未ready，则执行default中语句然后退出select流程。另外，由于启动的协程和select语句并不能保证执行顺序，所以也有可能select执行时协程还未向channel中写入数据，所以select直接执行default语句并退出，所以，以下三种输出都有可能： 可能的输出一： 12chan1 ready.main exit. 可能的输出二： 12chan2 readymain exit. 可能的输出三： 12defaultmain exit. 2.2 题目2下面的程序执行到select时会发生什么？ 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() &#123; chan1 := make(chan int) chan2 := make(chan int) writeFlag := false go func() &#123; for &#123; if writeFlag &#123; chan1 &lt;- 1 &#125; time.Sleep(time.Second) &#125; &#125;() go func() &#123; for &#123; if writeFlag &#123; chan2 &lt;- 1 &#125; time.Sleep(time.Second) &#125; &#125;() select &#123; case &lt;-chan1: fmt.Println(&quot;chan1 ready.&quot;) case &lt;-chan2: fmt.Println(&quot;chan2 ready.&quot;) &#125; fmt.Println(&quot;main exit.&quot;)&#125; 程序中声明两个channel，分别为chan1和chan2，依次启动两个协程，协程会判断一个bool类型的变量，writeFlag来决定是否要向channel中写入数据，由于writeFlag永远是false，所以实际上协程什么也没做。select语句两个case分别检测chan1和chan2是否可读，这个select语句不包含default语句。 参考答案： select会按照随机的顺序检测各case语句中cahnnel是否ready，如果某个case中的channel已经ready则执行相应的case语句然后退出select流程，如果所有的channel都未ready且没有default的话，则会阻塞等待各个channel。所以上述程序会一直阻塞。 2.3 题目3下面程序有什么问题？ 123456789101112131415161718192021222324252627package mainimport ( &quot;fmt&quot;)func main() &#123; chan1 := make(chan int) chan2 := make(chan int) go func() &#123; close(chan1) &#125;() go func() &#123; close(chan2) &#125;() select &#123; case &lt;-chan1: fmt.Println(&quot;chan1 ready.&quot;) case &lt;-chan2: fmt.Println(&quot;chan2 ready.&quot;) &#125; fmt.Println(&quot;main exit.&quot;)&#125; 程序中声明两个channel，分别为chan1和chan2，依次启动两个协程，协程分别关闭两个channel。select语句两个case分别检测chan1和chan2是否可读，这个select语句不包含default语句。 参考答案： select会按照随机的顺序检测各case语句中channel是否ready，考虑到已关闭的channel也是可读的，所以上述程序中select不会阻塞，具体执行哪个case语句具是随机的。 2.4 题目4下面程序会发生什么？ 12345package mainfunc main() &#123; select &#123;&#125;&#125; 上面程序中只有一个空的select语句。 参考答案： 对于空的select语句，程序会阻塞，准确的说是当前协程会被阻塞，同时Golang自带死锁检测机制，当发现当前协程再也没有机会被唤醒时，则会panic。所以上述程序会panic。 3.实现原理Golang实现了select时，定义了一个数据结构表示每个case语句（含default，default实际上是一种特殊的case），select执行过程类比成一个函数，函数输入case数组，输出选中的case，然后程序流转到选中的case块。 3.1 case数据结构源码包src/runtime/select.go:scase定义了表示case语句的数据结构 12345type scase struct &#123; c *hchan // chan kind uint16 elem unsafe.Pointer // data element&#125; scase.c 为当前case语句所操作的channel指针，这也说明了一个case语句只能操作一个channel。scase.kind表示该case的类型，分为读channel、写channel和default，三种类型分别由常量定义： caseRecv：case语句中尝试读取scase.c中的数据； caseSend：case语句中尝试向scase.c中写入数据 caseDefault：default语句 scase.elem 表示缓冲区地址，根据scase.kind的不同，有不同用途： scase.kind == caseRecv：scase.elem表示读出channel的数据存放地址； scase.kind == caseSend：scase.elem表示将要写入channel的数据存放地址； 3.2 select实现逻辑源码包src/runtime/select.go:selectgo()定义了select选择case的函数： 1func selectgo(cas0 *scase,order0 *uint16,ncases int)(int,bool) 函数参数： cas为scase数组的首地址，selectgo()就是从这些scase中找出一个返回。 order0为一个两倍cas0数组长度的buffer，保存scase随机序列pollorder和scase中channel地址序列lockorder pollorder：每次selectgo执行都会把scase序列打乱，以达到随机检测case的目的。 lockorder：所有case语句中channel序列，以达到去重防止对channel加锁时重复加锁的目的 ncase表示scase数据的长度 函数返回值： 1.int：选中case的编号，这个case编号和代码一致 2.bool：是否成功从channel中读取了数据，如果选中的case是从channel中读数据，则该返回值表示是否读取成功。 selectgo实现的伪代码如下： 12345678910111213func selectgo(cas0 *scase,order *uint16,ncase int) (int,bool)&#123; //1.锁定scase语句中所有的channel //2.按照随机顺序检测scase中的channel是否ready // 2.1 如果case可读，则读取channel中数据，解锁所有的channel,然后返回(case index,true) // 2.2 如果case可写，则将数据写入channel，解锁所有的channel，然后返回(case index,false) // 2.3 所有case都未ready,则解锁所有的channel，然后返回(default index,false) //3.所有case都未ready，且没有default语句 // 3.1将当前协程加入到所有channel的等待队列 // 3.2当前协程转入阻塞，等待被唤醒 //4.唤醒后返回channel对应case index // 4.1 如果是读操作，解锁所有的channel，然后返回(case index,true) // 4.2 如果是写操作，解锁所有的channel，然后返回(case index,false)&#125; 特别说明： 对于读channel的case来说，如case elem,ok := &lt;- chan1：，如果channel有可能被其它协程关闭的情况下，一定要检测是否读取成功，因为close的channel也有可能返回，此时ok==false。 4.总结 select语句中除default外，每个case操作一个channel，要么读要么写 select语句中除default外，各case执行顺序是随机的 select语句中如果没有default语句，则会阻塞等待任一case select语句中读操作要判断是否成功读取，关闭的channel也可以读取。]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go defer]]></title>
    <url>%2F2019%2F07%2F06%2Fgo-defer%2F</url>
    <content type="text"><![CDATA[1.前言defer语句用于延迟函数的调用，每次defer都会把一个函数压入栈中，函数返回前，再把延迟函数取出并执行。 为了方便描述，我们把创建defer的函数称为主函数，defer语句后面的函数称为延迟函数。 延迟函数可能有输入参数，这些参数可能来源于定义defer的函数，延迟函数也可能引用主函数用于返回的变量，也就是说延迟函数可能会影响主函数的一些行为，这些场景下，如果不了解defer的规则很容易出错。 其实官方说明的defer的三个原则很清楚，本节试图汇总defer的使用场景并做简单说明。 2.热身2.1 题目一下面函数输出结果是什么？ 12345678func deferFuncParameter() &#123; var aInt = 1 defer fmt.Println(aInt) aInt = 2 return&#125; 题目说明： 函数deferFuncParameter()定义一个整型变量并初始化为1，然后使用defer语句打印出变量值，最后修改变量值为2. 参考答案： 输出1。延迟函数fmt.Println(aInt)的参数在defer语句出现时就已经确定了，所以无论后面如何修改aInt变量都不会影响延迟函数。 2.2 题目二下面程序输出什么？ 12345678910111213141516171819202122package mainimport &quot;fmt&quot;func printArray(array *[3]int) &#123; for i := range array &#123; fmt.Println(array[i]) &#125;&#125;func deferFuncParameter() &#123; var aArray = [3]int&#123;1, 2, 3&#125; defer printArray(&amp;aArray) aArray[0] = 10 return&#125;func main() &#123; deferFuncParameter()&#125; 函数说明： 函数deferFuncParameter()定义一个数组，通过defer延迟函数printArray()的调用，最后修改数组第一个元素。printArray()函数接受数组的指针并把数组全部打印出来。 参考答案： 输出10、2、3三个值。延迟函数printArray()的参数在defer语句出现时就已经确定了，即数组的地址，由于延迟函数执行时机是在return语句之前，所以对数组的最终修改值会被打印出来。 2.3 题目三下面函数输出什么？ 123456789func deferFuncReturn() (result int) &#123; i := 1 defer func() &#123; result++ &#125;() return i&#125; 函数说明： 函数拥有一个具名返回值result，函数内部声明一个变量i，defer指定一个延迟函数，最后返回变量i。延迟函数中递增result。 参考答案： 函数输出2。函数的return语句并不是原子的，实际执行分为设置返回值–&gt;ret，defer语句实际执行在返回前，即拥有defer的函数返回过程是：设置返回值–&gt;执行defer–&gt;ret。所以return语句先把result设置为i的值，即1，defer语句中又把result递增1，所以最终返回2。 3. defer规则Golang官方博客里总结了defer的行为规则，只有三条，我们围绕这三条进行说明。 3.1 规则一：延迟函数的参数在defer语句出现时就已经确定下来了官方给出了一个例子，如下所示： 123456func a()&#123; i := 0 defer fmt.Println(i) i++ return&#125; defer语句中的fmt.Println()参数i值在defer出现时就已经确定下来，实际上是拷贝了一份。后面对变量i的修改不会影响fmt.Println()函数的执行，仍然打印”0”。 注意：对于指针类型参数，规则仍然适用，只不过延迟函数的参数是一个地址值，这种情况下，defer后面的语句对变量的修改可能会影响延迟函数。 3.2 规则二：延迟函数执行按后进先出顺序执行，即先出现的defer最后执行这个规则很好理解，定义defer类似于入栈操作，执行defer类似于出栈操作。 设计defer的初衷是简化函数返回时资源清理的动作，资源往往有依赖顺序，比如先申请A资源，再跟据A资源申请B资源，跟据B资源申请C资源，即申请顺序是:A–&gt;B–&gt;C，释放时往往又要反向进行。这就是把deffer设计成LIFO(Last In First Out)的原因。 每申请到一个用完需要释放的资源时，立即定义一个defer来释放资源是个很好的习惯。 3.3 规则三：延迟函数可能操作主函数的具名返回值定义defer的函数，即主函数可能有返回值，返回值有没有名字没有关系，defer所作用的函数，即延迟函数可能会影响到返回值。 若要理解延迟函数是如何影响主函数返回值的，只要明白函数是如何返回的就足够了。 3.1 函数返回过程有一个事实必须要了解，关键字return不是一个原子操作，实际上return只代理汇编指令ret，即将跳转程序执行。比如语句return i，实际上分两步进行，即将i存入栈中作为返回值，然后执行跳转，而defer的执行时机正是跳转前，所示说defer执行时还是有机会操作返回值的。 举个实际的例子进行说明这个过程： 123456789func deferFuncReturn() (result int) &#123; i := 1 defer func() &#123; result++ &#125;() return i&#125; 该函数的return语句可以拆分成下面两行： 12result = ireturn 而延迟函数的执行正是在return之前，即加入defer后执行过程如下： 123result = iresult ++ return 所以上面函数实际返回i++值。 关于主函数有不同的返回方式，但返回机制就如上机介绍所说，只要把return语句拆开都可以很好的理解，下面分别举例说明 3.1.1 主函数拥有匿名返回值，返回字面值一个主函数拥有一个匿名的返回值，返回时使用字面值，比如返回”1”、”2”、”Hello”这样的值，这种情况下defer语句是无法操作返回值的。 一个返回字面值的函数，如下所示： 123456789func foo() int &#123; var i int defer func() &#123; i++ &#125;() return 1&#125; 上面的return语句，直接把1写入栈中作为返回值，延迟函数无法操作该返回值，所以就无法影响返回值。 3.3.2 主函数拥有匿名返回值，返回变量一个主函数拥有一个匿名的返回值，返回使用本地或全局变量，这种情况下defer语句可以引用到返回值，但不会改变返回值。 一个返回本地变量的函数，如下所示： 123456789func foo() int &#123; var i int defer func() &#123; i++ &#125;() return i&#125; 上面的函数，返回一个局部变量，同时defer函数也会操作这个局部变量。对于匿名返回值来说，可以假定仍然有一个变量存储返回值，假定返回值变量为”anony”，上面的返回语句可以拆分成以下过程： 123anony = ii++return 由于i是整型，会将值拷贝给anony，所以defer语句中修改i值，对函数返回值不造成影响。 3.3.3 主函数拥有具名返回值主函声明语句中带名字的返回值，会被初始化成一个局部变量，函数内部可以像使用局部变量一样使用该返回值。如果defer语句操作该返回值，可能会改变返回结果。 一个影响函返回值的例子： 1234567func foo() (ret int) &#123; defer func() &#123; ret++ &#125;() return 0&#125; 上面的函数拆解出来，如下所示： 123ret = 0ret++return 函数真正返回前，在defer中对返回值做了+1操作，所以函数最终返回1。 4. defer实现原理本节我们尝试了解一些defer的实现机制。 4.1 defer数据结构源码包src/src/runtime/runtime2.go:_defer定义了defer的数据结构： 123456type _defer struct &#123; sp uintptr //函数栈指针 pc uintptr //程序计数器 fn *funcval //函数地址 link *_defer //指向自身结构的指针，用于链接多个defer&#125; 我们知道defer后面一定要接一个函数的，所以defer的数据结构跟一般函数类似，也有栈地址、程序计数器、函数地址等等。 与函数不同的一点是它含有一个指针，可用于指向另一个defer，每个goroutine数据结构中实际上也有一个defer指针，该指针指向一个defer的单链表，每次声明一个defer时就将defer插入到单链表表头，每次执行defer时就从单链表表头取出一个defer执行。 下图展示多个defer被链接的过程： 从上图可以看到，新声明的defer总是添加到链表头部。函数返回前执行defer则是从链表首部依次取出执行。 一个goroutine可能连续调用多个函数，defer添加过程跟上述流程一致，进入函数时添加defer，离开函数时取出defer，所有即便调用多个函数，也总能保证defer是按照LIFO方式执行 的。 4.2 defer的创建和执行源码包src/runtine/panic.go定义了两个方法分别用于创建defer和执行defer。 deferproc()：在声明defer处调用，其将defer函数存入goroutine的链表中； deferreturn()：在return指令，准确的将是在ret指令前调用，其将defer从goroutine链表中取出并执行。 可以简单的这么理解，在编译阶段，声明defer出插入了deferproc()，在函数return前插入了deferreturn()。 5. 总结 defer定义的延迟函数参数在defer语句出来时就已经确定下来了 defer定义顺序与执行顺序相反 return不是原子操作，执行过程是：保存返回值（若有） –&gt; 执行defer –&gt; 执行return跳转 申请资源后立即使用defer关闭资源是好习惯]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go iota]]></title>
    <url>%2F2019%2F07%2F06%2Fgo-iota%2F</url>
    <content type="text"><![CDATA[1.前言我们知道iota常用于const表达式中，我们还知道其值是从零开始的，const声明块中每增加一行iota值自增1。 使用iota可以简化常量定义，但其规则必须要牢牢掌握，否则在我们阅读别人源码时可能会造成误解或障碍。本节我们尝试全面的总结其使用场景，另外花一小部分时间看一下其实现原理，从原理上把握可以更深刻的记忆这些规则。 2.热身2.1 题目一下面常量定义源于GO源码，下面每个常量的值是多少？ 1234567891011type Priority intconst ( LOG_EMERG Priority = iota LOG_ALERT LOG_CRIT LOG_ERR LOG_WARNING LOG_NOTICE LOG_INFO LOG_DEBUG) 题目解释： 上面代码源于日志模块，定义了一组代表日志级别的常量，常量类型为Priority，实际为int类型。 参考答案： iota初始值为0，也即LOG_EMERG值为0，下面每个常量递增1。 2.2 题目二下面代码取自Go源码，请问每个常量值是多少？ 1234567const ( mutexLocked = 1 &lt;&lt; iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota starvationThresholdNs = 1e6) 题目解释： 以上代码取自Go互斥锁Mutex的实现，用于指示各种状态位的地址偏移。 参考答案： mutexLocked == 1；mutexWoken == 2；mutexStarving == 4；mutexWaiterShift == 3；starvationThresholdNs == 1000000。 2.3 题目三请问每个常量值是多少？ 123456const ( bit0, mask0 = 1 &lt;&lt; iota, 1&lt;&lt;iota - 1 bit1, mask1 _, _ bit3, mask3) 题目解释： 以上代码取自Go官方文档。 参考答案： bit0 == 1， mask0 == 0， bit1 == 2， mask1 == 1， bit3 == 8， mask3 == 7 3.规则很多书上或博客描述的规则是这样的： iota在const关键字出现时被重置为0 const声明块中每新增一行iota值自增1 我曾经也这么理解，看过编译器代码后发现，其实规则只有一条： iota代表了const声明块的行索引（下标从0开始） 这样理解更贴近编译器实现逻辑，也更准确。除此之外，const声明还有个特点，即第一个常量必须指定一个表达式，后续的常量如果没有表达式，则继承上面的表达式。 下面再来根据这个规则看下这段代码： 123456const ( bit0, mask0 = 1 &lt;&lt; iota, 1&lt;&lt;iota - 1 //const声明第0行，即iota==0 bit1, mask1 //const声明第1行，即iota==1, 表达式继承上面的语句 _, _ //const声明第2行，即iota==2 bit3, mask3 //const声明第3行，即iota==3) 第0行的表达式展开即bit0, mask0 = 1 &lt;&lt; 0, 1&lt;&lt;0 - 1，所以bit0 == 1，mask0 == 0； 第1行没有指定表达式继承第一行，即bit1, mask1 = 1 &lt;&lt; 1, 1&lt;&lt;1 - 1，所以bit1 == 2，mask1 == 1； 第2行没有定义常量 第3行没有指定表达式继承第一行，即bit3, mask3 = 1 &lt;&lt; 3, 1&lt;&lt;3 - 1，所以bit0 == 8，mask0 == 7； 4.编译原理const块中每一行在GO中使用spec数据结构描述，spec声明如下： 12345678910// A ValueSpec node represents a constant or variable declaration// (ConstSpec or VarSpec production).//ValueSpec struct &#123; Doc *CommentGroup // associated documentation; or nil Names []*Ident // value names (len(Names) &gt; 0) Type Expr // value type; or nil Values []Expr // initial values; or nil Comment *CommentGroup // line comments; or nil&#125; 这里我们只关注ValueSpec.Names， 这个切片中保存了一行中定义的常量，如果一行定义N个常量，那么ValueSpec.Names切片长度即为N。 const块实际上是spec类型的切片，用于表示const中的多行。 所以编译期间构造常量时的伪算法如下： 123456for iota, spec := range ValueSpecs &#123; for i, name := range spec.Names &#123; obj := NewConst(name, iota...) //此处将iota传入，用于构造常量 ... &#125;&#125; 从上面可以更清晰的看出iota实际上是遍历const块的索引，每行中即便多次使用iota，其值也不会递增。]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go channel 低层源码剖析]]></title>
    <url>%2F2019%2F07%2F06%2Fgo-channel%2F</url>
    <content type="text"><![CDATA[1. 前言channel是Golang在语言层面提供的goroutine间通信方式，比Unix管道更易用也更轻便。channel主要用于进程内各goroutine间通信，如果需要跨进程通信，建议使用分布式系统方法来解决。 本章，从源码角度分析channel的实现机制，实际上这部分源码非常简单易读。 chan数据结构src/runtine/chan.go:hchan定义了channel的数据结构： 12345678910111213type hchan struct &#123; qcount uint // 当前队列中剩余元素个数 dataqsiz uint // 环形队列长度，即可以存放的元素个数 buf unsafe.Pointer // 环形队列指针 elemsize uint16 // 每个元素的大小 closed uint32 // 标识关闭状态 elemtype *_type // 元素类型 sendx uint // 队列下标，指示元素写入时存放到队列中的位置 recvx uint // 队列下标，指示元素从队列的该位置读出 recvq waitq // 等待读消息的goroutine队列 sendq waitq // 等待写消息的goroutine队列 lock mutex // 互斥锁，chan不允许并发读写&#125; 从数据结构可以看出channel由队列、类型信息、goroutine等待队列组成，下面分别说明其原理。 2.1 环形队列chan内部实现了一个环形队列作为其缓冲区，队列的长度是创建chan时指定的。 下图展示了一个可缓存6个元素的channel示意图： datasiz 指示了队列长度为6，即可缓存6个元素； buf指向队列的内存，队列中还剩余两个元素； qcount表示队列中还有两个元素； sendx指示后续写入的数据存储的位置，取值[0,6) recvx指示从该位置读取数据，取值[0,6) 2.2 等待队列从channel读数据，如果channel缓冲区为空或者没有缓冲区，当前goroutine会被阻塞。向channel写数据，如果channel缓冲区已满或者没有缓冲区，当前的goroutine会被阻塞。 被阻塞的goroutine会被挂在channel的等待队列中； 因读阻塞的goroutine会被向channel写入数据的goroutine唤醒； 因写阻塞的goroutine会被从channel读数据的goroutine唤醒； 下图展示了一个没有缓冲区的channel，有几个gouroutine阻塞等待读数据： 注意，一般情况下recvq和sendq至少有一个为空。只有一个例外，那就是同一个goroutine使用select语句向channel一边写数据，一边读数据。 2.3 类型信息一个channel只能传递一种类型的值，类型信息存储在hchan数据结构中。 elemtype代表类型，用于数据传递过程中的赋值； elemsize代表类型大小，用于在buf中定位元素位置。 2.4 锁一个channel同时仅允许被一个goroutine读写 3.channel读写3.1 创建channel创建channel的过程实际上是初始化hchan结构，其中类型信息和缓冲区长度由make语句传入，buf的大小则与元素大小和缓冲区长度共同决定。 创建channel的伪代码如下所示 12345678910func makechan(t *chantype, size int) *hchan&#123; var c *hchan c = new(hchan) c.buf = malloc(元素类型*size) c.elemsize = 元素类型大小 c.elemtype = 元素类型 c.dataqsiz size return c&#125; 3.2 向channel写数据向一个channel中写数据简单过程如下： 1.如果等待接收队列recvq不为空，说明缓冲区中没有数据或者没有缓冲区，此时直接从recvq取出G，并把数据写入，最后把该G唤醒，结束发送过程 2.如果缓冲区有空余位置，将数据写入缓冲区，结束发送过程； 3.如果缓冲区没有空余位置，将待发数据写入G，将当前G加入sendq，进入睡眠，等待被读goroutine唤醒。. 简单流程图如下： 3.3 从channel读数据从一个channel读数据简单过程如下： 1.如果等待发送队列sendq不为空，且没有缓冲区，直接从sendq中取出G，把G中数据读出，最后把G唤醒，结束读取过程； 2.如果等待发送队列sendq不为空，缓冲区已满，从缓冲区首部读出数据，把G中数据写入缓冲区尾部，把G唤醒，结束读取过程； 3.如果缓冲区有数据，则从缓冲区取出数据，结束读取过程； 4.将当前的goroutine加入recvq，进入睡眠，等待被写goroutine唤醒。 3.4 关闭channel关闭channel时会把revq中的G全部唤醒，本该写入G的数据位置为nil。把sendq中的G全部唤醒，但是这些G会panic。 除此之外，panic出现的常见场景还有： 1.关闭值为nil的channel 2.关闭已经被关闭的channel 3.向已经关闭的channel写数据 4.常见用法4.1 单向channel顾名思义，单向channel指只能用于发送或接收数据，实际上也没有单向channel。 我们知道channel可以通过参数传递，所谓单向channel只是对channel的一种使用限制，这跟C语言使用const修饰函数参数为只读是一个道理。 func readChan(chanName &lt;-chan int)：通过形参限定函数内部只能从channel中读取数据 func writeChan(chanName chan&lt;- int)：通过形参限定函数内部只能往channel中写数据 一个简单的示例程序如下： 1234567891011121314func readChan(chanName &lt;-chan int) &#123; &lt;- chanName&#125;func writeChan(chanName chan&lt;- int) &#123; chanName &lt;- 1&#125;func main() &#123; var mychan = make(chan int, 10) writeChan(mychan) readChan(mychan)&#125; mychan是个正常的channel，而readChan()参数限制了传入的channel只能用来读，writeChan()参数限制了传入的channel只能用来读。 4.2 select使用select可以监控多个channel，比如监控多个channel，当其中某一个channel有数据的话，就从中读出数据。 一个简单的示例程序如下： 123456789101112131415161718192021222324252627282930313233package mainimport ( &quot;fmt&quot; &quot;time&quot;)func addNumberToChan(chanName chan int) &#123; for &#123; chanName &lt;- 1 time.Sleep(1 * time.Second) &#125;&#125;func main() &#123; var chan1 = make(chan int, 10) var chan2 = make(chan int, 10) go addNumberToChan(chan1) go addNumberToChan(chan2) for &#123; select &#123; case e := &lt;- chan1 : fmt.Printf(&quot;Get element from chan1: %d\n&quot;, e) case e := &lt;- chan2 : fmt.Printf(&quot;Get element from chan2: %d\n&quot;, e) default: fmt.Printf(&quot;No element in chan1 and chan2.\n&quot;) time.Sleep(1 * time.Second) &#125; &#125;&#125; 程序中创建两个channel： chan1和chan2。函数addNumberToChan()函数会向两个channel中周期性写入数据。通过select可以监控两个channel，任意一个可读时就从其中读出数据。 程序输出如下： 12345678910D:\SourceCode\GoExpert\src&gt;go run main.goGet element from chan1: 1Get element from chan2: 1No element in chan1 and chan2.Get element from chan2: 1Get element from chan1: 1No element in chan1 and chan2.Get element from chan2: 1Get element from chan1: 1No element in chan1 and chan2. 从输出可见，从channel中读出数据的顺序是随机的，事实上select语句的多个case执行顺序是随机的。 通过这个示例想说的是：select的case语句读channel不会阻塞，尽管channel中没有数据。这是由于case语句编译后调用读channel时会明确传入不阻塞的参数，此时读不到数据时不会将当前goroutine加入到等待队列，而是直接返回。 4.3 range通过range可以持续从channel中读出数据，好像在遍历一个数组一样，当channel中没有数据时会阻塞当前goroutine，与读channel时阻塞处理机制一样。 12345func chanRange(chanName chan int) &#123; for e := range chanName &#123; fmt.Printf(&quot;Get element from chan: %d\n&quot;, e) &#125;&#125; 注意：如果向此channel写数据的goroutine退出时，系统检测到这种情况后会panic，否则range将会永久阻塞。]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go map原理剖析]]></title>
    <url>%2F2019%2F07%2F01%2Fgo-map%2F</url>
    <content type="text"><![CDATA[1. map数据结构golang的map的使用了哈希表作为低层实现，一个哈希表里可以有多个哈希表节点，也即bucket，而每个bucket保存了map中的一个或一组键值对。 map的数据结构由runtime/map.go:hmap定义： 12345678type hmap struct &#123; count int //当前保存的元素个数 ... B uint8 //指示bucket数组的大小 ... buckets unsafe.Pointer //bucket数组指针，数组的大小为2^B ...&#125; 下图展示一个拥有4个bucket的map: 本例中，hmap.B=2，而hmap.buckets的长度是2^B为4，元素经过哈希运算后会落到某个bucket中进行存储。查找过程类似。 bucket很多时候会翻译成桶，所谓的哈希桶实际上就是bucket。 2. bucket数据结构bucket数据结构由runtime/map.go:bmap定义 12345type bmap struct &#123; tophash [8]uint8 //存储哈希值的高8位 data byte[1] //key value数据:key/key/key/.../value/value/value... overflow *bmap //溢出bucket的地址&#125; 每个bucket可以存储8个键值对。 tophash是个长度为8的数组，哈希值相同的键（准确的说是哈希值低位相同的键）存入当前bucket时会将哈希值的高位存储在该数组中，以方便后续匹配。 data区存放的是key-value数据，存放顺序是key/key/key/…value/value/value，如此存放是为了节省字节对齐带来的空间浪费。 overflow指针指向的是下一个bucket，据此将所有冲突的键连接起来。 注意：上述中data和overflow并不是在结构体中显示定义的，而是直接通过指针运算进行访问的。 下图展示bucket存放8个key-value对： 3. 哈希冲突当有两个或以上数量的键被哈希到了同一个bucket时，我们称这些键发生了冲突。Go使用链地址法来解决键冲突。 由于每个bucket可以存放8个键值对，所以同一个bucket存放超过8个键值对时就会再创建一个键值对，用类似链表的方式将bucket连接起来。 下图展示产生冲突后的map： bucket数据结构指示下一个bucket的指针称为overflow bucket，意为当前bucket盛不下而溢出的部分。事实上哈希冲突并不是好事情，它降低了存取效率，好的哈希算法可以保证哈希值的随机性，但冲突过多也是要控制的，后面会再详细介绍。 4. 负载因子负载因子是衡量一个哈希表冲突情况，公式为： 1负载因子 = 键数量 / bucket数量 例如，对于一个bucket数量为4，包含4个键值对的哈希表来说，这个哈希表的负载因子为1. 哈希表需要将负载因子控制在一个合适的大小，超过阈值需要进行refresh，也即键值对重新组织： 哈希因子过小，说明空间利用率低 哈希因子过大，说明冲突严重，存取效率低 每个哈希表的实现对负载因子容忍程度不同，比如Redis实现中负载因子大于1时就会触发rehash，而Go则在在负载因子达到6.5时才会触发rehash，因为Redis的每个bucket只能存1个键值对，而Go的bucket可能存8个键值对，所以Go可以容忍更高的负载因子。 5. 渐进式扩容5.1 扩容的前提条件为了保证访问效率，当新元素将要添加进map时，都会检查是否需要扩容，扩容实际上是以空间换时间的手段。 触发扩容的条件有二个： 1. 负载因子 &gt; 6.5时，也即平均每个bucket存储的键值对达到6.5个。 2. overflow数量 &gt; 2^15时，也即overflow数量超过32768时。 5.2 增量扩容当负载因子过大时，就新建一个buckets，新的buckets长度是原来的2倍，然后旧buckets数据搬迁到新的buckets。 考虑到如果map存储了数以亿计的key-value，一次性搬迁将会造成比较大的延时，Go采用逐步搬迁策略，即每次访问map时都会触发一次搬迁，每次搬迁2个键值对。 下图展示了包含一个bucket满载的map(为了描述方便，图中bucket省略了value区域): 当前map存储了7个键值对，只有1个bucket。此地负载因子为7。再次插入数据时将会触发扩容操作，扩容之后再将新插入键写入新的bucket。 当第8个键值对插入时，将会触发扩容，扩容后示意图如下： hmap数据结构中oldbuckets成员指身原bucket，而buckets指向了新申请的bucket。新的键值对被插入新的bucket中。 后续对map的访问操作会触发迁移，将oldbuckets中的键值对逐步的搬迁过来。当oldbuckets中的键值对全部搬迁完毕后，删除oldbuckets。 搬迁完成后的示意图如下： 数据搬迁过程中原bucket中的键值对将存在于新bucket的前面，新插入的键值对将存在于新bucket的后面。 实际搬迁过程中比较复杂，将在后续源码分析中详细介绍。 5.3 等量扩容所谓等量扩容，实际上并不是扩大容量，buckets数量不变，重新做一遍类似增量扩容的搬迁动作，把松散的键值对重新排列一次，以使bucket的使用率更高，进而保证更快的存取。 在极端场景下，比如不断的增删，而键值对正好集中在一小部分的bucket，这样会造成overflow的bucket数量增多，但负载因子又不高，从而无法执行增量搬迁的情况，如下图所示： 上图可见，overflow的buckt中大部分是空的，访问效率会很差。此时进行一次等量扩容，即buckets数量不变，经过重新组织后overflow的bucket数量会减少，即节省了空间又会提高访问效率。 6. 查找过程查找过程如下： 跟据key值算出哈希值 取哈希值低位与hmpa.B取模确定bucket位置 取哈希值高位在tophash数组中查询 如果tophash[i]中存储值也哈希值相等，则去找到该bucket中的key值进行比较 当前bucket没有找到，则继续从下个overflow的bucket中查找 如果当前处于搬迁过程，则优先从oldbuckets查找 注：如果查找不到，也不会返回空值，而是返回相应类型的0值。 7. 插入过程新员素插入过程如下： 跟据key值算出哈希值 取哈希值低位与hmap.B取模确定bucket位置 查找该key是否已经存在，如果存在则直接更新值 如果没找到将key，将key插入]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go string低层原理]]></title>
    <url>%2F2019%2F06%2F30%2Fgo-string%2F</url>
    <content type="text"><![CDATA[string标准概念Go标准库builtin给出了所有内置类型的定义。源码位于src/builtin/builtin.go，其中关于string的描述如下： 1234// string is the set of all strings of 8-bit bytes, conventionally but not// necessarily representing UTF-8-encoded text. A string may be empty, but// not nil. Values of string type are immutable.type string string 所以string是8比特字节的集合，通常但不一定是UTF-8编码的文本。 另外还提到了两点，非常重要： string可以为空（长度为0），但不会是nil； string对象是不可修改的。 string 数据结构源码包src/runtime/string.go:stringStruct定义了string的数据结构： 1234type stringStruct struct &#123; str unsafe.Pointer len int&#125; 其数据结构很简单： stringStruct.str: 字符串首字母地址； stringStruct.len：字符串的长度； string数据结构跟切片有些类似，只不过切片还有一个表示容量的成员，事实上string和切片，准确的说是byte切片经常发生转换。这个后面再详细介绍。 string操作声明如下代码所示，可以声明一个string变量并赋予初值： 12var str stringstr = &quot;hello world&quot; 字符串构建过程中先根据字符串构建stringStruct，再转换成string。转换的源码如下： 12345func gostringnocopy(str *byte) string &#123; // 跟据字符串地址构建string ss := stringStruct&#123;str: unsafe.Pointer(str), len: findnull(str)&#125; // 先构造stringStruct s := *(*string)(unsafe.Pointer(&amp;ss)) // 再将stringStruct转换成string return s&#125; string在runtime包中就是stringStruct，对外呈现叫做string。 []byte转stringbyte切片可以很方便的转换成string，如下所示： 123func GetStringBySlice(s []byte) string &#123; return string(s)&#125; 需要注意的是这种转换需要一次内存拷贝。 转换过程如下： 跟据切片的长度申请内存空间，假设内存地址为p，切片长度为len(b)； 构建string（string.str = p；string.len = len；） 拷贝数据(切片中数据拷贝到新申请的内存空间) 转换示意图： string转[]bytestring也可以很方便的转成byte切片，如下所示： 123func GetSliceByString(str string) []byte &#123; return []byte(str)&#125; string转换成byte切片，也需要一次内存拷贝，其过程如下： 申请切片内存空间 将string拷贝到切片 转换示意图： 字符串拼接字符串可以很方便的拼接，像下面这样： 1str := &quot;Str1&quot; + &quot;Str2&quot; + &quot;Str3&quot; 即便有非常多的字符串需要拼接，性能上也有比较好的保证，因为新字符串的内存空间是一次分配完成的，所以性能消耗主要在拷贝数据上。 一个拼接语句的字符串编译时都会被存放到一个切片中，拼接过程需要遍历两次切片，第一次遍历获取总的字符串长度，据此申请内存，第二次遍历会把字符串逐个拷贝过去。 字符串拼接伪代码如下： 12345678910111213141516func concatstrings(a []string) string &#123; // 字符串拼接 length := 0 // 拼接后总的字符串长度 for _, str := range a &#123; length += length(str) &#125; s, b := rawstring(length) // 生成指定大小的字符串，返回一个string和切片，二者共享内存空间 for _, str := range a &#123; copy(b, str) // string无法修改，只能通过切片修改 b = b[len(str):] &#125; return s&#125; 因为string是无法直接修改的，所以这里使用rawstring()方法初始化一个指定大小的string，同时返回一个切片，二者共享同一块内存空间，后面向切片中拷贝数据，也就间接修改了string。 rawstring()源代码如下： 12345678910func rawstring(size int) (s string, b []byte) &#123; // 生成一个新的string，返回的string和切片共享相同的空间 p := mallocgc(uintptr(size), nil, false) stringStructOf(&amp;s).str = p stringStructOf(&amp;s).len = size *(*slice)(unsafe.Pointer(&amp;b)) = slice&#123;p, size, size&#125; return&#125; 为什么字符串不允许修改？像C++语言中的string，其本身拥有内存空间，修改string是支持的。但Go的实现中，string不包含内存空间，只有一个内存的指针，这样做的好处是string变得非常轻量，可以很方便的进行传递而不用担心内存拷贝。 因为string通常指向字符串字面量，而字符串字面量存储位置是只读段，而不是堆或栈上，所以才有了string不可修改的约定。 []byte转换成string一定会拷贝内存吗？byte切片转换成string的场景很多，为了性能上的考虑，有时候只是临时需要字符串的场景下，byte切片转换成string时并不会拷贝内存，而是直接返回一个string，这个string的指针(string.str)指向切片的内存。 比如，编译器会识别如下临时场景： 使用m[string(b)]来查找map（map是string为key，临时把切片b转成string）； 字符串拼接，如”&lt;” + “string(b)” + “&gt;”； 字符串比较：string(b) == “foo” 因为是临时把byte切片转换成string，也就避免了因byte切片内容改变而导致string引用失败的情况，所以此时可以不必拷贝内存新建一个string。 string和[]byte如何取舍？string和[]byte都可以表示字符串，但因数据结构不同，其衍生出来的方法也不同，要跟据实际应用场景来选择。 string 擅长的场景： 需要字符串比较的场景； 不需要nil字符串的场景； []byte擅长的场景： 修改字符串的场景，尤其是修改粒度为1个字节 函数返回值，需要用nil表示含义的场景； 需要切片操作的场景； 虽然看起来string适用的场景不如[]byte多，但因为string直观，在实际应用中还是大量存在，在偏底层的实现中[]byte使用更多。]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go slice实现原理]]></title>
    <url>%2F2019%2F06%2F30%2Fgo-slice%2F</url>
    <content type="text"><![CDATA[1 前言Slice又称为动态数组，低层依托于数组实现。可以方便的进行扩容，传递等。实际使用过程中，比数组更灵活。 2 Slice实现原理Slice依托于数组实现，低层数组对用户屏蔽，在低层数组容量不足时可以实现自动重分配并生成新的Slice。 2.1 Slice的数据结构源码包中src/runtime/slice.go定义了Slice的数据结构 12345type slice struct&#123; array unsafe.Pointer len int cap int&#125; 从数据结构看，slice其实就是一个结构体，array指针指向低层数组，len表示切片长度，cap表示低层数组容量。 2.2 使用make创建Slice使用make关键字创建Slice时，可以同时制定长度和容量，创建时低层会分配一个数组，数组的长度即容量。 例如，语句 slice:=make([]int,5,10)所创建的slice，结构如下图所示: 该Slice的长度为5，可以使用slice[0]~slice[4]来操作里面的元素，capacity为10，表示后续向slice添加新的元素时可以不必重新分配内存，直接使用预留内存即可。 2.3 使用数组创建Slice使用数组来创建Slice时，Slice将于原数组共用一部分内存。例如，语句slice:=array[5:7]所创建的Slice，结构如下图所示: 切片从数组array[5]开始，到数组array[7]结束（不含array[7]）,即切片长度为2，数组后面的内容都作为切片的预留内存，即capacity为5。 数组和切片操作可能作用于同一块内存，这也是使用过程中需要注意的地方。 2.4 Slice扩容使用append向Slice追加元素时，如果Slice空间不足，将会触发Slice扩容，扩容实际上重新一配一块更大的内存，将原Slice数据拷贝进新Slice，然后返回新Slice，扩容后再将数据追加进去。 例如，当向一个capacity为5，且length也为5的Slice再次追加1个元素时，就会发生扩容，如图所示： 扩容操作只关心容量，会把原Slice数据拷贝到新Slice，追加数据由append在扩容结束后完成。上图可见，扩容后新的Slice长度仍然是5，但容量由5提升到了10，原Slice的数据也都拷贝到了新Slice指向的数组中。 扩容容量的选择遵循以下规则： 如果原Slice容量小于1024，则新Slice容量将扩大为原来的2倍； 如果原Slice容量大于等于1024，则新Slice容量将扩大为原来的1.25倍； 使用append()向Slice添加一个元素的实现步骤如下： 假如Slice容量够用，则将新元素追加进去，Slice.len++，返回原Slice 原Slice容量不够，则将Slice先扩容，扩容后得到新Slice 将新元素追加进新Slice，Slice.len++，返回新的Slice。 2.5 Slice Copy使用copy()内置函数拷贝两个切片时，会将源切片的数据逐个拷贝到目的切片指向的数组中，拷贝数量取两个切片长度的最小值。例如长度为10的切片拷贝到长度为5的切片时，将会拷贝5个元素。也就是说，copy过程中不会发生扩容。 2.6 特殊切片跟据数组或切片生成新的切片一般使用slice := array[start:end]方式，这种新生成的切片并没有指定切片的容量，实际上新切片的容量是从start开始直至array的结束。 比如下面两个切片，长度和容量都是一致的，使用共同的内存地址： 12sliceA := make([]int, 5, 10)sliceB := sliceA[0:5] 根据数组或切片生成切片还有另一种写法，即切片同时也指定容量，即slice[start:end:cap], 其中cap即为新切片的容量，当然容量不能超过原切片实际值，如下所示： 123sliceA := make([]int, 5, 10) //length = 5; capacity = 10sliceB := sliceA[0:5] //length = 5; capacity = 10sliceC := sliceA[0:5:5] //length = 5; capacity = 5 3 总结 每个切片都指向一个底层数组 每个切片都保存了当前切片的长度、底层数组可用容量 使用len()计算切片长度时间复杂度为O(1)，不需要遍历切片 使用cap()计算切片容量时间复杂度为O(1)，不需要遍历切片 通过函数传递切片时，不会拷贝整个切片，因为切片本身只是个结构体而矣 使用append()向切片追加元素时有可能触发扩容，扩容后将会生成新的切片]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-date-time-conver]]></title>
    <url>%2F2019%2F06%2F30%2Fgo-date-time-conver%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021package mainimport( &quot;fmt&quot; &quot;time&quot;)func main() &#123; datetime := &quot;2015-01-01 00:00:00&quot; //待转化为时间戳的字符串 //日期转化为时间戳 timeLayout := &quot;2006-01-02 15:04:05&quot; //转化所需模板 loc, _ := time.LoadLocation(&quot;Local&quot;) //获取时区 tmp, _ := time.ParseInLocation(timeLayout, datetime, loc) timestamp := tmp.Unix() //转化为时间戳 类型是int64 fmt.Println(timestamp) //时间戳转化为日期 datetime = time.Unix(timestamp, 0).Format(timeLayout) fmt.Println(datetime)&#125; 输出1214200416002015-01-01 00:00:00]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go strings包介绍]]></title>
    <url>%2F2019%2F06%2F30%2Fgo-strings-package%2F</url>
    <content type="text"><![CDATA[strings包提供了操作字符串的简单函数。 func Compare(a,b string) int func Contains(s, substr string) bool func Count(s, sep string) int func Fields(s string) []string func FieldsFunc(s string, f func(rune) bool) []string func HasPrefix(s, prefix string) bool func HasSuffix(s, suffix string) bool func Index(s, sep string) int func LastIndex(s,sep string) int func Join(a []string,sep string) string func Repeat(s string,count int) string func Replace(s,old,new string,n int) string func Split(s,sep string) []string func SplitN(s,sep string, n int) []string func ToLower(s string) string funcc ToUpper(s string) string func Trim(s string,cutset string) string 1. func Compare1func Compare(a, b string) int 根据字典顺序，比较两个字符串的大小。字典顺序，就是说，将多个字符串的同一位置的字符按照26个字母的顺序进行比对。a最小，z最大。 1The result will be 0 if a==b, -1 if a &lt; b, and +1 if a &gt; b. 2. func Contains判断，原字符串是否包含子串 1234fmt.Println(strings.Contains(&quot;seafood&quot;, &quot;foo&quot;))fmt.Println(strings.Contains(&quot;seafood&quot;, &quot;bar&quot;))fmt.Println(strings.Contains(&quot;seafood&quot;, &quot;&quot;))fmt.Println(strings.Contains(&quot;&quot;, &quot;&quot;)) 输出 1234truefalsetruetrue 3. func Count1func Count(s, sep string) int Count计算s中非重叠sep实例的数量。如果sep是空字符串，则Count返回1 +len(s)。 12fmt.Println（strings.Count（“cheese”，“e”））fmt.Println（strings.Count（“five”，“”））//在每个符文之前和之后 输出 123 5 4. func Fields1func Fields(s string) []string 以空格为分隔符，分割字符串s，并返回字符切片 5. func FieldsFunc按照空格，分割字符串，同时对分割后的单个字符串，做相应的逻辑判断，如果匿名函数为真，则不返回该子串。最后返回一个字符串切片。12345678910//只返回字母func testFieldsFunc() &#123; str := &quot;- MY NAME is meichaofan JACK 1534&quot; r := strings.FieldsFunc(str, func(r rune) bool &#123; return !unicode.IsLetter(r) &#125;) fmt.Printf(&quot;%v&quot;, r)&#125;//output // [MY NAME is meichaofan JACK] 6. func HasPrefix判断字符串是否以某个前缀开头 1234567func testHasPrefix() &#123; str := &quot;meichaofan&quot; r := strings.HasPrefix(str,&quot;mei&quot;) fmt.Println(r)&#125;//output//true 7. func HasSuffix判断字符串是否以某个后缀结束 1234567func testHasSuffix() &#123; str := &quot;/home/meichaofan&quot; r := strings.HasPrefix(str,&quot;/&quot;) fmt.Println(r)&#125;//output//false 8.func Index1func Index（s，sep string）int Index 返回s中第一个sep子串的位置，如果不存在sep，返回-1 代码： 12fmt.Println（strings.Index（“chicken”，“ken”））fmt.Println（strings.Index（“chicken”，“dmr”）） 输出： 124-1 9.func LastIndex返回子串最后一次出现的位置 10.func Join字符串切片以sep合并 12345str := []string&#123;&quot;my&quot;, &quot;name&quot;, &quot;is&quot;, &quot;jack&quot;&#125;r:= strings.Join(str,&quot;-&quot;)fmt.Println(r)//output//my-name-is-jack 11. func Repeat重复字符串 123fmt.Println（“ba”+ strings.Repeat（“na”，2））//output//banana 12. func Replace1func Replace(s, old, new string, n int) string 字符串替换，将原串中old串，替换成new串。替换次数为n次。当n&lt;0，替换次数没有限制。 12345fmt.Println(strings.Replace(&quot;oink oink oink&quot;, &quot;k&quot;, &quot;ky&quot;, 2))fmt.Println(strings.Replace(&quot;oink oink oink&quot;, &quot;oink&quot;, &quot;moo&quot;, -1))//output //oinky oinky oink//moo moo moo 13.fun Split1func Split(s, sep string) []string 将字符串s按照分隔符sep分割。 1234fmt.Printf(&quot;%q\n&quot;, strings.Split(&quot;a,b,c&quot;, &quot;,&quot;))fmt.Printf(&quot;%q\n&quot;, strings.Split(&quot;a man a plan a canal panama&quot;, &quot;a &quot;))fmt.Printf(&quot;%q\n&quot;, strings.Split(&quot; xyz &quot;, &quot;&quot;))fmt.Printf(&quot;%q\n&quot;, strings.Split(&quot;&quot;, &quot;Bernardo O&apos;Higgins&quot;)) 输出 1234[&quot;a&quot; &quot;b&quot; &quot;c&quot;][&quot;&quot; &quot;man &quot; &quot;plan &quot; &quot;canal panama&quot;][&quot; &quot; &quot;x&quot; &quot;y&quot; &quot;z&quot; &quot; &quot;][&quot;&quot;] 14. func SplitN1func SplitN（s，sep string，n int）[] string n表示要返回的子字符串数： 123n&gt;0:最多n个子串，最后一个子字符串是未分割的余数n==0:结果是niln&lt;0;所有子串 等效于 split 代码 123fmt.Printf（“％q \ n”，strings.SplitN（“a，b，c”，“，”，2））z：= strings.SplitN（“a，b，c”，“，”，0 ）fmt.Printf（“％q（nil =％v）\ n”，z，z == nil） 输出 12[“a”“b，c”] []（nil = true）]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go 初始化顺序]]></title>
    <url>%2F2019%2F06%2F30%2Fgo-initialization-sequence%2F</url>
    <content type="text"><![CDATA[初始化顺序先执行import包的每个文件的常量和变量，然后是init函数，最后执行main函数，当main函数执行结束程序退出。]]></content>
  </entry>
  <entry>
    <title><![CDATA[全方位解读PHP7低层源码]]></title>
    <url>%2F2019%2F06%2F15%2Fphp7-source-code%2F</url>
    <content type="text"><![CDATA[本栏从源码的角度，解析PHP7。对掌握PHP有重大帮助，望坚持更新。 PHP7的新特性 基础变量与内存管理 PHP运行的生命周期 PHP代码的编译与执行 基础语法实现的细节 PHP扩展编写]]></content>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NumPy介绍]]></title>
    <url>%2F2019%2F05%2F31%2Fpython-numpy%2F</url>
    <content type="text"><![CDATA[NumPy在学习深度学习时，NumPy的数组类提供了很多关于操作数组和矩阵的便捷方法。 2019/5/301.1 导入NumPyNumPy并不存在于标准版Python中，因此，首先需要导入NumPy库 1&gt;&gt;&gt; import numpy as np 1.2 生成NumPy数组使用np.array()方法。np.array()接受Python的列表作为参数，生成NumPy数组（num.ndarray）。 12345&gt;&gt;&gt; x=np.array([1.0,2.0,3.0])&gt;&gt;&gt; print(x)[1. 2. 3.]&gt;&gt;&gt; type(x)&lt;class &apos;numpy.ndarray&apos;&gt; 1.3 NumPy的算术运算12345678910&gt;&gt;&gt; x = np.array([1.0, 2.0, 3.0])&gt;&gt;&gt; y = np.array([2.0, 4.0, 6.0])&gt;&gt;&gt; x + y # 对应元素的加法array([ 3., 6., 9.])&gt;&gt;&gt; x - yarray([ -1., -2., -3.])&gt;&gt;&gt; x * y # element-wise productarray([ 2., 8., 18.])&gt;&gt;&gt; x / yarray([ 0.5, 0.5, 0.5]) 需要注意，数组x和数组y的元素个数相同，如果元素个数不同，程序会报错。 NumPy数组不仅可以进行对应元素的运算，也可以和单一的数值（标量）进行运算，这个功能叫广播。 123&gt;&gt;&gt; x = np.array([1.0, 2.0, 3.0])&gt;&gt;&gt; x / 2.0array([ 0.5, 1. , 1.5]) NumPy的N维数组NumPy可以生成多维数组 12345678&gt;&gt;&gt; A = np.array([[1, 2], [3, 4]])&gt;&gt;&gt; print(A)[[1 2][3 4]]&gt;&gt;&gt; A.shape #查看数组形状(2, 2)&gt;&gt;&gt; A.dtype #查看数组元素的数据类型dtype(&apos;int64&apos;) 1234567&gt;&gt;&gt; B = np.array([[3, 0],[0, 6]])&gt;&gt;&gt; A + B #两个二维数组相加array([[ 4, 2],[ 3, 10]])&gt;&gt;&gt; A * B #两个二维数组相乘，对应位置的元素进行算术运算array([[ 3, 0],[ 0, 24]]) 1234567#广播&gt;&gt;&gt;print(A)[[1 2] [3 4]]&gt;&gt;&gt;A*10array([[ 10, 20],[ 30, 40]]) 访问元素元素的索引从0开始。对各个元素的访问如下： 123456789&gt;&gt;&gt; X = np.array([[51, 55], [14, 19], [0, 4]])&gt;&gt;&gt; print(X)[[51 55][14 19][ 0 4]]&gt;&gt;&gt; X[0] # 第0行array([51, 55])&gt;&gt;&gt; X[0][1] # (0,1)的元素55 也可以用for语句访问各个元素 123456&gt;&gt;&gt; for row in X:... print(row)...[51 55][14 19][0 4] 除了前面介绍的索引操作，NumPy还可以使用数组访问各个元素 12345&gt;&gt;&gt; X = X.flatten() # 将X转换为一维数组&gt;&gt;&gt; print(X)[51 55 14 19 0 4]&gt;&gt;&gt; X[np.array([0, 2, 4])] # 获取索引为0、 2、 4的元素array([51, 14, 0]) 运用这个标记法，可以获取满足一定条件的元素。例如，要从 X中抽出大于15的元素，可以写成如下形式。 1234&gt;&gt;&gt; X &gt; 15array([ True, True, False, True, False, False], dtype=bool)&gt;&gt;&gt; X[X&gt;15]array([51, 55, 19]) 对NumPy数组使用不等号运算符等（上例中是 X &gt; 15）,结果会得到一个布尔型的数组。上例中就是使用这个布尔型数组取出了数组的各个元素（取出 True对应的元素）。]]></content>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-1-two-sum]]></title>
    <url>%2F2019%2F05%2F29%2Fleetcode-1-two-sum%2F</url>
    <content type="text"><![CDATA[描述给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。 123456示例:给定 nums = [2, 7, 11, 15], target = 9因为 nums[0] + nums[1] = 2 + 7 = 9所以返回 [0, 1] 思路解法PHP版本JAVA版本Go版本Python版本]]></content>
      <tags>
        <tag>leetcode</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好好过生活，知足最快乐]]></title>
    <url>%2F2019%2F05%2F28%2Fhave-a-good-life%2F</url>
    <content type="text"><![CDATA[还记得 你说家是唯一的城堡 随着稻香河流继续奔跑 微微笑 小时候的梦我知道 不要哭 让萤火虫带着你逃跑 乡间的歌谣 永远的依靠 回家吧 回到最初的美好 杂记 毕业在即，云胡不喜]]></content>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毕业在即，云乎不喜]]></title>
    <url>%2F2019%2F05%2F28%2Fgraduation-finally%2F</url>
    <content type="text"><![CDATA[终于要换一种身份开启人生新一段旅程。]]></content>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux如何给应用程序创建一个桌面启动图标]]></title>
    <url>%2F2019%2F04%2F29%2Flinux-create-a-desktop-app%2F</url>
    <content type="text"><![CDATA[本文主要讲述的是linux中如何给应用程序创建一个快速启动图标，话不多说，我们来看实际的操作步骤： 本文的实例是给celipse创建一个启动图标 我们需要通过下列命令，来创建一个启动的脚本： 1vim /usr/share/applications/eclipse.desktop 将下列内容复制到启动脚本中： 12345678910[Desktop Entry]Encoding=UTF-8Name=EclipseComment=Eclipse IDEExec=/usr/local/android/eclipse/eclipse Icon=/usr/local/android/eclipse/icon.xpmTerminal=falseStartupNotify=trueType=ApplicationCategories=Application;Development; 说明部分：Exec ：这个是应用程序可执行文件的目录Icon ：这个是图标的目录 然后在applications -&gt; programming 菜单中就可以找到你所创建的图标了，然后再右键创建一个桌面图标即可]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Desktop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 系统修改默认运行级别]]></title>
    <url>%2F2019%2F04%2F29%2Fubuntu-change-runlevel%2F</url>
    <content type="text"><![CDATA[Deb系运行级别（Debian、Ubuntu） 0 – Halt，关机模式1 – Single，单用户模式2 - Full multi-user with display manager (GUI)3 - Full multi-user with display manager (GUI)4 - Full multi-user with display manager (GUI)5 - Full multi-user with display manager (GUI)6 – Reboot，重启S - 单用户恢复模式 2~5级是没有任何区别的，他们为多用户模式。 Rpm系运行级别（Redhat、CentOS） 0 – Halt，关机模式1 – Single，单用户模式2 – 多用户模式，但不能使用NFS（相当于Windows下的网上邻居）3 – 字符界面的多用户模式4 – Undefined5 – Full multi-user with display manager (GUI)6 – Reboot，重启 查看当前运行级别12meichaofan@ubuntu:~$ runlevel N 2 ubuntu系统下修改运行级别1234567vi /etc/default/grup将GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet&quot;改为GRUB_CMDLINE_LINUX_DEFAULT=&quot;text&quot;然后执行update-grub2]]></content>
      <tags>
        <tag>ubuntu</tag>
        <tag>runlevel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux的进程调度]]></title>
    <url>%2F2019%2F04%2F28%2Flinux-process-sche%2F</url>
    <content type="text"><![CDATA[转载至 https://blog.csdn.net/gatieme/article/details/51701149 1. 前言 1.1 进程调度内存中保存了对每个进程的唯一描述，并通过若干结构与其它进程连接起来。 调度器面对的情形就是这样，其任务是在程序之间共享CPU时间，创造并行执行的错觉，该任务分为两个不同的部分，其中一个涉及调度策略，另外一个涉及上下文切换。 1.2 进程的分类 Linux把进程区分为实时进程和非实时进程，其中非实时进程进一步划分为交互式进程和批处理进程。 类型 描述 示例 实时进程（real-time process） 这些进程需要很强的调度需要，这样的进程不会被低优先级进程阻塞，并且他们的响应时间要尽可能的短 视频音频应用程程序，机器人控制程序以及物理传感器收集数据的程序 交互式进程（interactive process） 此类进程经常与用户进行交互，因此需要花很多时间等待键盘和鼠标操作，当接受了用户输入后，进程必须很快被唤醒，否则用户感觉系统反应迟钝 shell,文本编辑程序和图形应用程序 批处理进程（batch process） 此类进程不必与用户交互，因此经常在后台运行，因为这样的进程不必很快响应，因此常受到调度程序的怠慢 程序语言的编译程序，数据库搜索引擎以及科学计算 在Linux中，调度算法可以明确的确认所有实时进程的身份，但是没办法区分交互式程序和批处理程序，在Linux2.6的调度程序实现了基于进程过去式行为的启发式算法，以确定进程应该被当做交互式进程还是批处理进程，当然与批处理进程相比，调度程序有偏爱交互式进程的倾向。 1.3 不同进程采用不同的调度策略 根据进程的不同分类Linux采用不同的调度策略。 对于实时进程，采用FIFO或者Round Robin的调度策略。 对于普通进程，则需要区分交互式和批处理式的不同。传统Linux调度器提高交互式应用的优先级，使得它们能更快地被调度。而CFS和RSDL等新的调度器核心思想是“完全公平”。这个设计理念不仅大大简化了调度器的代码复杂度，还对各种调度需求的提供了更完美的支持。 注意Linux通过将进程和线程调度视为一个，同时包含二者。进程可以看做是单个线程，但是进程可以包含共享一定资源（代码和/或数据）的多个线程。因此进程调度也包含了线程调度的功能。 目前实时进程的调度策略比较简单, 因为实时进程值只要求尽可能快的被响应, 基于优先级, 每个进程根据它重要程度的不同被赋予不同的优先级，调度器在每次调度时, 总选择优先级最高的进程开始执行. 低优先级不可能抢占高优先级, 因此FIFO或者Round Robin的调度策略即可满足实时进程调度的需求. 但是普通进程的调度策略就比较麻烦了, 因为普通进程不能简单的只看优先级, 必须公平的占有CPU, 否则很容易出现进程饥饿, 这种情况下用户会感觉操作系统很卡, 响应总是很慢，因此在linux调度器的发展历程中经过了多次重大变动, linux总是希望寻找一个最接近于完美的调度策略来公平快速的调度进程. 1.4 Linux调度器的演变 一开始的调度器是复杂度为O(n)的调度算法（实际上每次遍历所有任务，所以复杂度为O(n)），这个算法的缺点是当内核中有很多任务时，调度器本身就会耗费不少时间，所以，从Linux2.5开始引入了赫赫有名O(1)的调度器。 然而，linux是集全球很多程序员的聪明才智而发展起来的超级内核，没有最好，只有更好，在O(1)调度器风光了没几天就又被另一个更优秀的调度器取代了，它就是CFS调度器Completely Fair Scheduler. 这个也是在2.6内核中引入的，具体为2.6.23，即从此版本开始，内核使用CFS作为它的默认调度器，O(1)调度器被抛弃了。 所以完全有理由相信，后续如果再会出现一个更优秀的调度器，CFS也不会幸免。因为linux只要最好的那个。 2. O(n)的始调度算法 2.1 Linux2.4之前的内核调度器 早期的Linux进程调度器使用了最低的设计，它显然不关注具有很多处理器的大型架构，更不用说是超线程了。 Linux调度器使用了环形队列用于可运行的任务管理, 使用循环调度策略. 此调度器添加和删除进程效率很高（具有保护结构的锁）。简而言之，该调度器并不复杂但是简单快捷. Linux版本2.2引入了调度类的概念，允许针对实时任务、非抢占式任务、非实时任务的调度策略。调度器还包括对称多处理 (SMP) 支持。 2.2 Linux2.4的调度器 2.1 概述 在Linux2.4.18中(linux-2.5)之前的内核, 当很多任务都处于活动状态时, 调度器有很明显的限制. 这是由于调度器是使用一个复杂度为O(n)的算法实现的. 调度器采用基于优先级的设计，这个调度器和Linus在1992年发布的调度器没有大的区别。该调度器的pick next算法非常简单：对runqueue中所有进程的优先级进行依次进行比较，选择最高优先级的进程作为下一个被调度的进程。(Runqueue是Linux 内核中保存所有就绪进程的队列)。 pick next用来指从所有候选进程中挑选下一个要被调度的进程的过程。 这种调度算法非常简单易懂: 在每次进程切换时, 内核扫描可运行进程的链表, 计算优先级,然后选择“最佳”进程来运行。 在这种调度器中, 调度任务所花费的时间是一个系统中任务个数的函数. 换而言之, 活动的任务越多, 调度任务所花费的时间越长. 在任务负载非常重时, 处理器会因调度消耗掉大量的时间, 用于任务本身的时间就非常少了。因此，这个算法缺乏可伸缩性 2.2.2 详情 每个进程被创建时都被赋予一个时间片。时钟中断递减当前运行进程的时间片，当进程的时间片被用完时，它必须等待重新赋予时间片才能有机会运行。Linux2.4调度器保证只有当所有RUNNING进程的时间片都被用完之后，才对所有进程重新分配时间片。这段时间被称为一个epoch。这种设计保证了每个进程都有机会得到执行。每个epoch中，每个进程允许执行到其时间切片用完。如果某个进程没有使用其所有的时间切片，那么剩余时间切片的一半将被添加到新时间切片使其在下个epoch中可以执行更长时间。调度器只是迭代进程，应用goodness函数（指标）决定下面执行哪个进程。当然，各种进程对调度的需求并不相同，Linux 2.4调度器主要依靠改变进程的优先级，来满足不同进程的调度需求。事实上，所有后来的调度器都主要依赖修改进程优先级来满足不同的调度需求。 实时进程：实时进程的优先级是静态设定的，而且始终大于普通进程的优先级。因此只有当runqueue中没有实时进程的情况下，普通进程才能够获得调度。 实时进程采用两种调度策略，SCHED_FIFO 和 SCHED_RR。FIFO 采用先进先出的策略，对于所有相同优先级的进程，最先进入 runqueue 的进程总能优先获得调度；Round Robin采用更加公平的轮转策略，使得相同优先级的实时进程能够轮流获得调度。 普通进程：对于普通进程，调度器倾向于提高交互式进程的优先级，因为它们需要快速的用户响应。普通进程的优先级主要由进程描述符中的Counter字段决定 (还要加上nice设定的静态优先级) 。进程被创建时子进程的counter值为父进程counter值的一半，这样保证了任何进程不能依靠不断地fork()子进程从而获得更多的执行机会。 Linux2.4调度器是如何提高交互式进程的优先级的呢？如前所述，当所有 RUNNING 进程的时间片被用完之后，调度器将重新计算所有进程的 counter 值，所有进程不仅包括 RUNNING 进程，也包括处于睡眠状态的进程。处于睡眠状态的进程的 counter 本来就没有用完，在重新计算时，他们的 counter 值会加上这些原来未用完的部分，从而提高了它们的优先级。交互式进程经常因等待用户输入而处于睡眠状态，当它们重新被唤醒并进入 runqueue 时，就会优先于其它进程而获得 CPU。从用户角度来看，交互式进程的响应速度就提高了。 该调度器的主要缺点： 可扩展性不好调度器选择进程时需要遍历整个 runqueue 从中选出最佳人选，因此该算法的执行时间与进程数成正比。另外每次重新计算 counter 所花费的时间也会随着系统中进程数的增加而线性增长，当进程数很大时，更新 counter 操作的代价会非常高，导致系统整体的性能下降。 高负载系统上的调度性能比较低2.4的调度器预分配给每个进程的时间片比较大，因此在高负载的服务器上，该调度器的效率比较低，因为平均每个进程的等待时间于该时间片的大小成正比。 交互式进程的优化并不完善Linux2.4识别交互式进程的原理基于以下假设，即交互式进程比批处理进程更频繁地处于SUSPENDED状态。然而现实情况往往并非如此，有些批处理进程虽然没有用户交互，但是也会频繁地进行IO操作，比如一个数据库引擎在处理查询时会经常地进行磁盘IO，虽然它们并不需要快速地用户响应，还是被提高了优先级。当系统中这类进程的负载较重时，会影响真正的交互式进程的响应时间。 对实时进程的支持不够Linux2.4内核是非抢占的，当进程处于内核态时不会发生抢占，这对于真正的实时应用是不能接受的。 为了解决这些问题，Ingo Molnar开发了新的O(1)调度器，在CFS和RSDL之前，这个调度器不仅被Linux2.6采用，还被backport到Linux2.4中，很多商业的发行版本都采用了这个调度器 3. O(1)的调度算法 3.1 概述 由于进程优先级的最大值为139，因此MAX_PRIO的最大值取140(具体的是，普通进程使用100到139的优先级，实时进程使用0到99的优先级). 因此，该调度算法为每个优先级都设置一个可运行队列, 即包含140个可运行状态的进程链表，每一条优先级链表上的进程都具有相同的优先级，而不同进程链表上的进程都拥有不同的优先级。 除此之外, 还包括一个优先级位图bitmap。该位图使用一个位(bit)来代表一个优先级，而140个优先级最少需要5个32位来表示， 因此只需要一个int[5]就可以表示位图，该位图中的所有位都被置0，当某个优先级的进程处于可运行状态时，该优先级所对应的位就被置1。 如果确定了优先级，那么选取下一个进程就简单了，只需在queue数组中对应的链表上选取一个进程即可。 最后，在早期的内核中，抢占是不可能的；这意味着如果有一个低优先级的任务在执行，高优先级的任务只能等待它完成。 3.2 详情 从名字就可以看出O(1)调度器主要解决了以前版本中的扩展性问题。 O(1)调度算法所花费的时间为常数，与当前系统中的进程个数无关。 此外Linux 2.6内核支持内核态抢占，因此更好地支持了实时进程。 相对于前任，O(1)调度器还更好地区分了交互式进程和批处理式进程。 Linux 2.6内核也支持三种调度策略。其中SCHED_FIFO和SCHED_RR用于实时进程，而SCHED_NORMAL用于普通进程。 O(1)调度器在两个方面修改了Linux 2.4调度器，一是进程优先级的计算方法；二是pick next算法。 O(1)调度器跟踪运行队列中可运行的任务（实际上，每个优先级水平有两个运行队列，一个用于活动任务，一个用于过期任务）， 这意味着要确定接下来执行的任务，调度器只需按优先级将下一个任务从特定活动的运行队列中取出即可。 3.2.1 普通进程的优先级计算 不同类型的进程应该有不同的优先级。每个进程与生俱来（即从父进程那里继承而来）都有一个优先级，我们将其称为静态优先级。普通进程的静态优先级范围从100到139，100为最高优先级，139 为最低优先级，0－99保留给实时进程。当进程用完了时间片后，系统就会为该进程分配新的时间片（即基本时间片），静态优先级本质上决定了时间片分配的大小。 静态优先级和基本时间片的关系如下： 静态优先级&lt;120，基本时间片=max((140-静态优先级)20,MIN_TIMESLICE)静态优先级&gt;=120，基本时间片=max((140-静态优先级)5,MIN_TIMESLICE) 其中MIN_TIMESLICE为系统规定的最小时间片。从该计算公式可以看出，静态优先级越高（值越低），进程得到的时间片越长。其结果是，优先级高的进程会获得更长的时间片，而优先级低的进程得到的时间片则较短。进程除了拥有静态优先级外，还有动态优先级，其取值范围是100到139。当调度程序选择新进程运行时就会使用进程的动态优先级，动态优先级和静态优先级的关系可参考下面的公式： 动态优先级=max(100，min(静态优先级-bonus+5)，139) 从上面看出，动态优先级的生成是以静态优先级为基础，再加上相应的惩罚或奖励(bonus)。这个bonus并不是随机的产生，而是根据进程过去的平均睡眠时间做相应的惩罚或奖励。 所谓平均睡眠时间（sleep_avg，位于task_struct结构中）就是进程在睡眠状态所消耗的总时间数，这里的平均并不是直接对时间求平均数。平均睡眠时间随着进程的睡眠而增长，随着进程的运行而减少。因此，平均睡眠时间记录了进程睡眠和执行的时间，它是用来判断进程交互性强弱的关键数据。如果一个进程的平均睡眠时间很大，那么它很可能是一个交互性很强的进程。反之，如果一个进程的平均睡眠时间很小，那么它很可能一直在执行。另外，平均睡眠时间也记录着进程当前的交互状态，有很快的反应速度。比如一个进程在某一小段时间交互性很强，那么sleep_avg就有可能暴涨（当然它不能超过 MAX_SLEEP_AVG），但如果之后都一直处于执行状态，那么sleep_avg就又可能一直递减。理解了平均睡眠时间，那么bonus的含义也就显而易见了。交互性强的进程会得到调度程序的奖励（bonus为正），而那些一直霸占CPU的进程会得到相应的惩罚（bonus为负）。其实bonus相当于平均睡眠时间的缩影，此时只是将sleep_avg调整成bonus数值范围内的大小。可见平均睡眠时间可以用来衡量进程是否是一个交互式进程。如果满足下面的公式，进程就被认为是一个交互式进程： 动态优先级≤3*静态优先级/4 + 28 平均睡眠时间是进程处于等待睡眠状态下的时间，该值在进程进入睡眠状态时增加，而进入RUNNING状态后则减少。该值的更新时机分布在很多内核函数内：时钟中断scheduler_tick()；进程创建；进程从TASK_INTERRUPTIBLE状态唤醒；负载平衡等。 3.2.2 实时进程的优先级计算 实时进程的优先级由sys_sched_setschedule()设置。该值不会动态修改，而且总是比普通进程的优先级高。在进程描述符中用rt_priority域表示。 3.2.3 pick next算法 普通进程的调度选择算法基于进程的优先级，拥有最高优先级的进程被调度器选中。 Linux2.4中，时间片counter同时也表示了一个进程的优先级。Linux2.6中时间片用任务描述符中的time_slice域表示，而优先级用prio（普通进程）或者rt_priority（实时进程）表示。调度器为每一个CPU维护了两个进程队列数组：指向活动运行队列的active数组和指向过期运行队列的expire数组。数组中的元素着保存某一优先级的进程队列指针。系统一共有140个不同的优先级，因此这两个数组大小都是140。它们是按照先进先出的顺序进行服务的。被调度执行的任务都会被添加到各自运行队列优先级列表的末尾。每个任务都有一个时间片，这取决于系统允许执行这个任务多长时间。运行队列的前100个优先级列表保留给实时任务使用，后40个用于用户任务，参见下图： 当需要选择当前最高优先级的进程时，2.6调度器不用遍历整个runqueue，而是直接从active数组中选择当前最高优先级队列中的第一个进程。假设当前所有进程中最高优先级为50（换句话说，系统中没有任何进程的优先级小于50）。则调度器直接读取 active[49]，得到优先级为50的进程队列指针。该队列头上的第一个进程就是被选中的进程。这种算法的复杂度为O(1)，从而解决了2.4调度器的扩展性问题。为了实现O(1)算法active数组维护了一个由5个32位的字（140个优先级）组成的bitmap，当某个优先级别上有进程被插入列表时，相应的比特位就被置位。 sched_find_first_bit()函数查询该bitmap，返回当前被置位的最高优先级的数组下标。在上例中sched_find_first_bit函数将返回49。在IA处理器上可以通过bsfl等指令实现。可见查找一个任务来执行所需要的时间并不依赖于活动任务的个数，而是依赖于优先级的数量。这使得 2.6 版本的调度器成为一个复杂度为 O(1) 的过程，因为调度时间既是固定的，而且也不会受到活动任务个数的影响。 为了提高交互式进程的响应时间，O(1)调度器不仅动态地提高该类进程的优先级，还采用以下方法：每次时钟tick中断时，进程的时间片(time_slice)被减一。当time_slice为0时，表示当前进程的时间片用完，调度器判断当前进程的类型，如果是交互式进程或者实时进程，则重置其时间片并重新插入active数组。如果不是交互式进程则从active数组中移到expired数组，并根据上述公式重新计算时间片。这样实时进程和交互式进程就总能优先获得CPU。然而这些进程不能始终留在active数组中，否则进入expire数组的进程就会产生饥饿现象。当进程已经占用CPU时间超过一个固定值后，即使它是实时进程或者交互式进程也会被移到expire数组中。当active数组中的所有进程都被移到expire数组中后，调度器交换active数组和expire数组。因此新的active数组又恢复了初始情况，而expire数组为空，从而开始新的一轮调度。 Linux 2.6调度器改进了前任调度器的可扩展性问题，schedule()函数的时间复杂度为O(1)。这取决于两个改进： pick next算法借助于active数组，无需遍历runqueue； 消了定期更新所有进程counter的操作，动态优先级的修改分布在进程切换，时钟tick中断以及其它一些内核函数中进行。 为了解决O(1)调度器面临的问题以及应对其他外部压力, 需要改变某些东西。这种改变来自Con Kolivas的内核补丁staircase scheduler（楼梯调度算法），以及改进的RSDL（Rotating Staircase Deadline Scheduler）。它为调度器设计提供了一个新的思路。Ingo Molnar在RSDL之后开发了CFS，并最终被2.6.23内核采用。接下来我们开始介绍这些新一代调度器。 4. Linux 2.6的新一代调度器CFS 4.1 楼梯调度算法staircase scheduler 楼梯算法(SD)在思路上和O(1)算法有很大不同，它抛弃了动态优先级的概念。而采用了一种完全公平的思路。前任算法的主要复杂性来自动态优先级的计算，调度器根据平均睡眠时间和一些很难理解的经验公式来修正进程的优先级以及区分交互式进程。这样的代码很难阅读和维护。楼梯算法思路简单，但是实验证明它对应交互式进程的响应比其前任更好，而且极大地简化了代码。 和O(1)算法一样，楼梯算法也同样为每一个优先级维护一个进程列表，并将这些列表组织在active数组中。当选取下一个被调度进程时，SD算法也同样从active数组中直接读取。与O(1)算法不同在于，当进程用完了自己的时间片后，并不是被移到expire数组中。而是被加入active数组的低一优先级列表中，即将其降低一个级别。不过请注意这里只是将该任务插入低一级优先级任务列表中，任务本身的优先级并没有改变。当时间片再次用完，任务被再次放入更低一级优先级任务队列中。就象一部楼梯，任务每次用完了自己的时间片之后就下一级楼梯。任务下到最低一级楼梯时，如果时间片再次用完，它会回到初始优先级的下一级任务队列中。比如某进程的优先级为1，当它到达最后一级台阶140后，再次用完时间片时将回到优先级为2的任务队列中，即第二级台阶。不过此时分配给该任务的time_slice将变成原来的2倍。比如原来该任务的时间片time_slice为10ms，则现在变成了20ms。基本的原则是，当任务下到楼梯底部时，再次用完时间片就回到上次下楼梯的起点的下一级台阶。并给予该任务相同于其最初分配的时间片。总结如下：设任务本身优先级为P，当它从第N级台阶开始下楼梯并到达底部后，将回到第N+1级台阶。并且赋予该任务N+1倍的时间片。 以上描述的是普通进程的调度算法，实时进程还是采用原来的调度策略，即FIFO或者Round Robin。 楼梯算法能避免进程饥饿现象，高优先级的进程会最终和低优先级的进程竞争，使得低优先级进程最终获得执行机会。对于交互式应用，当进入睡眠状态时，与它同等优先级的其他进程将一步一步地走下楼梯，进入低优先级进程队列。当该交互式进程再次唤醒后，它还留在高处的楼梯台阶上，从而能更快地被调度器选中，加速了响应时间。 楼梯算法的优点：从实现角度看，SD基本上还是沿用了O(1)的整体框架，只是删除了O(1)调度器中动态修改优先级的复杂代码；还淘汰了expire数组，从而简化了代码。它最重要的意义在于证明了完全公平这个思想的可行性。 4.2 RSLD(Rotating Staircase Deadline Scheduler) RSDL也是由Con Kolivas开发的，它是对SD算法的改进。核心的思想还是”完全公平”。没有复杂的动态优先级调整策略。RSDL重新引入了expire数组。它为每一个优先级都分配了一个 “组时间配额”，记为Tg；同一优先级的每个进程都拥有同样的”优先级时间配额”，用Tp表示。当进程用完了自身的Tp时，就下降到下一优先级进程组中。这个过程和SD相同，在RSDL中这个过程叫做minor rotation（次轮询）。请注意Tp不等于进程的时间片，而是小于进程的时间片。下图表示了minor rotation。进程从priority1的队列中一步一步下到priority140之后回到priority2的队列中，这个过程如下图左边所示，然后从priority 2开始再次一步一步下楼，到底后再次反弹到priority3队列中，如下图所示。 在SD算法中，处于楼梯底部的低优先级进程必须等待所有的高优先级进程执行完才能获得CPU。因此低优先级进程的等待时间无法确定。RSDL中，当高优先级进程组用完了它们的Tg(即组时间配额)时，无论该组中是否还有进程Tp尚未用完，所有属于该组的进程都被强制降低到下一优先级进程组中。这样低优先级任务就可以在一个可以预计的未来得到调度。从而改善了调度的公平性。这就是RSDL中Deadline代表的含义。进程用完了自己的时间片time_slice时（下图中T2），将放入expire数组指向的对应初始优先级队列中(priority 1)。 当active数组为空，或者所有的进程都降低到最低优先级时就会触发主轮询major rotation。Major rotation交换active数组和expire数组，所有进程都恢复到初始状态，再一次从新开始minor rotation的过程。RSDL对交互式进程的支持：和SD同样的道理，交互式进程在睡眠时间时，它所有的竞争者都因为minor rotation而降到了低优先级进程队列中。当它重新进入RUNNING状态时，就获得了相对较高的优先级，从而能被迅速响应。 4.3 安全公平的调度器CFS CFS是最终被内核采纳的调度器。它从RSDL/SD中吸取了完全公平的思想，不再跟踪进程的睡眠时间，也不再企图区分交互式进程。它将所有的进程都统一对待，这就是公平的含义。CFS的算法和实现都相当简单，众多的测试表明其性能也非常优越。按照作者Ingo Molnar的说法（参考Documentation/scheduler/sched-design-CFS.txt）， CFS百分之八十的工作可以用一句话概括：CFS在真实的硬件上模拟了完全理想的多任务处理器。在真空的硬件上，同一时刻我们只能运行单个进程，因此当一个进程占用CPU时，其它进程就必须等待，这就产生了不公平。但是在“完全理想的多任务处理器 “下，每个进程都能同时获得CPU的执行时间，即并行地每个进程占1/nr_running的时间。例如当系统中有两个进程时，CPU的计算时间被分成两份，每个进程获得50%。假设runqueue中有n个进程，当前进程运行了10ms。在“完全理想的多任务处理器”中，10ms应该平分给n个进程(不考虑各个进程的nice值)，因此当前进程应得的时间是(10/n)ms，但是它却运行了10ms。所以CFS将惩罚当前进程，使其它进程能够在下次调度时尽可能取代当前进程。最终实现所有进程的公平调度。 与之前的Linux调度器不同，CFS没有将任务维护在链表式的运行队列中，它抛弃了active/expire数组，而是对每个CPU维护一个以时间为顺序的红黑树。 该树方法能够良好运行的原因在于： 红黑树可以始终保持平衡，这意味着树上没有路径比任何其他路径长两倍以上。 由于红黑树是二叉树，查找操作的时间复杂度为O(log n)。但是除了最左侧查找以外，很难执行其他查找，并且最左侧的节点指针始终被缓存。 对于大多数操作（插入、删除、查找等），红黑树的执行时间为O(log n)，而以前的调度程序通过具有固定优先级的优先级数组使用 O(1)。O(log n) 行为具有可测量的延迟，但是对于较大的任务数无关紧要。Molnar在尝试这种树方法时，首先对这一点进行了测试。 红黑树可通过内部存储实现，即不需要使用外部分配即可对数据结构进行维护。 要实现平衡，CFS使用”虚拟运行时”表示某个任务的时间量。任务的虚拟运行时越小，意味着任务被允许访问服务器的时间越短，其对处理器的需求越高。CFS还包含睡眠公平概念以便确保那些目前没有运行的任务（例如，等待 I/O）在其最终需要时获得相当份额的处理器。 4.3.1 CFS如何实现pick next 下图是一个红黑树的例子 所有可运行的任务通过不断地插入操作最终都存储在以时间为顺序的红黑树中（由 sched_entity 对象表示），对处理器需求最多的任务（最低虚拟运行时）存储在树的左侧，处理器需求最少的任务（最高虚拟运行时）存储在树的右侧。 为了公平，CFS调度器会选择红黑树最左边的叶子节点作为下一个将获得cpu的任务。这样，树左侧的进程就被给予时间运行了。 4.3.2 tick中断 在CFS中，tick中断首先更新调度信息。然后调整当前进程在红黑树中的位置。调整完成后如果发现当前进程不再是最左边的叶子，就标记need_resched标志，中断返回时就会调用scheduler()完成进程切换。否则当前进程继续占用CPU。从这里可以看到 CFS抛弃了传统的时间片概念。Tick中断只需更新红黑树，以前的所有调度器都在tick中断中递减时间片，当时间片或者配额被用完时才触发优先级调整并重新调度。 4.3.3 红黑树键值计算 理解CFS的关键就是了解红黑树键值的计算方法。该键值由三个因子计算而得：一是进程已经占用的CPU时间；二是当前进程的nice值；三是当前的cpu负载。进程已经占用的CPU时间对键值的影响最大，其实很大程度上我们在理解CFS时可以简单地认为键值就等于进程已占用的 CPU时间。因此该值越大，键值越大，从而使得当前进程向红黑树的右侧移动。另外CFS规定，nice值为1的进程比nice值为0的进程多获得10%的 CPU时间。在计算键值时也考虑到这个因素，因此nice值越大，键值也越大。 CFS为每个进程都维护两个重要变量：fair_clock和wait_runtime。这里我们将为每个进程维护的变量称为进程级变量，为每个CPU维护的称作CPU级变量，为每个runqueue维护的称为runqueue级变量。进程插入红黑树的键值即为fair_clock – wait_runtime。其中fair_clock从其字面含义上讲就是一个进程应获得的CPU时间，即等于进程已占用的CPU时间除以当前 runqueue中的进程总数；wait_runtime是进程的等待时间。它们的差值代表了一个进程的公平程度。该值越大，代表当前进程相对于其它进程越不公平。对于交互式任务，wait_runtime长时间得不到更新，因此它能拥有更高的红黑树键值，更靠近红黑树的左边。从而得到快速响应。 红黑树是平衡树，调度器每次总最左边读出一个叶子节点，该读取操作的时间复杂度是O(LogN) 4.3.4 调度器管理器 为了支持实时进程，CFS提供了调度器模块管理器。各种不同的调度器算法都可以作为一个模块注册到该管理器中。不同的进程可以选择使用不同的调度器模块。2.6.23中，CFS实现了两个调度算法，CFS算法模块和实时调度模块。对应实时进程，将使用实时调度模块。对应普通进程则使用CFS算法。CFS 调度模块（在 kernel/sched_fair.c 中实现）用于以下调度策略：SCHED_NORMAL、SCHED_BATCH 和 SCHED_IDLE。对于 SCHED_RR 和 SCHED_FIFO 策略，将使用实时调度模块（该模块在 kernel/sched_rt.c 中实现）。 4.3.5 CFS组调度 CFS组调度（在 2.6.24 内核中引入）是另一种为调度带来公平性的方式，尤其是在处理产生很多其他任务的任务时。 假设一个产生了很多任务的服务器要并行化进入的连接（HTTP 服务器的典型架构）。不是所有任务都会被统一公平对待， CFS 引入了组来处理这种行为。产生任务的服务器进程在整个组中（在一个层次结构中）共享它们的虚拟运行时，而单个任务维持其自己独立的虚拟运行时。这样单个任务会收到与组大致相同的调度时间。您会发现 /proc 接口用于管理进程层次结构，让您对组的形成方式有完全的控制。使用此配置，您可以跨用户、跨进程或其变体分配公平性。 考虑一个两用户示例，用户 A 和用户 B 在一台机器上运行作业。用户 A 只有两个作业正在运行，而用户 B 正在运行 48 个作业。组调度使 CFS 能够对用户 A 和用户 B 进行公平调度，而不是对系统中运行的 50 个作业进行公平调度。每个用户各拥有 50% 的 CPU 使用。用户 B 使用自己 50% 的 CPU 分配运行他的 48 个作业，而不会占用属于用户 A 的另外 50% 的 CPU 分配。]]></content>
  </entry>
  <entry>
    <title><![CDATA[构建实现run命令的容器]]></title>
    <url>%2F2019%2F04%2F24%2Fwrite-docker-run%2F</url>
    <content type="text"><![CDATA[实现run命令 构建一个简单版本的run命令，类似于docker run -it [command]，为了了解Docker启动容器的原理，该简单版本的实现参考了runC的实现。 1.目前的代码文件结构如下：12345678.├── container│ ├── container_process.go│ └── init.go├── main_command.go├── main.go├── README.md└── run.go 2.首先，来看一下入口main文件123456789101112131415161718192021222324252627282930313233package mainimport ( &quot;github.com/urfave/cli&quot; &quot;github.com/Sirupsen/logrus&quot; &quot;os&quot;)const usage = `my docker is a simple container runtime implement`//mydocker run -it /bin/bashfunc main() &#123; app := cli.NewApp() app.Name = &quot;mydocker&quot; app.Usage = usage app.Commands = []cli.Command&#123; initCommand, runCommand, &#125; //设置日志格式 app.Before = func(context *cli.Context) error &#123; logrus.SetFormatter(&amp;logrus.JSONFormatter&#123;&#125;) logrus.SetOutput(os.Stdout) return nil; &#125; if err := app.Run(os.Args); err != nil &#123; logrus.Fatal(err) &#125;&#125; 使用 github.com/urfave/cli 提供的命令行工具, 该工具的用法, 点此。定义mydocker的两个基本命令,initCommand和runCommand，在app.Before内初始化一下logrus的日志配置。下面看一下，具命令的定义。 3.runCommand &amp; initCommand 定义123456789101112131415161718192021222324252627282930313233343536373839404142434445//这里定义`runCommand`的`Flags`，其作用类似于命令时使用 -- 来指定参数var runCommand = cli.Command&#123; Name: &quot;run&quot;, Usage: `Create a container with namespace and cgroups limit mydocker run -it [command]`, Flags: []cli.Flag&#123; cli.BoolFlag&#123; Name: &quot;it&quot;, Usage: &quot;enable tty&quot;, &#125;, &#125;, /** 这里是run命令执行的真正函数 1. 判断参数是否包含command 2. 获取用户指定的command 3. 调用 Run function 去准备启动容器 */ Action: func(context *cli.Context) error &#123; if len(context.Args()) &lt; 1 &#123; return fmt.Errorf(&quot;Missing container command&quot;) &#125; cmd := context.Args().Get(0) tty := context.Bool(&quot;it&quot;) Run(tty, cmd) return nil &#125;,&#125;//定义initCommand的具体操作，此操作为内部方法，禁止外部调用var initCommand = cli.Command&#123; Name: &quot;init&quot;, Usage: &quot;Init container process run user&apos;s process in container, Do not call it outside&quot;, /** 1.获取传递过来的command参数 2.执行容器初始化操作 */ Action: func(context *cli.Context) error &#123; logrus.Infof(&quot;init come on&quot;) cmd := context.Args().Get(0) logrus.Infof(&quot;command %s&quot;, cmd) err := container.RunContainerInitProcess(cmd, nil) return err &#125;,&#125; 4.先来看一下Run和NewParentProcess做了哪些事情。这里是父进程，也就是当前进程执行的内容。 这里的/proc/self/exe的调用中，/proc/self指的是当前运行进程自己的环境，exec其实就是自己调用了自己，使用这种方式对创建出来的进程初始化。 后面的args是参数，其中init是传递给本进程的第一个参数，在本例中，其实就会去调用initCommand去初始化进程的一些环境和资源。./mydocker init [command] 下面的clone参数就是去fork出来一个新的进程，并且使用了namespace隔离新创建的进程和外部环境。 如果用户指定了 -it 参数，就需要把当前进程的输入输出导入到标准的输入输出上 12345678910111213141516171819202122// conatiner_process.gopackage containerimport ( &quot;os/exec&quot; &quot;syscall&quot; &quot;os&quot;)func NewParentProcess(tty bool, command string) *exec.Cmd &#123; args := []string&#123;&quot;init&quot;, command&#125; cmd := exec.Command(&quot;/proc/self/exe&quot;, args...) cmd.SysProcAttr = &amp;syscall.SysProcAttr&#123; Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS | syscall.CLONE_NEWNET | syscall.CLONE_NEWIPC, &#125; if tty &#123; cmd.Stdin = os.Stdout cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr &#125; return cmd&#125; 123456789101112131415161718// run.gopackage mainimport ( &quot;mydocker/container&quot; &quot;github.com/Sirupsen/logrus&quot; &quot;os&quot;)//启动init进程func Run(tty bool, command string) &#123; parent := container.NewParentProcess(tty, command) if err := parent.Run(); err != nil &#123; logrus.Error(err) &#125; parent.Wait() os.Exit(-1)&#125; 5.那么init函数里面发生了什么呢？ 这里的init函数是在容器内执行的，也就是说代码执行到这里，容器所在的进程其实已经创建出来了，这是本容器执行的第一个进程。 使用mount先去挂载proc文件系统，以便后面通过ps命令去查看当前容器内进程情况。 12345678910111213141516171819// init.go package containerimport ( &quot;github.com/Sirupsen/logrus&quot; &quot;syscall&quot; &quot;os&quot;)func RunContainerInitProcess(command string, args []string) error &#123; logrus.Infof(&quot;command %s&quot;, command) defaultMountFlags := syscall.MS_NOEXEC | syscall.MS_NOSUID | syscall.MS_NODEV syscall.Mount(&quot;proc&quot;, &quot;/proc&quot;, &quot;proc&quot;, uintptr(defaultMountFlags), &quot;&quot;) argv := []string&#123;command&#125; if err := syscall.Exec(command, argv, os.Environ()); err != nil &#123; logrus.Errorf(err.Error()) &#125; return nil&#125; 这里MountFlag意思如下： MS_NOEXEC在本文件系统中不允许运行其它程序 MS_NOSUID在本文件系统中运行程序的时候，不允许set-user-ID或set-group-ID MS_NODEV这个参数自Linux2.4以来，所有mount的系统都会默认设定的 本函数最后的syscall.Exec，这个系统调用实现了完成初始化并将用户进程运行起来的操作。下面解释一下这句话的神奇之处。 首先，使用Docker创建起来一个容器后，会发现容器内的第一个进程，也就是PID为1的那个进程，是指定的前台进程。但是，根据前面所讲，容器启动后的第一个进程不是用户进程，而是init初始化的进程。这个时候通过ps命令就会发现，容器内的第一进程变成了自己的init，这个和预想的不一样。你可能回想，大不了把第一个init进程给kill掉。但是PID为1的进程是不能被kill掉的，如果该进程被kill掉，我们的容器也就退出了。那么有什么办法？这里execve系统调用就可以大显神威了。 syscall.Exec这个方法，其实最终调用了Kernel的int execve(const char filename,const const argv[],char *const envp[]);这个系统函数。它的作用是执行当前的filename对应的程序，会覆盖当前进程的镜像、数据和堆栈等信息，包括PID，这些都会将要运行的进程覆盖掉。也就是说，调用这个方法，将用户指定的进程运行起来，把最初的init进程给替换掉，这样当进入到容器内部的时候，就会发现容器内的第一个程序就是我们指定的进程了[command]。这其实也是目前Docker使用的容器引擎runC的实现方式之一。 6.流程图如图所示: 图1：mydocker 启动流程 7.下面编译运行一下。 #使用 go build，在mydocker目录下进行编译 #使用 ./mydocker run -it /bin/sh 命令，其中 -it 表示想要以交互的形式运行容器， /bin/bash 为指定容器的第一个进程。12345678root@ubuntu1:/home/meichaofan/peek-a-boo/src/mydocker# ./mydocker run -it /bin/sh&#123;&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;init come on&quot;,&quot;time&quot;:&quot;2019-04-24T21:09:35-07:00&quot;&#125;&#123;&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;command /bin/sh&quot;,&quot;time&quot;:&quot;2019-04-24T21:09:35-07:00&quot;&#125;&#123;&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;command /bin/sh&quot;,&quot;time&quot;:&quot;2019-04-24T21:09:35-07:00&quot;&#125;# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.0 4508 756 pts/0 S 21:09 0:00 /bin/shroot 5 0.0 0.1 39104 3188 pts/0 R+ 21:09 0:00 ps aux 在容器运行 ps -aux 时，可以发现 /bin/sh 进程是容器内的第一个进程，PID=1。而 ps -aux 是PID为1的进程创建出来的。 这里的 /bin/sh 是一个会在前台一直运行的进程。如果指定一个运行就退出的进程会是什么效果。12345root@ubuntu1:/home/meichaofan/peek-a-boo/src/mydocker# ./mydocker run -it /bin/ls&#123;&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;init come on&quot;,&quot;time&quot;:&quot;2019-04-24T21:19:05-07:00&quot;&#125;&#123;&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;command /bin/ls&quot;,&quot;time&quot;:&quot;2019-04-24T21:19:05-07:00&quot;&#125;&#123;&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;command /bin/ls&quot;,&quot;time&quot;:&quot;2019-04-24T21:19:05-07:00&quot;&#125;container main_command.go main.go mydocker README.md run.go 由于没有chroot，所以目前的系统文件是继承宿主主机的系统文件，运行了一下 ls 命令，当容器启动起来以后，打印出了当前目录内容，然后便退出了，这个结果和Docker要求容器必须有一个一直在前台运行的进程的要求是一致的。]]></content>
      <tags>
        <tag>docker</tag>
        <tag>runC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux相关软件和命令]]></title>
    <url>%2F2019%2F04%2F23%2Fabout-linux-software%2F</url>
    <content type="text"><![CDATA[这里主要介绍Linux相关软件安装和日常使用命令 HTTPie - 一款http客户端工具]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPie - 一款http客户端]]></title>
    <url>%2F2019%2F04%2F23%2Fhttpie-a-http-client%2F</url>
    <content type="text"><![CDATA[一款http客户端 主要特点 具表达力和直观语法 格式化的及彩色化的终端输出 内置JSON支持 表单和文件上传 HTTPS、代理和认证 任意请求数据 自定义头部 持久化会话 类似于wget的下载 支持Python2.7 和 3.x 在Linux下安装Httpie Debian/Ubuntu系统，使用apt-get或apt 1$ sudo apt install httpie RHEL/CentOs系统，使用yum安装 1$ sudo yum install httpie 用法 如何使用HTTPie请求URL？httpie的基本用法是将URL作为参数 1234567891011meichaofan@ubuntu1:~$ http 2daygeek.comHTTP/1.1 301 Moved PermanentlyCF-RAY: 4cbdc9a7b85322a0-LAXCache-Control: max-age=3600Connection: keep-aliveDate: Tue, 23 Apr 2019 06:30:15 GMTExpires: Tue, 23 Apr 2019 07:30:15 GMTLocation: https://2daygeek.com/Server: cloudflareTransfer-Encoding: chunkedVary: Accept-Encoding 如何使用HTTPie下载文件带 --download 参数，用来下载文件，类似于wget 123456789101112131415161718192021meichaofan@ubuntu1:~$ http --download https://www.2daygeek.com/wp-content/uploads/2019/04/Anbox-Easy-Way-To-Run-Android-Apps-On-Linux.pngHTTP/1.1 200 OKAccept-Ranges: bytesCF-Cache-Status: HITCF-RAY: 4cbdcfbafb53540e-LAXCache-Control: public, max-age=7200Connection: keep-aliveContent-Length: 32066Content-Type: image/pngDate: Tue, 23 Apr 2019 06:34:23 GMTExpect-CT: max-age=604800, report-uri=&quot;https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct&quot;Expires: Tue, 23 Apr 2019 08:34:23 GMTLast-Modified: Mon, 08 Apr 2019 04:54:25 GMTServer: cloudflareSet-Cookie: __cfduid=dee8965dcfafc633c5463965e0c40522d1556001263; expires=Wed, 22-Apr-20 06:34:23 GMT; path=/; domain=.2daygeek.com; HttpOnly; SecureVary: Accept-EncodingDownloading 31.31 kB to &quot;Anbox-Easy-Way-To-Run-Android-Apps-On-Linux.png&quot;Done. 31.31 kB in 0.55747s (56.17 kB/s)meichaofan@ubuntu1:~$ lsAnbox-Easy-Way-To-Run-Android-Apps-On-Linux.png package peek-a-boo 你还可以使用 -o 参数用不同的名称保存输出文件。 123456789101112131415161718192021meichaofan@ubuntu1:~$ http --download https://www.2daygeek.com/wp-content/uploads/2019/04/Anbox-Easy-Way-To-Run-Android-Apps-On-Linux.png -o Anbox-1.pngHTTP/1.1 200 OKAccept-Ranges: bytesCF-Cache-Status: HITCF-RAY: 4cbdd1493c0e5047-LAXCache-Control: public, max-age=7200Connection: keep-aliveContent-Length: 32066Content-Type: image/pngDate: Tue, 23 Apr 2019 06:35:27 GMTExpect-CT: max-age=604800, report-uri=&quot;https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct&quot;Expires: Tue, 23 Apr 2019 08:35:27 GMTLast-Modified: Mon, 08 Apr 2019 04:54:25 GMTServer: cloudflareSet-Cookie: __cfduid=d4ac029dc64db0797db8e607d6a8568341556001327; expires=Wed, 22-Apr-20 06:35:27 GMT; path=/; domain=.2daygeek.com; HttpOnly; SecureVary: Accept-EncodingDownloading 31.31 kB to &quot;Anbox-1.png&quot;Done. 31.31 kB in 0.28450s (110.07 kB/s)meichaofan@ubuntu1:~$ lsAnbox-1.png package peek-a-boo 如何使用 HTTPie 恢复部分下载？可以使用 -c 参数的HTTPie继续下载 1http --download --continue https://speed.hetzner.de/100MB.bin -o 100MB.bin 如何使用 HTTPie 上传文件？你可以通过使用带有小于号 &lt; 的 HTTPie 命令上传文件 1$ http https://transfer.sh &lt; Anbox-1.png 如何使用带有重定向符号 &gt; 下载文件？你可以使用带有重定向 &gt; 符号的 HTTPie 命令下载文件。 123$ http https://www.2daygeek.com/wp-content/uploads/2019/03/How-To-Install-And-Enable-Flatpak-Support-On-Linux-1.png &gt; Flatpak.png$ ls -ltrh Flatpak.png-rw-r--r-- 1 root root 47K Apr 9 01:44 Flatpak.png 发送一个 HTTP GET 请求？您可以在请求中发送 HTTP GET 方法。GET 方法会使用给定的 URI，从给定服务器检索信息。 1234567891011http GET httpie.orgHTTP/1.1 301 Moved PermanentlyCF-RAY: 4c4a83a3f90dcbe6-SINCache-Control: max-age=3600Connection: keep-aliveDate: Tue, 09 Apr 2019 06:44:44 GMTExpires: Tue, 09 Apr 2019 07:44:44 GMTLocation: https://httpie.org/Server: cloudflareTransfer-Encoding: chunkedVary: Accept-Encoding 提交表单使用以下格式提交表单。POST 请求用于向服务器发送数据，例如客户信息、文件上传等。要使用 HTML 表单。 12345678910111213http -f POST Ubuntu18.2daygeek.com hello=&apos;World&apos;HTTP/1.1 200 OKAccept-Ranges: bytesConnection: Keep-AliveContent-Encoding: gzipContent-Length: 3138Content-Type: text/htmlDate: Tue, 09 Apr 2019 06:48:12 GMTETag: &quot;2aa6-5844bf1b047fc-gzip&quot;Keep-Alive: timeout=5, max=100Last-Modified: Sun, 17 Mar 2019 15:29:55 GMTServer: Apache/2.4.29 (Ubuntu)Vary: Accept-Encoding 运行下面的指令以查看正在发送的请求。 1234567891011121314151617181920http -v Ubuntu18.2daygeek.comGET / HTTP/1.1Accept: */*Accept-Encoding: gzip, deflateConnection: keep-aliveHost: ubuntu18.2daygeek.comUser-Agent: HTTPie/0.9.8hello=WorldHTTP/1.1 200 OKAccept-Ranges: bytesConnection: Keep-AliveContent-Encoding: gzipContent-Length: 3138Content-Type: text/htmlDate: Tue, 09 Apr 2019 06:48:30 GMTETag: &quot;2aa6-5844bf1b047fc-gzip&quot;Keep-Alive: timeout=5, max=100Last-Modified: Sun, 17 Mar 2019 15:29:55 GMTServer: Apache/2.4.29 (Ubuntu)Vary: Accept-Encoding]]></content>
      <tags>
        <tag>linux</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[介绍urfave/cli 一款构建命令行app的go包]]></title>
    <url>%2F2019%2F04%2F22%2Fintroducing-urfave-cli%2F</url>
    <content type="text"><![CDATA[一个简单，快速构建基于命令行应用的工具包https://github.com/urfave/cli 安装1go get github.com/urfave/cli 使用1.Cli的哲学之一是API应该有趣和充满惊喜，所以cli应用程序可以做到在main()函数里只有一行代码。 1234567891011121314package mainimport ( &quot;github.com/urfave/cli&quot; &quot;os&quot; &quot;log&quot;)func main() &#123; err := cli.NewApp().Run(os.Args) if err != nil &#123; log.Fatal(err) &#125;&#125; 1.1.运行并输出一些默认信息123456789101112131415NAME: one - A new cli applicationUSAGE: one [global options] command [command options] [arguments...]VERSION: 0.0.0COMMANDS: help, h Shows a list of commands or help for one commandGLOBAL OPTIONS: --help, -h show help --version, -v print the version 2.设置执行动作，和输出一些帮助文档1234567891011121314151617181920212223package mainimport ( &quot;github.com/urfave/cli&quot; &quot;fmt&quot; &quot;os&quot; &quot;log&quot;)func main() &#123; app := cli.NewApp() app.Name = &quot;boom&quot; app.Usage = &quot;make an explosive entrance&quot; app.Action = func(c *cli.Context) error &#123; fmt.Println(&quot;boom! I say!&quot;) return nil &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal(err) &#125;&#125; 2.1.编译并运行 go build . &amp;&amp; ./main12meichaofan@ubuntu1:~/peek-a-bow/src/cli/two$ go run main.goboom! I say! 2.2.运行 ./main -h , 可以看到，显示有相关文档12345678910111213141516meichaofan@ubuntu1:~/peek-a-bow/src/cli/two$ ./main -hNAME: boom - make an explosive entranceUSAGE: main [global options] command [command options] [arguments...]VERSION: 0.0.0COMMANDS: help, h Shows a list of commands or help for one commandGLOBAL OPTIONS: --help, -h show help --version, -v print the version 3.支持参数12345678910111213141516171819202122package mainimport ( &quot;github.com/urfave/cli&quot; &quot;fmt&quot; &quot;os&quot; &quot;log&quot;)func main() &#123; app := cli.NewApp() app.Action = func(ctx *cli.Context) error &#123; fmt.Printf(&quot;Hello %q\n&quot;, ctx.Args().Get(0)) return nil &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal(err) &#125;&#125; 3.1.输出12meichaofan@ubuntu1:~/peek-a-bow/src/cli/three$ ./main huanhuanHello &quot;huanhuan&quot; 4.支持标识位 flags123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( &quot;os&quot; &quot;log&quot; &quot;github.com/urfave/cli&quot; &quot;fmt&quot;)func main() &#123; app := cli.NewApp() app.Flags = []cli.Flag&#123; cli.StringFlag&#123; Name: &quot;lang&quot;, Value: &quot;english&quot;, Usage: &quot;language for the greeting&quot;, &#125;, &#125; app.Action = func(ctx *cli.Context) error &#123; name := &quot;huanhuan&quot; if ctx.NArg() &gt; 0 &#123; name = ctx.Args().Get(0) fmt.Printf(&quot;there have %d args&quot;,len(ctx.Args())) &#125; if ctx.String(&quot;lang&quot;) == &quot;spanish&quot; &#123; fmt.Println(&quot;Hala&quot;, name) &#125; else &#123; fmt.Println(&quot;Hello&quot;, name) &#125; return nil &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal(err) &#125;&#125; 4.1.注：Flag和argumens要分清楚 ./main –lang spanish aa bb cc ，其中有3个参数，1个标识123meichaofan@ubuntu1:~/peek-a-bow/src/cli/four$ ./main --lang spanish aa bb ccthere have 3 argsHala aa 5.还可以将flag值注入到变量中，通过变量来判断123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport ( &quot;log&quot; &quot;os&quot; &quot;fmt&quot; &quot;github.com/urfave/cli&quot;)func main() &#123; var language string app := cli.NewApp() app.Flags = []cli.Flag &#123; cli.StringFlag&#123; Name: &quot;lang&quot;, Value: &quot;english&quot;, Usage: &quot;language for the greeting&quot;, Destination: &amp;language, &#125;, &#125; app.Action = func(c *cli.Context) error &#123; name := &quot;someone&quot; if c.NArg() &gt; 0 &#123; name = c.Args()[0] &#125; if language == &quot;spanish&quot; &#123; fmt.Println(&quot;Hola&quot;, name) &#125; else &#123; fmt.Println(&quot;Hello&quot;, name) &#125; return nil &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal(err) &#125;&#125; 6.指定flag的值，这些值的占位符用后引号表示。123456789101112131415161718192021222324package mainimport ( &quot;log&quot; &quot;os&quot; &quot;github.com/urfave/cli&quot;)func main() &#123; app := cli.NewApp() app.Flags = []cli.Flag&#123; cli.StringFlag&#123; Name: &quot;config, c&quot;, Usage: &quot;Load configuration from `FILE`&quot;, &#125;, &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal(err) &#125;&#125; 6.1.我们将会在帮助中看到:1--config FILE, -c FILE Load configuration from FILE]]></content>
      <tags>
        <tag>go</tag>
        <tag>cli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linix之间几种文件传输方式]]></title>
    <url>%2F2019%2F04%2F22%2Ftranfer-in-linux%2F</url>
    <content type="text"><![CDATA[当我们需要在类UNIX主机间，互传文件，下面几个命令可以排上用场了 rsync 1rsync -avz user@src_host:/path/to/file ./ --delete scp]]></content>
  </entry>
  <entry>
    <title><![CDATA[ubuntu]]></title>
    <url>%2F2019%2F04%2F22%2Fabout-ubuntu%2F</url>
    <content type="text"><![CDATA[这是关于Ubuntu系统运维的 ubuntu系统修改网卡ip ubuntu系统修改默认运行级别]]></content>
      <tags>
        <tag>linux</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu系统修改网卡ip]]></title>
    <url>%2F2019%2F04%2F22%2Fchange-ip-on-ubuntu%2F</url>
    <content type="text"><![CDATA[需求：将ubuntu系统ens33网卡ip修改为192.168.244.140 1.编辑/etc/network/interfaces文件 1234567891011meichaofan@ubuntu:~$ cat /etc/network/interfaces# interfaces(5) file used by ifup(8) and ifdown(8)auto loiface lo inet loopback# 新增内容auto ens33iface ens33 inet staticaddress 192.168.244.140netmask 255.255.255.0gateway 192.168.244.2 2.重启网卡 1sudo /etc/init.d/networking restart]]></content>
      <tags>
        <tag>linux</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用docker搭建samba目录共享]]></title>
    <url>%2F2019%2F04%2F22%2Fdocker-run-samba%2F</url>
    <content type="text"><![CDATA[1.下载samba镜像1docker pull dperson/samba 2.启动镜像，具体配置看文档，但重要的配置是一下的注释12345678docker run --name samba \-it -p 139:139 -p 445:445 \-v /home/meichaofan:/home/meichaofan \-v /etc/passwd:/etc/passwd \-v /etc/group:/etc/group \-d dperson/samba \-u &quot;meichaofan;huanhuan0921&quot; \-s &quot;meichaofan home;/home/meichaofan;yes;no;no;all;none&quot; 3.替换samba的启动用户，与权限相关1docker exec -it samba sed -i &apos;s/force user = smbuser/force user = meichaofan/g&apos; /etc/samba/smb.conf 3.替换samba的启动组，与权限相关1docker exec -it samba sed -i &apos;s/force group = users/force group = meichaofan/g&apos; /etc/samba/smb.conf 4.重启samba1docker restart samba]]></content>
      <tags>
        <tag>docker</tag>
        <tag>samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 存储驱动之 overlay]]></title>
    <url>%2F2019%2F04%2F21%2Fdocker-overlay%2F</url>
    <content type="text"></content>
      <tags>
        <tag>docker</tag>
        <tag>overlayFs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 存储驱动之 overlay2]]></title>
    <url>%2F2019%2F04%2F21%2Fdocker-overlay2%2F</url>
    <content type="text"><![CDATA[overlay2中镜像和容器的磁盘结构docker pull ubuntu:14.04下载了包含4层的镜像，12345678[root@www ~]# docker pull ubuntu:14.0414.04: Pulling from library/ubuntue082d4499130: Pull complete 371450624c9e: Pull complete c8a555b3a57c: Pull complete 1456d810d42e: Pull complete Digest: sha256:6612de24437f6f01d6a2988ed9a36b3603df06e8d2c0493678f3ee696bc4bb2dStatus: Downloaded newer image for ubuntu:14.04 可以在/var/lib/docker/overlay2中看到，有5个目录。1234567[root@www overlay2]# ll -htotal 28Kdrwx------ 4 root root 4.0K Apr 21 00:32 0734cd8060d194cf3db93162b421e4f245151920f0b9acda5313ec9f671bc5ccdrwx------ 3 root root 4.0K Apr 21 00:32 153f0c95b638414d41bb07b9d45243a0219719e468dd9dcb097b80f837b4d8b3drwx------ 4 root root 4.0K Apr 21 00:32 658b3e84761843f58ecaf82e1f987bf32d498b7bd54a9cf40bf6bf635fff8ac3drwx------ 4 root root 4.0K Apr 21 00:32 9ff7c96e688b25a7353c83904d791eae357c2e16315ecbe602009678965ce761drwx------ 2 root root 4.0K Apr 21 00:33 l l目录的内容其中l目录中包含了很多软连接，使用短名称指向了其它层。短名称用于避免mount参数时达到页面大小的限制。123456[root@www overlay2]# ll l/total 24lrwxrwxrwx 1 root root 72 Apr 21 00:32 2AQ2F7X67IL4TATXIIYO62CM67 -&gt; ../153f0c95b638414d41bb07b9d45243a0219719e468dd9dcb097b80f837b4d8b3/difflrwxrwxrwx 1 root root 72 Apr 21 00:32 HMOMCX3OAMM4K6KUZORQ7NTIG4 -&gt; ../9ff7c96e688b25a7353c83904d791eae357c2e16315ecbe602009678965ce761/difflrwxrwxrwx 1 root root 72 Apr 21 00:32 JZPHZPG7ZLX7GTKCFVHQZDEF43 -&gt; ../658b3e84761843f58ecaf82e1f987bf32d498b7bd54a9cf40bf6bf635fff8ac3/difflrwxrwxrwx 1 root root 72 Apr 21 00:32 OJ5PMEVISSBQ4X4N2U66YEE6IH -&gt; ../0734cd8060d194cf3db93162b421e4f245151920f0b9acda5313ec9f671bc5cc/diff mount 查看容器/镜像的层次关系现在起一个容器，它会在rootfs层上，加上init层（环境相关）和容器层（读写）1docker run -it ubuntu:14.04 /bin/bash 查看mount相关信息，可以看出层级关系123[root@www ~]# mount -l | grep overlay2/dev/vda1 on /var/lib/docker/overlay2 type ext3 (rw,relatime,data=ordered)overlay on /var/lib/docker/overlay2/bda1eaf86f4c4a500aac2418bc45956531e81de6fff829b67452174c891f5f15/merged type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/MXQORLOJXLIRFVZ3R26TNWWURM:/var/lib/docker/overlay2/l/HMOMCX3OAMM4K6KUZORQ7NTIG4:/var/lib/docker/overlay2/l/OJ5PMEVISSBQ4X4N2U66YEE6IH:/var/lib/docker/overlay2/l/JZPHZPG7ZLX7GTKCFVHQZDEF43:/var/lib/docker/overlay2/l/2AQ2F7X67IL4TATXIIYO62CM67,upperdir=/var/lib/docker/overlay2/bda1eaf86f4c4a500aac2418bc45956531e81de6fff829b67452174c891f5f15/diff,workdir=/var/lib/docker/overlay2/bda1eaf86f4c4a500aac2418bc45956531e81de6fff829b67452174c891f5f15/work) 整理mount信息,如下：123456789101112131415merged: /var/lib/docker/overlay2/bda1eaf86f4c4a500aac2418bc45956531e81de6fff829b67452174c891f5f15/merged (联合挂载到此目录下)workdir: /var/lib/docker/overlay2/bda1eaf86f4c4a500aac2418bc45956531e81de6fff829b67452174c891f5f15/work upperdir: /var/lib/docker/overlay2/bda1eaf86f4c4a500aac2418bc45956531e81de6fff829b67452174c891f5f15/diff (第六层 rw)lowerdir: /var/lib/docker/overlay2/l/MXQORLOJXLIRFVZ3R26TNWWURM (第5层 init层 ro) /var/lib/docker/overlay2/l/HMOMCX3OAMM4K6KUZORQ7NTIG4 (第四层 ro) /var/lib/docker/overlay2/l/OJ5PMEVISSBQ4X4N2U66YEE6IH (第三层 ro) /var/lib/docker/overlay2/l/JZPHZPG7ZLX7GTKCFVHQZDEF43 (第二层 ro) /var/lib/docker/overlay2/l/2AQ2F7X67IL4TATXIIYO62CM67 (rootfs 第一层 ro) 各个rootfs层文件内容介绍查看rootfs第一层的目录信息1234567[root@www ~]# ll /var/lib/docker/overlay2/l/2AQ2F7X67IL4TATXIIYO62CM67lrwxrwxrwx 1 root root 72 Apr 21 00:32 /var/lib/docker/overlay2/l/2AQ2F7X67IL4TATXIIYO62CM67 -&gt; ../153f0c95b638414d41bb07b9d45243a0219719e468dd9dcb097b80f837b4d8b3/diff[root@www ~]# ll /var/lib/docker/overlay2/153f0c95b638414d41bb07b9d45243a0219719e468dd9dcb097b80f837b4d8b3/total 8drwxr-xr-x 21 root root 4096 Apr 21 00:32 diff-rw-r--r-- 1 root root 26 Apr 21 00:32 link 可以看到，最低层只有两个文件，一个是diff，存放当前层的文件和目录，link则和l目录的软链接向对应123456789101112131415161718192021222324[root@www ~]# ll /var/lib/docker/overlay2/153f0c95b638414d41bb07b9d45243a0219719e468dd9dcb097b80f837b4d8b3/difftotal 76drwxr-xr-x 2 root root 4096 Mar 5 12:46 bindrwxr-xr-x 2 root root 4096 Apr 11 2014 bootdrwxr-xr-x 3 root root 4096 Mar 5 12:45 devdrwxr-xr-x 61 root root 4096 Mar 5 12:46 etcdrwxr-xr-x 2 root root 4096 Apr 11 2014 homedrwxr-xr-x 12 root root 4096 Mar 5 12:46 libdrwxr-xr-x 2 root root 4096 Mar 5 12:45 lib64drwxr-xr-x 2 root root 4096 Mar 5 12:45 mediadrwxr-xr-x 2 root root 4096 Apr 11 2014 mntdrwxr-xr-x 2 root root 4096 Mar 5 12:45 optdrwxr-xr-x 2 root root 4096 Apr 11 2014 procdrwx------ 2 root root 4096 Mar 5 12:46 rootdrwxr-xr-x 7 root root 4096 Mar 5 12:46 rundrwxr-xr-x 2 root root 4096 Mar 5 12:46 sbindrwxr-xr-x 2 root root 4096 Mar 5 12:45 srvdrwxr-xr-x 2 root root 4096 Mar 13 2014 sysdrwxrwxrwt 2 root root 4096 Mar 5 12:46 tmpdrwxr-xr-x 10 root root 4096 Mar 5 12:45 usrdrwxr-xr-x 11 root root 4096 Mar 5 12:46 var[root@www ~]# cat /var/lib/docker/overlay2/153f0c95b638414d41bb07b9d45243a0219719e468dd9dcb097b80f837b4d8b3/link 2AQ2F7X67IL4TATXIIYO62CM67 查看rootfs第二层信息12345678[root@www ~]# ll /var/lib/docker/overlay2/l/JZPHZPG7ZLX7GTKCFVHQZDEF43lrwxrwxrwx 1 root root 72 Apr 21 00:32 /var/lib/docker/overlay2/l/JZPHZPG7ZLX7GTKCFVHQZDEF43 -&gt; ../658b3e84761843f58ecaf82e1f987bf32d498b7bd54a9cf40bf6bf635fff8ac3/diff[root@www ~]# ll /var/lib/docker/overlay2/658b3e84761843f58ecaf82e1f987bf32d498b7bd54a9cf40bf6bf635fff8ac3total 16drwxr-xr-x 6 root root 4096 Apr 21 00:32 diff-rw-r--r-- 1 root root 26 Apr 21 00:32 link-rw-r--r-- 1 root root 28 Apr 21 00:32 lowerdrwx------ 2 root root 4096 Apr 21 00:32 work 第二层有四个文件，diff 和 link如上所序一样。lower文件的内容是当前层下面的rootfs的软连接名1234567891011# 第二层rootfs的lower内容[root@www ~]# cat /var/lib/docker/overlay2/658b3e84761843f58ecaf82e1f987bf32d498b7bd54a9cf40bf6bf635fff8ac3/lower l/2AQ2F7X67IL4TATXIIYO62CM67#第三层rootfs的lower内容[root@www ~]# cat /var/lib/docker/overlay2/0734cd8060d194cf3db93162b421e4f245151920f0b9acda5313ec9f671bc5cc/lower l/JZPHZPG7ZLX7GTKCFVHQZDEF43:l/2AQ2F7X67IL4TATXIIYO62CM67#第四层rootfs的lower内容[root@www ~]# cat /var/lib/docker/overlay2/9ff7c96e688b25a7353c83904d791eae357c2e16315ecbe602009678965ce761/lower l/OJ5PMEVISSBQ4X4N2U66YEE6IH:l/JZPHZPG7ZLX7GTKCFVHQZDEF43:l/2AQ2F7X67IL4TATXIIYO62CM67 最顶层，也就是upperdir层，看一下它的文件目录12[root@www bda1eaf86f4c4a500aac2418bc45956531e81de6fff829b67452174c891f5f15]# lsdiff link lower merged work upperdir是容器层，是可读写的。在容器中所有修改文件操作最后都在upperdir的diff目录体现，并合并到merged目录下。merged目录是联合后挂载的目录，也是容器的文件系统。123456789101112131415# 假如我docker run -it ubuntu:14.04 /bin/bash 启动了一个容器，然后再其/(根目录)下创建一个Test目录,并在/root目录下新建了一个aa文件，并删除了/bin/ss文件。我们现在看一下upperdir的`diff`目录[root@www bda1eaf86f4c4a500aac2418bc45956531e81de6fff829b67452174c891f5f15]# tree diff/diff/├── bin│ └── ss├── root│ └── aa└── Test3 directories, 2 files# 在看一个merged目录，它是叠加后一个完整的文件系统目录结构[root@www bda1eaf86f4c4a500aac2418bc45956531e81de6fff829b67452174c891f5f15]# ls merged/bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys Test tmp usr var OverlayFS constructsOverlayFS将单个Linux主机上的两个目录合并成一个目录。这些目录被称为层，统一过程被称为联合挂载。OverlayFS底层目录称为lowerdir， 高层目录称为upperdir。合并统一视图称为merged。当需要修改一个文件时，使用CoW将文件从只读的Lower复制到可写的Upper进行修改，结果也保存在Upper层。在Docker中，底下的只读层就是image，可写层就是Container 下图分层图，镜像层是lowdir，容器层是upperdir，统一的视图层是merged层 OverlayFs constructs]]></content>
      <tags>
        <tag>docker</tag>
        <tag>overlay2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装Docker CE]]></title>
    <url>%2F2019%2F04%2F20%2Finstall-docker%2F</url>
    <content type="text"><![CDATA[官网安装文档 卸载老版本老版本的Docker，以前叫做docker,docker.io和docker-engine，如果系统里安装了它们，就先卸载掉1$ sudo apt-get remove docker docker-engine docker.io containerd runc 支持的存储系统Docker CE在Ubuntu上支持overlay2，aufs,和btrfs文件系统。在Linux内核4.0或更高的内核版本上，默认使用overlay2文件系统，它的性能能高于aufs。如果非要使用aufs，请见配置Docker CE使用aufs文件系统。 安装Docker CE1.使用apt repository添加仓库123456789101112131415161718192021222324252627# 更新 `apt`$ sudo apt-get update# 安装一些必要的软件$ sudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ gnupg-agent \ software-properties-common# 下载Docker官方GPG key$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -# 检验指纹 `9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88`$ sudo apt-key fingerprint 0EBFCD88 pub rsa4096 2017-02-22 [SCEA] 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid [ unknown] Docker Release (CE deb) &lt;docker@docker.com&gt;sub rsa4096 2017-02-22 [S]# 添加仓库$ sudo add-apt-repository \ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable&quot; 安装Docker CE1234567891011121314151617$ sudo apt-get update# 默认安装最新版本$ sudo apt-get install docker-ce docker-ce-cli containerd.io# 可以安装指定版本# 1.查看可用版本$ apt-cache madison docker-ce docker-ce | 5:18.09.1~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:18.09.0~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18.06.1~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 18.06.0~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages ...# 2.安装指定版本$ sudo apt-get install docker-ce=&lt;VERSION_STRING&gt; docker-ce-cli=&lt;VERSION_STRING&gt; containerd.io 2.使用deb包安装1.去 https://download.docker.com/linux/ubuntu/dists/ 网站，选择合适的.deb文件2.安装.deb包1$ sudo dpkg -i /path/to/package.deb 3.使用shell脚本安装 脚本在 get.docker.com 不建议在生产环境直接使用脚本安装docker 安装步骤1234$ curl -fsSL https://get.docker.com -o get-docker.sh$ sudo sh get-docker.sh&lt;output truncated&gt; 添加非root用户到docker组1$ sudo usermod -aG docker your-user 卸载Docker CE1.卸载Docker CE1$ sudo apt-get purge docker-ce 2.镜像、数据卷、容器和一些自定义的配置文件不会自动删除，需要手动删除1$ sudo rm -rf /var/lib/docker]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker运维相关]]></title>
    <url>%2F2019%2F04%2F20%2Fabout-use-docker%2F</url>
    <content type="text"><![CDATA[记录Docker在日常学习和工作中的相关积累 Docker运维 安装Docker Image相关 Unionfs *overlay2]]></content>
      <tags>
        <tag>docker</tag>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己动手写docker]]></title>
    <url>%2F2019%2F04%2F20%2Fwrite-docker-self%2F</url>
    <content type="text"><![CDATA[Docker目前是后端服务中最火的技术之一，读这本书《自己动手写docker》，对自己来说，主要是从原理上熟悉docker，顺便复习go语言 容器技术的发展 docker VS 虚拟机 基础技术 docker namespace UTS USER docker cgroup aufs 构建容器 构建实现run命令的容器]]></content>
      <tags>
        <tag>docker</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解容器镜像]]></title>
    <url>%2F2019%2F04%2F18%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[Namespace和Cgroups正如前面所讲，“容器的本质只是一个特殊的进程”。主要是利用Namespace和Cgroup的特性。正如前面所讲，Namespace的作用是“隔离”，它让应用程序只能看到Namespace内的“世界”；而Cgroups的作用是“限制”，它限制“世界”使用某些资源。经过这么一折腾，进程就被“装”在了一个与世隔绝的房间里，而这些房间就是Paas项目赖以生存的应用“沙盒”。 Mount Namespace可是，还有一个问题不知道你有没有仔细思考过：这个房间四周虽然有了墙，但是如果容器进程低头一看地面，又是怎样一副景象呢？ 可能你立即想到了,这一定是一个Mount Namespace的问题：容器里的应用进程，理应当看到了一份完全独立的文件系统，这样它就可以在自己容器目录(/tmp)下进行操作，而完全不受宿主主机以及其他容器的影响。 那么，真实情况是这样吗？ “左耳朵耗子”叔在多年前写的一篇关于 Docker 基础知识的博客里，曾经介绍过一段小程序。这段小程序的作用是，在创建子进程时开启指定的 Namespace。 123456789101112131415161718192021222324252627282930313233#define _GNU_SOURCE#include &lt;sys/mount.h&gt; #include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;stdio.h&gt;#include &lt;sched.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#define STACK_SIZE (1024 * 1024)static char container_stack[STACK_SIZE];char* const container_args[] = &#123; &quot;/bin/bash&quot;, NULL&#125;;int container_main(void* arg)&#123; printf(&quot;Container - inside the container!\n&quot;); execv(container_args[0], container_args); printf(&quot;Something&apos;s wrong!\n&quot;); return 1;&#125;int main()&#123; printf(&quot;Parent - start a container!\n&quot;); int container_pid = clone(container_main, container_stack+STACK_SIZE, CLONE_NEWNS | SIGCHLD , NULL); waitpid(container_pid, NULL, 0); printf(&quot;Parent - container stopped!\n&quot;); return 0;&#125; 这段代码的功能是：在main函数中，通过clone()系统调用创建一个新的子进程 container_main，并且声明要为它启用Mount Namespace（即：CLONE_NEWNS标志） 而这个子进程执行的，是一个“/bin/bash”程序，也就是一个 shell。所以这个 shell 就运行在了 Mount Namespace 的隔离环境中。 编译运行这个程序1234$ make ns$ ./nsParent - start a container!Container - inside the container! 这样，我们就进入了这个“容器”当中。可是，如果在“容器”里执行一下 ls 指令的话，我们就会发现一个有趣的现象： /tmp 目录下的内容跟宿主机的内容是一样的。 12$ ls /tmp# 你会看到好多宿主机的文件 也就是说： 即使开启了 Mount Namespace，容器进程看到的文件系统也跟宿主机完全一样。 这是怎么回事呢？ 其实这并不难理解：Mount Namespace修改的，是容器进程对“挂载点”的认知。但是这就意味着，只有在“挂载点”这个操作发生之后，进程的视图才会被改变。而在此之前，新创建的容器进程挂载点是直接继承宿主主机的各个挂载点。 这时，你可能已经想到了一个解决办法：创建新进程时，除了声明要启用 Mount Namespace 之外，我们还可以告诉容器进程，有哪些目录需要重新挂载，就比如这个 /tmp 目录。于是，我们在容器进程执行前可以添加一步重新挂载 /tmp 目录的操作： 12345678910int container_main(void* arg)&#123; printf(&quot;Container - inside the container!\n&quot;); // 如果你的机器的根目录的挂载类型是 shared，那必须先重新挂载根目录 // mount(&quot;&quot;, &quot;/&quot;, NULL, MS_PRIVATE, &quot;&quot;); mount(&quot;none&quot;, &quot;/tmp&quot;, &quot;tmpfs&quot;, 0, &quot;&quot;); execv(container_args[0], container_args); printf(&quot;Something&apos;s wrong!\n&quot;); return 1;&#125; 可以看到，在修改后的代码里，我在容器进程启动之前，加上了一句 mount(“none”, “/tmp”, “tmpfs”, 0, “”) 语句。就这样，我告诉了容器以 tmpfs（内存盘）格式，重新挂载了 /tmp 目录。 这段修改后的代码，编译执行后的结果又如何呢？我们可以试验一下： 12345$ gcc -o ns ns.c$ ./nsParent - start a container!Container - inside the container!$ ls /tmp 可以看到，这次 /tmp 变成了一个空目录，这意味着重新挂载生效了。我们可以用 mount -l 检查一下： 12$ mount -l | grep tmpfsnone on /tmp type tmpfs (rw,relatime) 可以看到，容器里的 /tmp 目录是以 tmpfs 方式单独挂载的。 更重要的是，因为我们创建的新进程启用了 Mount Namespace，所以这次重新挂载的操作，只在容器进程的 Mount Namespace 中有效。如果在宿主机上用 mount -l 来检查一下这个挂载，你会发现它是不存在的： 12# 在宿主机上$ mount -l | grep tmpfs 这就是 Mount Namespace 跟其他 Namespace 的使用略有不同的地方：它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。 可是，作为一个普通用户，我们希望的是一个更友好的情况：每当创建一个新容器时，我希望容器进程看到的文件系统就是一个独立的隔离环境，而不是继承自宿主机的文件系统。怎么才能做到这一点呢？ 不难想到，我们可以在容器进程启动之前重新挂载它的整个根目录“/”。而由于 Mount Namespace 的存在，这个挂载对宿主机不可见，所以容器进程就可以在里面随便折腾了。 为了能够让容器的这个根目录看起来更“真实”，我们一般会在这个容器的根目录下挂载一个完整操作系统的文件系统，比如 Ubuntu16.04 的 ISO。这样，在容器启动之后，我们在容器里通过执行 “ls /“ 查看根目录下的内容，就是 Ubuntu 16.04 的所有目录和文件。 而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。 所以，一个最常见的 rootfs，或者说容器镜像，会包括如下所示的一些目录和文件，比如 /bin，/etc，/proc 等等： 12ls /bin dev etc home lib lib64 mnt opt proc root run sbin sys tmp usr var 而你进入容器之后执行的 /bin/bash，就是 /bin 目录下的可执行文件，与宿主机的 /bin/bash 完全不同。 现在，你应该可以理解，对 Docker 项目来说，它最核心的原理实际上就是为待创建的用户进程： 启用 Linux Namespace 配置； 设置指定的 Cgroups 参数； 切换进程的根目录（Change Root）。 这样，一个完整的容器就诞生了。不过，Docker 项目在最后一步的切换上会优先使用 pivot_root 系统调用，如果系统不支持，才会使用 chroot。这两个系统调用虽然功能类似，但是也有细微的区别，这一部分小知识就交给你课后去探索了。 rootfs另外，需要明确的是，rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。 所以说，rootfs 只包括了操作系统的“躯壳”，并没有包括操作系统的“灵魂”。那么，对于容器来说，这个操作系统的“灵魂”又在哪里呢？实际上，同一台机器上的所有容器，都共享宿主机操作系统的内核。 这就意味着，如果你的应用程序需要配置内核参数、加载额外的内核模块，以及跟内核进行直接的交互，你就需要注意了：这些操作和依赖的对象，都是宿主机操作系统的内核，它对于该机器上的所有容器来说是一个“全局变量”，牵一发而动全身。 这也是容器相比于虚拟机的主要缺陷之一：毕竟后者不仅有模拟出来的硬件机器充当沙盒，而且每个沙盒里还运行着一个完整的 Guest OS 给应用随便折腾。 不过，正是由于 rootfs 的存在，容器才有了一个被反复宣传至今的重要特性：一致性。 什么是容器的“一致性”呢？ 我在专栏的第一篇文章《小鲸鱼大事记（一）：初出茅庐》中曾经提到过：由于云端与本地服务器环境不同，应用的打包过程，一直是使用 PaaS 时最“痛苦”的一个步骤。 但有了容器之后，更准确地说，有了容器镜像（即 rootfs）之后，这个问题被非常优雅地解决了。 由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。 事实上，对于大多数开发者而言，他们对应用依赖的理解，一直局限在编程语言层面。比如 Golang 的 Godeps.json。但实际上，一个一直以来很容易被忽视的事实是，对一个应用来说，操作系统本身才是它运行所需要的最完整的“依赖库”。 有了容器镜像“打包操作系统”的能力，这个最基础的依赖环境也终于变成了应用沙盒的一部分。这就赋予了容器所谓的一致性：无论在本地、云端，还是在一台任何地方的机器上，用户只需要解压打包好的容器镜像，那么这个应用运行所需要的完整的执行环境就被重现出来了。 这种深入到操作系统级别的运行环境一致性，打通了应用在本地开发和远端执行环境之间难以逾越的鸿沟。 不过，这时你可能已经发现了另一个非常棘手的问题：难道我每开发一个应用，或者升级一下现有的应用，都要重复制作一次 rootfs 吗？ 比如，我现在用 Ubuntu 操作系统的 ISO 做了一个 rootfs，然后又在里面安装了 Java 环境，用来部署我的 Java 应用。那么，我的另一个同事在发布他的 Java 应用时，显然希望能够直接使用我安装过 Java 环境的 rootfs，而不是重复这个流程。 一种比较直观的解决办法是，我在制作 rootfs 的时候，每做一步“有意义”的操作，就保存一个 rootfs 出来，这样其他同事就可以按需求去用他需要的 rootfs 了。 但是，这个解决办法并不具备推广性。原因在于，一旦你的同事们修改了这个 rootfs，新旧两个 rootfs 之间就没有任何关系了。这样做的结果就是极度的碎片化。 那么，既然这些修改都基于一个旧的 rootfs，我们能不能以增量的方式去做这些修改呢？这样做的好处是，所有人都只需要维护相对于 base rootfs 修改的增量内容，而不是每次修改都制造一个“fork”。 答案当然是肯定的。 这也正是为何，Docker 公司在实现 Docker 镜像时并没有沿用以前制作 rootfs 的标准流程，而是做了一个小小的创新： Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。 当然，这个想法不是凭空臆造出来的，而是用到了一种叫作联合文件系统（Union File System）的能力。Union File System 也叫 UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。比如，我现在有两个目录 A 和 B，它们分别有两个文件： 12345678$ tree.├── A│ ├── a│ └── x└── B ├── b └── x 然后，我使用联合挂载的方式，将这两个目录挂载到一个公共的目录 C 上：12$ mkdir C$ mount -t aufs -o dirs=./A:./B none ./C 这时，我再查看目录 C 的内容，就能看到目录 A 和 B 下的文件被合并到了一起：12345$ tree ./C./C├── a├── b└── x 可以看到，在这个合并后的目录 C 里，有 a、b、x 三个文件，并且 x 文件只有一份。这，就是“合并”的含义。此外，如果你在目录 C 里对 a、b、x 文件做修改，这些修改也会在对应的目录 A、B 中生效。 那么在Docker中如何使用这种Union File System的呢？ 我的环境是 Ubuntu 16.04 和 Docker CE 18.05，这对组合默认使用的是 AuFS 这个联合文件系统的实现。你可以通过 docker info 命令，查看到这个信息。AuFS 的全称是 Another UnionFS，后改名为 Alternative UnionFS，再后来干脆改名叫作 Advance UnionFS。 对于 AuFS 来说，它最关键的目录结构在 /var/lib/docker 路径下的 diff 目录：1/var/lib/docker/aufs/diff/&lt;layer_id&gt; 现在，我们启动一个容器，比如：1$ docker run -d ubuntu:latest sleep 3600 这时候，Docker 就会从 Docker Hub 上拉取一个 Ubuntu 镜像到本地。 这个所谓的“镜像”，实际上就是一个 Ubuntu 操作系统的 rootfs，它的内容是 Ubuntu 操作系统的所有文件和目录。不过，与之前我们讲述的 rootfs 稍微不同的是，Docker 镜像使用的 rootfs，往往由多个“层”组成： 123456789101112$ docker image inspect ubuntu:latest... &quot;RootFS&quot;: &#123; &quot;Type&quot;: &quot;layers&quot;, &quot;Layers&quot;: [ &quot;sha256:f49017d4d5ce9c0f544c...&quot;, &quot;sha256:8f2b771487e9d6354080...&quot;, &quot;sha256:ccd4d61916aaa2159429...&quot;, &quot;sha256:c01d74f99de40e097c73...&quot;, &quot;sha256:268a067217b5fe78e000...&quot; ] &#125; 可以看到，这个 Ubuntu 镜像，实际上由五个层组成。这五个层就是五个增量 rootfs，每一层都是 Ubuntu 操作系统文件与目录的一部分；而在使用镜像时，Docker 会把这些增量联合挂载在一个统一的挂载点上（等价于前面例子里的“/C”目录）。这个挂载点就是 /var/lib/docker/aufs/mnt/，比如： 1/var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fcfa2a2f5c89dc21ee30e166be823ceaeba15dce645b3e 不出意外的，这个目录里面正是一个完整的 Ubuntu 操作系统： 12$ ls /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fcfa2a2f5c89dc21ee30e166be823ceaeba15dce645b3ebin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 那么，前面提到的五个镜像层，又是如何被联合挂载成这样一个完整的 Ubuntu 文件系统的呢？这个信息记录在 AuFS 的系统目录 /sys/fs/aufs 下面。首先，通过查看 AuFS 的挂载信息，我们可以找到这个目录对应的 AuFS 的内部 ID（也叫：si）： 12$ cat /proc/mounts| grep aufsnone /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fc... aufs rw,relatime,si=972c6d361e6b32ba,dio,dirperm1 0 0 即，si=972c6d361e6b32ba。然后使用这个 ID，你就可以在 /sys/fs/aufs 下查看被联合挂载在一起的各个层的信息： 12345678$ cat /sys/fs/aufs/si_972c6d361e6b32ba/br[0-9]*/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...=rw/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...-init=ro+wh/var/lib/docker/aufs/diff/32e8e20064858c0f2...=ro+wh/var/lib/docker/aufs/diff/2b8858809bce62e62...=ro+wh/var/lib/docker/aufs/diff/20707dce8efc0d267...=ro+wh/var/lib/docker/aufs/diff/72b0744e06247c7d0...=ro+wh/var/lib/docker/aufs/diff/a524a729adadedb90...=ro+wh 从这些信息里，我们可以看到，镜像的层都放置在 /var/lib/docker/aufs/diff 目录下，然后被联合挂载在 /var/lib/docker/aufs/mnt 里面。而且，从这个结构可以看出来，这个容器的 rootfs 由如下图所示的三部分组成： 这里有一个图 第一部分，只读层。它是这个容器的 rootfs 最下面的五层，对应的正是 ubuntu:latest 镜像的五层。可以看到，它们的挂载方式都是只读的（ro+wh，即 readonly+whiteout，至于什么是 whiteout，我下面马上会讲到）。这时，我们可以分别查看一下这些层的内容： 123456$ ls /var/lib/docker/aufs/diff/72b0744e06247c7d0...etc sbin usr var$ ls /var/lib/docker/aufs/diff/32e8e20064858c0f2...run$ ls /var/lib/docker/aufs/diff/a524a729adadedb900...bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 可以看到，这些层，都以增量的方式分别包含了 Ubuntu 操作系统的一部分。 第二部分，可读写层。 它是这个容器的 rootfs 最上面的一层（6e3be5d2ecccae7cc），它的挂载方式为：rw，即 read write。在没有写入文件之前，这个目录是空的。而一旦在容器里做了写操作，你修改产生的内容就会以增量的方式出现在这个层中。可是，你有没有想到这样一个问题：如果我现在要做的，是删除只读层里的一个文件呢？为了实现这样的删除操作，AuFS 会在可读写层创建一个 whiteout 文件，把只读层里的文件“遮挡”起来。比如，你要删除只读层里一个名叫 foo 的文件，那么这个删除操作实际上是在可读写层创建了一个名叫.wh.foo 的文件。这样，当这两个层被联合挂载之后，foo 文件就会被.wh.foo 文件“遮挡”起来，“消失”了。这个功能，就是“ro+wh”的挂载方式，即只读 +whiteout 的含义。我喜欢把 whiteout 形象地翻译为：“白障”。所以，最上面这个可读写层的作用，就是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用 docker commit 和 push 指令，保存这个被修改过的可读写层，并上传到 Docker Hub 上，供其他人使用；而与此同时，原先的只读层里的内容则不会有任何变化。这，就是增量 rootfs 的好处。 第三部分，Init 层。 它是一个以“-init”结尾的层，夹在只读层和读写层之间。Init 层是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息。需要这样一层的原因是，这些文件本来属于只读的 Ubuntu 镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。可是，这些修改往往只对当前的容器有效，我们并不希望执行 docker commit 时，把这些信息连同可读写层一起提交掉。所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行 docker commit 只会提交可读写层，所以是不包含这些内容的。最终，这 7 个层都被联合挂载到 /var/lib/docker/aufs/mnt 目录下，表现为一个完整的 Ubuntu 操作系统供容器使用。 总结在今天的分享中，我着重介绍了 Linux 容器文件系统的实现方式。而这种机制，正是我们经常提到的容器镜像，也叫作：rootfs。它只是一个操作系统的所有文件和目录，并不包含内核，最多也就几百兆。而相比之下，传统虚拟机的镜像大多是一个磁盘的“快照”，磁盘有多大，镜像就至少有多大。 通过结合使用 Mount Namespace 和 rootfs，容器就能够为进程构建出一个完善的文件系统隔离环境。当然，这个功能的实现还必须感谢 chroot 和 pivot_root 这两个系统调用切换进程根目录的能力。 而在 rootfs 的基础上，Docker 公司创新性地提出了使用多个增量 rootfs 联合挂载一个完整 rootfs 的方案，这就是容器镜像中“层”的概念。 通过“分层镜像”的设计，以 Docker 镜像为核心，来自不同公司、不同团队的技术人员被紧密地联系在了一起。而且，由于容器镜像的操作是增量式的，这样每次镜像拉取、推送的内容，比原本多个完整的操作系统的大小要小得多；而共享层的存在，可以使得所有这些容器镜像需要的总空间，也比每个镜像的总和要小。这样就使得基于容器镜像的团队协作，要比基于动则几个 GB 的虚拟机磁盘镜像的协作要敏捷得多。更重要的是，一旦这个镜像被发布，那么你在全世界的任何一个地方下载这个镜像，得到的内容都完全一致，可以完全复现这个镜像制作者当初的完整环境。这，就是容器技术“强一致性”的重要体现。 而这种价值正是支撑 Docker 公司在 2014~2016 年间迅猛发展的核心动力。容器镜像的发明，不仅打通了“开发 - 测试 - 部署”流程的每一个环节，更重要的是： 容器镜像将会成为未来软件的主流发布方式。]]></content>
      <tags>
        <tag>docker</tag>
        <tag>image</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C程序分析工具 valgrind]]></title>
    <url>%2F2019%2F04%2F18%2F04-introducing-valgrind%2F</url>
    <content type="text"><![CDATA[现在介绍另外一个工具，在学习C的过程中，要习惯性的使用，它就是 Valgrind 。Valgrind是一个运行你的程序的程序，并且随后会报告所有你犯下的可怕错误。 安装 Valgrind有两种安装方式，在Centos中，可以通过yum install -y Valgrind方式安装，另外是下载Valgrind源码安装。 这里演示源码安装方式 12345678910111213141) 下载Valgrind源码包wget wget https://sourceware.org/pub/valgrind/valgrind-3.15.0.tar.bz22) 解压tar jxvf valgrind-3.15.0.tar.bz23) configure./configure4) 编译make5) 安装make install 使用Valgrind这里写一个带有错误的C程序，待会儿让Valgrind来运行一下,error.c源码如下： 1234567891011#include&lt;stdio.h&gt;int main()&#123; int age = 12; int height; printf(&quot;I am %d years old.\n&quot;); printf(&quot;I am %d inches tall.\n&quot;,height); return 0;&#125; 当前程序有两个错误： 没有初始化height变量 没有将age变量传入第一个printf函数 使用make构建 123456789101112[root@www practice04]# makecc -Wall -g error.c -o errorerror.c: In function ‘main’:error.c:7:5: warning: format ‘%d’ expects a matching ‘int’ argument [-Wformat=] printf(&quot;I am %d years old.\n&quot;); ^error.c:4:9: warning: unused variable ‘age’ [-Wunused-variable] int age = 12; ^error.c:8:11: warning: ‘height’ is used uninitialized in this function [-Wuninitialized] printf(&quot;I am %d inches tall.\n&quot;,height); ^ 使用Valgrind来运行error程序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849==17432== Memcheck, a memory error detector==17432== Copyright (C) 2002-2017, and GNU GPL&apos;d, by Julian Seward et al.==17432== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info==17432== Command: ./error==17432== I am -16775928 years old.==17432== Conditional jump or move depends on uninitialised value(s)==17432== at 0x4E7C9F2: vfprintf (in /usr/lib64/libc-2.17.so)==17432== by 0x4E86878: printf (in /usr/lib64/libc-2.17.so)==17432== by 0x400561: main (error.c:8)==17432== ==17432== Use of uninitialised value of size 8==17432== at 0x4E7BE8B: _itoa_word (in /usr/lib64/libc-2.17.so)==17432== by 0x4E7CF05: vfprintf (in /usr/lib64/libc-2.17.so)==17432== by 0x4E86878: printf (in /usr/lib64/libc-2.17.so)==17432== by 0x400561: main (error.c:8)==17432== ==17432== Conditional jump or move depends on uninitialised value(s)==17432== at 0x4E7BE95: _itoa_word (in /usr/lib64/libc-2.17.so)==17432== by 0x4E7CF05: vfprintf (in /usr/lib64/libc-2.17.so)==17432== by 0x4E86878: printf (in /usr/lib64/libc-2.17.so)==17432== by 0x400561: main (error.c:8)==17432== ==17432== Conditional jump or move depends on uninitialised value(s)==17432== at 0x4E7CF54: vfprintf (in /usr/lib64/libc-2.17.so)==17432== by 0x4E86878: printf (in /usr/lib64/libc-2.17.so)==17432== by 0x400561: main (error.c:8)==17432== ==17432== Conditional jump or move depends on uninitialised value(s)==17432== at 0x4E7CABD: vfprintf (in /usr/lib64/libc-2.17.so)==17432== by 0x4E86878: printf (in /usr/lib64/libc-2.17.so)==17432== by 0x400561: main (error.c:8)==17432== ==17432== Conditional jump or move depends on uninitialised value(s)==17432== at 0x4E7CB40: vfprintf (in /usr/lib64/libc-2.17.so)==17432== by 0x4E86878: printf (in /usr/lib64/libc-2.17.so)==17432== by 0x400561: main (error.c:8)==17432== I am 0 inches tall.==17432== ==17432== HEAP SUMMARY:==17432== in use at exit: 0 bytes in 0 blocks==17432== total heap usage: 0 allocs, 0 frees, 0 bytes allocated==17432== ==17432== All heap blocks were freed -- no leaks are possible==17432== ==17432== Use --track-origins=yes to see where uninitialised values come from==17432== For lists of detected and suppressed errors, rerun with: -s==17432== ERROR SUMMARY: 6 errors from 6 contexts (suppressed: 0 from 0) Valgrind运行并分析程序，返回的数据分成三部分，第一部分是Vargrind版本信息,第二部分报告程序的相关错误信息，第三部分会生成一个简短报告，告诉你你的程序有多烂。 附加题 根据Valgrind错误信息，修复程序 12345678910111213141516==17515== Memcheck, a memory error detector==17515== Copyright (C) 2002-2017, and GNU GPL&apos;d, by Julian Seward et al.==17515== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info==17515== Command: ./error==17515== I am 12345 years old.I am 72 inches tall.==17515== ==17515== HEAP SUMMARY:==17515== in use at exit: 0 bytes in 0 blocks==17515== total heap usage: 0 allocs, 0 frees, 0 bytes allocated==17515== ==17515== All heap blocks were freed -- no leaks are possible==17515== ==17515== For lists of detected and suppressed errors, rerun with: -s==17515== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)]]></content>
      <tags>
        <tag>C</tag>
        <tag>valgrind</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[格式化输出]]></title>
    <url>%2F2019%2F04%2F18%2F03-format-print%2F</url>
    <content type="text"><![CDATA[printf格式化函数许多编程语言都使用了C风格格式化输出，所以让我们也尝试一下,编写format-output.c，代码如下： 1234567891011#include&lt;stdio.h&gt;int main()&#123; int age = 10; int height = 72; printf(&quot;I am %d years old.\n&quot;,age); printf(&quot;I am %d inches tall.\n&quot;,height); return 0;&#125; Makefile文件如下：123456CFLAGS=-Wall -gall: format-outputclean: rm -rf format-output 执行make，将看到如下内容:12[root@www practice03]# makecc -Wall -g format-output.c -o format-output 这段代码量很小，我们逐行分析一下： 首先你包含了一个叫做 stdio.h 的头文件。这告诉你的编译器要使用“标准的输入/输出函数”。他们之一就是下面的printf。 然后你声明了一个int类型的age变量，并赋值为10。 接着你又声明了一个int类型的height变量，并赋值为72。 再然后用printf函数来打印你的年龄和身高 在printf中你会注意到你传入了一个字符串，这就是格式字符串，和其它语言中一样。 在格式化字符串后面，你传入了一些变量，他们应该被printf“替换”进格式化字符串中。 附加题 执行 man 3 printf 来阅读它更多可用的“%”格式的占位符。 控制符 说明 %d 按十进制整型数据的实际长度输出。 %ld 输出长整型数据。 %md m为指定的输出字段的宽度。如果数据的位数小于 m，则左端补以空格，若大于 m，则按实际位数输出。 %u 输出无符号整型（unsigned）。输出无符号整型时也可以用 %d，这时是将无符号转换成有符号数，然后输出。但编程的时候最好不要这么写，因为这样要进行一次转换，使 CPU 多做一次无用功。 %c 输出一个字符 %f 用来输出实数，包括单精度和双精度，以小数形式输出。不指定字段宽度，由系统自动指定，整数部分全部输出，小数部分输出 6 位，超过 6 位的四舍五入。 %.mf 输出实数时小数点后保留 m 位，注意 m 前面有个点。 %o 以八进制整数形式输出，这个就用得很少了，了解一下就行了。 %s 用来输出字符串。用 %s 输出字符串同前面直接输出字符串是一样的。但是此时要先定义字符数组或字符指针存储或指向字符串。 %x（或 %X 或 %#x 或 %#X） 以十六进制形式输出整数，这个很重要。 %x、%X、%#x、%#X 的区别 一定要掌握 %x（或 %X 或 %#x 或 %#X），因为调试的时候经常要将内存中的二进制代码全部输出，然后用十六进制显示出来。下面写一个程序看看它们四个有什么区别： 12345678910# include &lt;stdio.h&gt;int main(void)&#123; int i = 47; printf(&quot;%x\n&quot;, i); printf(&quot;%X\n&quot;, i); printf(&quot;%#x\n&quot;, i); printf(&quot;%#X\n&quot;, i); return 0;&#125; 在 VC++ 6.0 中的输出结果：12342f2F0x2f0X2F 从输出结果可以看出：如果是小写的x，输出的字母就是小写的；如果是大写的X，输出的字母就是大写的；如果加一个#，就以标准的十六进制形式输出。 最好是加一个#，否则如果输出的十六进制数正好没有字母的话会误认为是一个十进制数呢！]]></content>
      <tags>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker:从进程说起]]></title>
    <url>%2F2019%2F04%2F12%2Fdocker-process%2F</url>
    <content type="text"><![CDATA[进程进程是运行的程序，一旦“程序”被执行起来，它就从磁盘上的二进制文件，变成了计算机内存中的数据、寄存器里的值、堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。像这样一个程序运起来后的计算机执行环境的总和，就是进程。 Namespace而容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。 对于 Docker 等大多数 Linux 容器来说，Cgroups 技术是用来制造约束的主要手段，而Namespace 技术则是用来修改进程视图的主要方法。 假设你已经有了一个 Linux 操作系统上的 Docker 项目在运行，比如我的环境是 Ubuntu 16.04 和 Docker CE 18.05。 接下来，让我们创建一个容器试试。 12$ docker run -it busybox /bin/bash/ # 这就是大名鼎鼎的docker run。-it参数告诉Docker项目在启动的时候分配一个输入/输出环境，也就是TTY，跟容器的标准输入相关联，这样我们就可以和这个容器交互了。而/bin/bash就是在这个容器里运行的程序。 所以，上面这条指令翻译成人类的语言就是：请帮我启动一个容器，在容器里执行 /bin/sh，并且给我分配一个命令行终端跟这个容器交互。 在容器里执行ps，会出现如下信息： 1234/ # psPID USER TIME COMMAND 1 root 0:00 /bin/sh 10 root 0:00 ps 我们可以看到，容器启动时执行的/bin/bash，就是这个容器里第1号进程（PID=1）,当前，容器里有两个进程在运行。这两个进程，已经被Docker隔离在了一个跟宿主主机完全不同的世界当中。 那么，这究竟是这么做到的呢？ 本来，当我们在宿主主机执行/bin/bash,操作系统会给它分配一个进程编号，比如PID=100。而现在，我们通过Docker把/bin/bash运行在容器当中。这时候，Docker就会在这个进程启动时，给它实时一个“障眼法”，让它永远也看不到前面的99个进程，这里，它就会误认为自己是第1号进程了。 这种机制，其实就是对被隔离应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号，比如 PID=1。可实际上，他们在宿主主机的操作系统中，还是原来的第100号进程。 这种技术，就是Linux中的Namespace机制。而Namespace的使用方式也非常有意思：它其实只是Linux创建新进程的一个可选参数。我们知道，在Linux系统中创建线程的系统调用是clone(),比如： 1int pid = clone(main_function, stack_size, SIGCHLD, NULL); 这个系统调用就会为我们创建一个新的进程，并且返回它的进程号 pid。而当我们用 clone() 系统调用创建一个新进程时，就可以在参数中指定 CLONE_NEWPID 参数，比如： 1int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL); 这时，新创建的这个进程将会“看到”一个全新的进程空间，在这个进程空间里，它的 PID 是 1。之所以说“看到”，是因为这只是一个“障眼法”，在宿主机真实的进程空间里，这个进程的 PID 还是真实的数值，比如 100。 而除了刚刚这种PID Namespace，Linux操作系统还提供了Mount、UTS、IPC、Network和User 这些Namespace，用来对各种不同的进程上下文进行“障眼法”操作。 这就是Linux容器最基本的实现原理了。所以说，容器只是一种特殊的进程而已，在创建该容器进程时，指定了这个进程所需要启用的一组Namespace参数。这样，容器就只能“看”到当前Namespace所限定的资源、文件、设备、状态或者配置。而宿主主机以及其他不想关的程序，它就完全看不到了。 CGroup除了Namespace对容器环境进行隔离，还通过Linux CGroup限制容器进程使用相关资源 Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。 在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。在 Ubuntu 16.04 机器里，我可以用 mount 指令把它们展示出来，这条命令是： 1234567cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)...... 可以看到，在 /sys/fs/cgroup 下面有很多诸如 cpuset、cpu、 memory 这样的子目录，也叫子系统。这些都是我这台机器当前可以被 Cgroups 进行限制的资源种类。而在子系统对应的资源种类下，你就可以看到该类资源具体可以被限制的方法。比如，对 CPU 子系统来说，我们就可以看到如下几个配置文件，这个指令是： 123$ ls /sys/fs/cgroup/cpucgroup.clone_children cpu.cfs_period_us cpu.rt_period_us cpu.shares notify_on_releasecgroup.procs cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat tasks 如果熟悉 Linux CPU 管理的话，你就会在它的输出里注意到 cfs_period 和 cfs_quota 这样的关键词。这两个参数需要组合使用，可以用来限制进程在长度为 cfs_period 的一段时间内，只能被分配到总量为 cfs_quota 的 CPU 时间。 而这样的配置文件又如何使用呢？你需要在对应的子系统下面创建一个目录，比如，我们现在进入 /sys/fs/cgroup/cpu 目录下： 1234root@ubuntu:/sys/fs/cgroup/cpu$ mkdir containerroot@ubuntu:/sys/fs/cgroup/cpu$ ls container/cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us cpu.shares notify_on_releasecgroup.procs cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat tasks 这个目录就称为一个“控制组”。你会发现，操作系统会在你新创建的 container 目录下，自动生成该子系统对应的资源限制文件。 现在，我们在后台执行这样一条脚本： 12$ while : ; do : ; done &amp;[1] 226 显然，它执行了一个死循环，可以把计算机的 CPU 吃到 100%，根据它的输出，我们可以看到这个脚本在后台运行的进程号（PID）是 226。这样，我们可以用 top 指令来确认一下 CPU 有没有被打满： 12$ top%Cpu0 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st 在输出里可以看到，CPU 的使用率已经 100% 了（%Cpu0 :100.0 us）。而此时，我们可以通过查看 container 目录下的文件，看到 container 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us）： 1234$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us -1$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us 100000 接下来，我们可以通过修改这些文件的内容来设置限制。比如，向 container 组里的 cfs_quota 文件写入 20 ms（20000 us）： 1$ echo 20000 &gt; /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us 结合前面的介绍，你应该能明白这个操作的含义，它意味着在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的 CPU 带宽。接下来，我们把被限制的进程的 PID 写入 container 组里的 tasks 文件，上面的设置就会对该进程生效了： 1$ echo 226 &gt; /sys/fs/cgroup/cpu/container/tasks 我们可以用 top 指令查看一下： 12$ top%Cpu0 : 20.3 us, 0.0 sy, 0.0 ni, 79.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st 可以看到，计算机的 CPU 使用率立刻降到了 20%（%Cpu0 : 20.3 us）。 除 CPU 子系统外，Cgroups 的每一项子系统都有其独有的资源限制能力，比如： blkio，为​​​块​​​设​​​备​​​设​​​定​​​I/O 限​​​制,一般用于磁盘等设备； cpuset，为进程分配单独的 CPU 核和对应的内存节点； memory，为进程设定内存使用的限制。 Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行 docker run 时的参数指定了，比如这样一条命令： 1$ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash 在启动这个容器后，我们可以通过查看 Cgroups 文件系统下，CPU 子系统中，“docker”这个控制组里的资源限制文件的内容来确认： 1234$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us 100000$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us 20000 这就意味着这个 Docker 容器，只能使用到 20% 的 CPU 带宽。 总结一个正在运行的 Docker 容器，其实就是一个启用了多个 Linux Namespace 的应用进程，而这个进程能够使用的资源量，则受 Cgroups 配置的限制。]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用make]]></title>
    <url>%2F2019%2F04%2F09%2F02-use-make%2F</url>
    <content type="text"><![CDATA[使用make使用make的第一个阶段，就是用它已知的方法来构建程序。make预置了一些知识，来从其它文件构建多种文件。在上一个练习中，有如下操作： 12$ make hello-world$ CFLAG=&quot;-Wall&quot; make hello-world 第一条命令中你告诉make，“我想创建名为hello-word的文件”。于是，make执行了下面的动作： 文件hello-world存在吗？ 没有的话。好的，那有没有其它文件是以hello-world开头的？ 有，叫做hello-world.c。我知道如何构建.c文件吗？ 知道。我会运行 cc hello-world.c -o hello-world 来构建它。 我将使用 cc 从 hello-world.c 文件为你构建 hello-world 上面的第二条命令，是向 make 命令传递“修改器”的途径。这个例子中，我执行了 CFLAGS=&quot;-Wall&quot; make hello-world，它会给make使用的 cc 命令添加 -Wall 选项。这行命令告诉编译器要报告所有的警告。 Makefile编写创建文件并写入一下内容 1234CFLAGS=-Wall -gclean: rm -rf hello-world 将文件在你当前文件夹下保存为Makefile。Make会自动假设当前文件夹下有一个叫Makefile的文件，并且会执行它。 首先我们在文件中设置CFLAGS,所以之后都不用再设置了。并且添加了-g标识来获取调试信息。接着我们写了一个clean的部门，它告诉make如何清理我们的小项目。 请确保，你的makefile文件和hello-world.c在同一个目录下，hello-world.c内容如下： 1234int main(int argc,char *argv[])&#123; puts(&quot;Hello world.\nnice to see you!&quot;); return 0;&#125; 之后可以执行命令: 12$ make clean$ make hello-world 如果代码正常执行，你应该看到下面这些内容 12345678[root@www practice02]# make cleanrm -f hello-world[root@www practice02]# make hello-worldcc -Wall -g hello-world.c -o hello-worldhello-world.c: In function ‘main’:hello-world.c:2:5: warning: implicit declaration of function ‘puts’ [-Wimplicit-function-declaration] puts(&quot;Hello world.\nnice to see you!&quot;); ^ 你可以看出来,我执行了make clean，它告诉make执行我们的clean目标。在看makefile，发现clean下面有一些shell命令。你可以在此处输入任意多的命令，所以它是一个非常棒的自动化工具。 注:如果你修改了 ex1.c ，添加了 #include\&lt;stdio> ，输出中的关于 puts 的警告就会消失（这其实应该算作一个错误） 。我这里有警告是因为我并没有去掉它 附加题 创建目标 all:hello-world,可以用单个命令make构建hello-world 123456CFLAGS=-Wall -gall: hello-worldclean: rm -f hello-world 阅读 man make 来了解关于他的更多信息。 阅读 man cc 来了解关于 -Wall 和 -g 行为的更多信息。]]></content>
      <tags>
        <tag>C</tag>
        <tag>Makefile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[启用编译器]]></title>
    <url>%2F2019%2F04%2F09%2F01-dust-off-that-compiler%2F</url>
    <content type="text"><![CDATA[这是一个最简单的C程序,hello-world.c： 1234int main(int argc, char *argv[])&#123; puts("Hello world."); return 0;&#125; 在Linux终端输入： 12$ make hello-worldcc hello-world.c -o hello-world 现在，你可以运行并可以看到程序输出。 12$ ./hello-worldHello World. 思考： 1.make指令的运行原理和流程 2.puts函数的作用 C 库函数 int puts(const char *str) 把一个字符串写入到标准输出 stdout，直到空字符，但不包括空字符。换行符会被追加到输出中。 3.C语言中的空字符 在C语言中空字符用’\0’表示; ‘\0’对应的整数值是0，所以给一个字符变量赋值为空字符时，以下两种都是可以的： 12char ch=&apos;\0&apos;;char ch=0; 4.字符串 字符串就是一串零个或多个字符，并且以位模式为全0的NUL字节即空字符(‘\0’)结尾。C语言中字符串没有显示的数据类型，字符串通常存储在字符数组或动态分配的内存中，在编码操作中通常将整个字符串作为操作对象，常用操作包括复制、查找、比较等。 5.空字符与字符串 1、空字符是字符串的终止符。注：空字符本身不是字符串的一部分，所以字符串的长度并不包含空字符； 2、操作字符串时，必须保证字符串以空字符结尾(注：不以空字符结尾的字符序列，不是字符串)。]]></content>
      <tags>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[笨方法学C]]></title>
    <url>%2F2019%2F04%2F09%2Flearn-c-the-hard-way%2F</url>
    <content type="text"><![CDATA[这几年，我一直在学习编程语言，从JAVA、PHP、JS到Go，其实我一直想学好的是C语言，C即是基础。这个《笨方法学C》的读书系列，希望自己一定要坚持下来，好好学习，好好总结。 这本书的目的是让你足够熟悉C语言，并能够使用它编写自己的软件，或者修改其他人的代码。你需要学习下面这些东西来达到这一阶段： C的基本语法和编写习惯; 编译,make文件和链接; 寻找和预防bug; 防御性编程实战; 使C的代码崩溃; 编写基本的Unix系统软件。]]></content>
      <tags>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis源码从哪里读起?]]></title>
    <url>%2F2019%2F04%2F03%2FRedis%E6%BA%90%E7%A0%81%E4%BB%8E%E5%93%AA%E9%87%8C%E8%AF%BB%E8%B5%B7%2F</url>
    <content type="text"><![CDATA[转载至 http://zhangtielei.com/posts/blog-redis-how-to-start.html 溯源Redis使用C语言写的。首先，你应该从main函数读起。但是我们在读的时候应该抓住一条主线，也就是当我们向Redis输入一条命令的时候，代码是如何一步一步执行的。这样我们就可以先从外部观察，尝试执行一些命令，在了解了这些命令执行的外部表现之后，再钻进去看对应的源码是如何实现的。要想读懂这些代码，首先我们需要理解Redis的事件机制。而且，一旦理解了Redis的事件循环（Event Loop）的机制，我们还会搞明白一个有趣的问题：为什么Redis是单线程执行却能同时处理多个请求？（当然严格来说Redis运行并不是只有一个线程，但除了主线程外，Redis的其它线程只是起辅助作用，它们是一些在后台运行做异步耗时任务的线程）。 从main函数开始，沿着代码执行路径，实际上我们可以一直追下去。但为了让本文不至于太过冗长，我们还是限定一下返回。本文的目标就定为：引领读者从main函数开始，一步步追踪下去，最终到达任一Redis命令执行入口。这样接下来就可以与Redis内部数据结构详解的一些列文章衔接上。 为了表述清楚，本文按照如下思路进行： 1.先概括地介绍整个代码初始化流程（从main函数开始）和事件循环的结构； 2.再概括地介绍对于Redis命令请求的处理流程； 3.重点介绍事件机制； 4.对于前面介绍的各个代码流程处理，给出详细的代码调用关系，方便随时查阅； 根据这样几部分的划分，如果你只想粗读大致的处理流程，那么只需要阅读前两个部分就可以了。而后两部分则会深入到某些值得关注的细节。 注：本文的分析基于Redis源码的5.0分支。 初始化流程和事件循环概述Redis源码的main函数在源文件server.c中。main函数开始执行后的逻辑可以分为两个阶段： 各种初始化（包括事件循环的初始化） 执行事件循环。 这两个执行阶段可以用下面的流程图来表达： 图1：main函数执行逻辑 首先，我们开一下初始化阶段中的各个步骤： 配置加载和初始化，这一步表示Redis服务器基本数据结构和各种参数的初始化。在Redis源码中，Redis服务器就是用一个叫做redisServer的struct来表示的。 里面定义了Redis服务器赖以运行的各种参数，比如监听的端口号和文件描述符、当前连接的各个client端、Redis命令表（command table）配置、持久化相关的各种参数，等等。Redis服务器在运行时就是由一个redisServer类型的全局变量来表示的（变量名叫 server）,这一步的初始化主要对于这个全局变量进行初始化。在整个初始化过程中，有一个特别需要注意的函数：populateCommandTable。它初始化了Redis命令表，通过它可以由任意一个Redis命令的名字查找该命令的配置信息（比如该命令接受的命令参数个数、执行函数入口等）。在本文的第二部分，我们将会一起来看看如何从接受一个Redis命令的请求开始，一步步执行到查阅这个命令表，从而找到该命令的执行入口。另外，这一步中还有一个值得一提的地方，在对全局的redisServer结构进行初始化之后，还需要从配置文件（redis.conf）中加载配置。这个过程可能覆盖掉之前的初始化过的redisServer结构中的某些参数。换句话说，就是先经过一轮初始化，保证Redis的各个内部数据结构以及参数都有缺省值，然后再从配置文件中加载自定义的配置。 创建事件循环，在Redis中，事件循环是用一个叫aeEventLoop的struct来表示的。创建事件循环这一步主要就是创建一个aeEventLoop结构，并存储到server全局变量中。另外，事件循环的执行依赖系统低层的I/O多路复用机制，比如Linux系统上的epoll机制。因此，这一步也包含对于低层I/O多路复用机制的初始化。（调用系统API） 开始监听socket。服务器程序需要监听才能收到请求。根据配置，这一步可能会打开两种监听：对于TCP连接的监听和对于Unix domain socket的监听，Unix domain socket是一种高效的进程间通信机制，在POSIX规范中也有明确的定义，用于在同一台主机上的两个不同进程之间进行通信，比使用TCP协议性能跟高（因为省去了协议栈的开销）。当使用Redis客户端连接同一台机器上的Redis服务器时，可以使用Unix domain socket进行连接。但是不管是哪一种监听，程序都会获得文件描述符，并存储到server全局变量中。对于TCP的监听来说，由于监听的IP地址和端口可以绑定多个，因此获得的用于监听TCP连接的文件描述符也可以包含多个。后面，程序就可以拿这一步获得的文件描述符去注册I/O事件回调了。 注册timer事件回调。Redis作为一个单线程(single-threaded)的程序，它如果想调度一些异步执行的任务，比如比如周期性的执行过期key的回收动作，除了依赖事件循环机制，没有其它办法。这一步就是向前面刚刚创建好的事件循环中注册一个timer事件，并配置成可以周期性地执行一个回调函数：serverCron。由于Redis只有一个主线程，因此这个函数周期性的执行也是在这个线程内，它由事件循环来驱动（即在合适的时机调用），但不影响同一个线程上其它逻辑的执行（相当于按时间分片了）。serverCron函数到底做了什么呢？实际上，它除了周期性地执行过期key的回收动作，还执行了很多其它任务，比如主从重连、Cluster节点间的重连、bgsave和aof rewrite的触发执行，等等。 注册I/O事件回调。Redis服务器最主要的工作就是监听I/O事件，从中分析出来自客户端的命令请求，执行命令，然后返回响应结果。对于I/O事件的监听，自然也是依赖事件循环。前面提到过，Redis可以打开两种监听：对于TCP连接的监听和对于Unix domain socket的监听。因此，这里就包含对于这两种I/O事件的回调的注册，两个回调函数分别是acceptTcpHandler和acceptUnixHandler。对于来自Redis客户端的请求的处理，就会走到这两个函数中去。我们在下一部分就会讨论到这个处理过程。另外，其实Redis在这里还会注册一个I/O事件，用于通过管道(pipe[6])机制与module进行双向通信。这个也不是本文的重点，我们暂时忽略它。 初始化后台线程。Redis会创建一些额外的线程，在后台运行，专门用于处理一些耗时的并且可以被延迟执行的任务（一般是一些清理工作）。在Redis里面这些后台线程被称为bio（background i/o server）。它们负责的任务包括：可以延迟执行的文件关闭操作（比如unlink命令的执行），AOF的持久化写库操作（即fsync调用，但注意只有可以被延迟执行的fsync操作才在后台线程执行），还有一些大key的清除操作（比如flushdb async命令的执行）。可见bio这个名字有点名不副实，它做的事情不一定跟I/O有关。对于这些后台线程，我们可能还会产生一个疑问：前面的初始化过程，已经注册了一个timer事件回调，即serverCron函数，按说后台线程执行的这些任务似乎也可以放在serverCron中去执行。因为serverCron函数也是可以用来执行后台任务的。实际上这样做是不行的。前面我们已经提到过，serverCron由事件循环来驱动，执行还是在Redis主线程上，相当于和主线程上执行的其它操作（主要是对于命令请求的执行）按时间进行分片了。这样的话，serverCron里面就不能执行过于耗时的操作，否则它就会影响Redis执行命令的响应时间。因此，对于耗时的、并且可以被延迟执行的任务，就只能放到单独的线程中去执行了。 启动事件循环。前面创建好了事件循环的结构，但还没有真正进入循环的逻辑。过了这一步，事件循环就运行起来，驱动前面注册的timer事件回调和I/O事件回调不断执行。 注意：Redis服务器初始化其实还有很多其它事情，比如加载数据到内存，Cluster集群的初始化，module的初始化，等等。但为了简化，上面讨论的初始化流程，只列出了我们当前关注的步骤。本文关注的是由事件驱动的整个运行机制以及跟命令执行直接相关的部分，因此我们暂时忽略掉其它不太相关的步骤。 现在，我们继续去讨论上面流程图中的第二个阶段：事件循环。 我们先想一下为什么这里需要一个循环。 一个程序启动后，如果没有循环，那么它从第一条指令执行到最后一条指令，然后就只能退出了。而Redis作为一个服务端程序，是要等客户端不停地发来请求然后做相应的处理，不能自己执行完就退出了。因此，Redis启动后必定要进入一个无限循环，显然，程序在每一次循环执行中，如果有事件（包括客户端请求的I/O事件）发生，就会去处理这些事件。如果没有事件发生呢？程序显然也不应该空转，而是应该等待，把整个循环阻塞住。这里的等待，就是上面流程图的【等待事件发生】这个步骤。那么，当整个循环被阻塞住之后，什么时候再恢复执行呢？自然是等待的事件发生的时候，程序被重新唤醒，循环继续下去。这里需要的等待和唤醒操作，是怎么实现呢？它们都需要依赖系统的能力才能做到。 实际上，这种事件循环机制，对于开发过手机客户端的同学来说，是非常常见且基础的机制。比如跑在iOS/Android上面的App，这些程序都有一个消息循环，负责等待各种UI事件（点击、滑动等）的发生，然后进行处理。同理，对应到服务端，这个循环的原理可以认为差不多，只是等待和处理的事件变成是I/O事件了。另外，除了I/O事件，整个系统在运行过程中肯定还需要根据时间来调度执行一些任务，比如延迟100毫秒再执行某个操作，或者周期性地每隔1秒执行某个任务，这就需要等待和处理另外一种事件——timer事件。 timer事件和I/O事件是两种截然不同的事件，如何由事件循环来统一调度呢？假设事件循环有空闲的时候去等待I/O事件的发生，那么有可能一个timer事件先发生了，这时事件循环就没有被及时唤醒（仍在等待I/O事件）；反之，如果事件循环在等待timer事件，而一个I/O事件先发生了，那么同样没能够及时唤醒。因此，我们必须有一种机制能够同时等待这两种事件的发生。而恰好，一些系统的API可以做到这一点（比如我们前面提到的epoll机制）。 前面流程图的第二阶段已经比较清楚地表达出了事件循环的执行流程。在这里我们对于其中一些步骤需要关注的地方做一些补充说明： 查找最近的timer事件。如前所序，事件循环需要等待timerI/O两种事件。对于I/O事件，只需要明确等待的是哪些文件描述符就可以了；而对于timer事件，还需要经过一番比较，明确在当前这一轮循环中需要等待多长时间。由于系统运行过程中可能注册多个timer事件回调，比如先要求在100毫秒后执行一个回调，同时又要求在200毫秒后执行另外一个回调，这就要求事件循环在它的每一轮执行之前，首先要找出最近需要执行的那次timer事件。这样事件循环在接下来等待中就知道该等待多长时间（在这个例子中，我们需要等待100毫秒）。 等待事件发生。这一步我们需要能够同时等待timer和I/O两种事件的发生。要做到这一点，我们依赖系统低层的I/O多路复用机制。这种机制一般是这样设计的：它允许我们针对多个文件描述符来等待对应的I/O事件发生，并同时可以指定一个最长的阻塞超时时间。如果在这段阻塞时间内，有I/O事件发生，那么程序会被唤醒继续执行；如果一直没有I/O事件发生，而是指定的时间先超时了，那么程序也会被唤醒。对于timer事件的等待，就是依赖这里的超时机制。当然，这里的超时时间也可以指定成无限长，这就相当于只等待I/O事件。我们再看一下上一步查找最近timer事件，查找完之后可能有三种结果，因此这一步等待也可能出现三种对应的情况： 第一种情况，查找到了一个最近的timer事件，它要求在未来某一个时刻触发。那么，这一步只需要把这个未来时刻转换成阻塞超时时间即可。 第二种情况，查找到了一个最近的timer事件，但它要求的时刻已经过去了。那么，这时候它应该立刻被触发，而不应该再有任何等待。当然，在实现的时候还是调用了事件等待的API，只是把超时事件设置成0就可以达到这个效果。 第三种情况，没有查找到任何注册的timer事件。那么，这时候应该把超时时间设置成无限长。接下来只有I/O事件发生才能唤醒。 判断有I/O事件发生还是超时。这里是程序从上一步（可能的）阻塞状态中恢复后执行逻辑。如果是I/O事件发生了，那么先指向I/O事件回调，然后根据需要把到期的timer事件的回调也执行掉（如果有的话）；如果是超时先发生了，那么表示只有timer事件需要触发（没有I/O事件发生），那么就直接把到期的timer事件的回调执行掉。 执行I/O事件回调。我们前面提到的对于TCP连接的监听和对于Unix domain socket的监听，这两种I/O事件的回调函数acceptTcpHandler和acceptUnixHandler，就是在这一步被调用的。 执行timer事件回调。我们前面提到的周期性回调函数serverCron，就是在这一步被调用的。一般情况下，一个timer事件被处理后，它就会被从队列中删除，不会再次执行了。但serverCron却是被周期性调用的，这是怎么回事呢？这是因为Redis对于timer事件回调的处理设计了一个小机制：timer事件的回调函数可以返回一个需要下次执行的毫秒数。如果返回值是正常的正值，那么Redis就不会把这个timer事件从事件循环的队列中删除，这样它后面还有机会再次执行。例如，按照默认的设置，serverCron返回值是100，因此它每隔100毫秒会执行一次（当然这个执行频率可以在redis.conf中通过hz变量来调整）。 至此，Redis整个事件循环的轮廓我们就清楚了。Redis主要的处理流程，包括接收请求、执行命令，以及周期性地执行后台任务（serverCron），都是由这个事件循环驱动的。当请求到来时，I/O事件被触发，事件循环被唤醒，根据请求执行命令并返回响应结果；同时，后台异步任务（如回收过期的key）被拆分成若干小段，由timer事件所触发，夹杂在I/O事件处理的间隙来周期性地运行。这种执行方式允许仅仅使用一个线程来处理大量的请求，并能提供快速的响应时间。当然，这种实现方式之所以能够高效运转，除了事件循环的结构之外，还得益于系统提供的异步的I/O多路复用机制(I/O multiplexing)。事件循环使得CPU资源被分时复用了，不同代码块之间并没有「真正的」并发执行，但I/O多路复用机制使得CPU和I/O的执行是真正并发的。而且，使用单线程还有额外的好处：避免了代码的并发执行，在访问各种数据结构的时候都无需考虑线程安全问题，从而大大降低了实现的复杂度。 Redis命令请求的处理流程概述我们在前面讨论[注册I/O事件回调]的时候提到过，Redis对于来自客户端的请求的处理，都会走到acceptTcpHandler和acceptUnixHandler这两个回调函数中去。实际上，这样的描述还过于粗略。 Redis客户端向服务器发送命令，可以细分为两个过程： 1.建立连接。客户端发起连接请求（通过TCP或Unix Domain Socket）,服务器接受连接。 2.命令发送、执行和响应。连接一旦建立好，客户端就可以在这个新连接的基础上发送命令数据，服务器收到后执行这个命令，并把执行结果返回给客户端。而且，在新连接上，这整个的[命令发送、执行和响应]的过程就可以反复执行。 上述第一个过程，「连接建立」，对应到服务端的代码，就是会走到acceptTcpHandler或acceptUnixHandler这两个回调函数中去。换句话说，Redis服务器每收到一个新的连接请求，就会由事件循环触发一个I/O事件，从而执行到acceptTcpHandler或acceptUnixHandler回调函数的代码。 接下来，从socket编程的角度，服务器应该调用accept系统API来接受连接请求，并为新的连接创建出一个socket。这个新的socket也就对应着一个新的文件描述符。为了在新的连接上能接收到客户端发来的命令，接下来必须在事件循环中为这个新的文件描述符注册一个I/O事件回调。这个过程的流程图如下： 图2：接收客户端连接请求 从上面流程图可以看出，新的连接注册了一个I/O事件回调，即readQueryFromClient。也就是说，对应前面讲的第二个过程，[命令发送、执行和响应]，当服务器收到命令数据的时候，也会由事件循环触发一个I/O事件，执行到readQueryFromClient回调。这个函数的实现就是在处理命令的[执行和响应]了。因此，下面我们看一下这个函数的执行流程图。 图3：readQueryFromClient函数执行流程图 从socket中读入数据，是按照流的方式。也就是说，站在应用层的角度，从底层网络层读入的数据，是由一个个字节组成的字节流。而我们需要从这些字节流中解析出完整的Redis命令，才能知道接下来如何处理。但由于网络传输的特点，我们并不能控制一次读入多少个字节。实际上，即使服务器只是收到一个Redis命令的部分数据（哪怕只有一个字节），也有可能触发一次I/O事件回调。这时我们是调用read系统API来读入数据的。虽然调用read时我们可以指定期望读取的字节数，但它并不会保证一定能返回期望长度的数据。比如我们想读100个字节，但可能只能读到80个字节，剩下的20个字节可能还在网络传输中没有到达。这种情况给接收Redis命令的过程造成了很大的麻烦：首先，可能我们读到的数据还不够一个完整的命令，这时我们应该继续等待更多的数据到达。其次，我们可能一次性收到了大量的数据，里面包含不止一个命令，这时我们必须把里面包含的所有命令都解析出来，而且要正确解析到最后一个完整命令的边界。如果最后一个完整命令后面还有多余的数据，那么这些数据应该留在下次有更多数据到达时再处理。这个复杂的过程一般称为「粘包」。 「粘包」处理的第一个表现，就是当尝试解析出一个完整的命令时，如果解析失败了，那么上面的流程就直接退出了。接下来，如果有更多数据到达，事件循环会再次触发I/O事件回调，重新进入上面的流程继续处理。 「粘包」处理的第二个表现，是上面流程图中的大循环。只要暂存输入数据的query buffer中还有数据可以处理，那么就不停地去尝试解析完整命令，直到把里面所有的完整命令都处理完，才退出循环。 查命令表那一步，就是查找本文前面提到的由populateCommandTable初始化的命令表，这个命令表存储在server.c的全局变量redisCommandTable当中。命令表中存有各个Redis命令的执行入口。 对于命令的执行结果，在上面的流程图中只是最后存到了一个输出buffer中，并没有真正输出给客户端。输出给客户端的过程不在这个流程当中，而是由另外一个同样是由事件循环驱动的过程来完成。这个过程涉及很多细节，我们在这里先略过，留在后面第四部分再来讨论。 事件机制介绍在本文第一部分，我们提到过，我们必须有一种机制能够同时等待I/O和timer这两种事件的发生。这一机制就是系统底层的I/O多路复用机制(I/O multiplexing)。但是，在不同的系统上，存在多种不同的I/O多路复用机制。因此，为了方便上层程序实现，Redis实现了一个简单的事件驱动程序库，即ae.c的代码，它屏蔽了系统底层在事件处理上的差异，并实现了我们前面一直在讨论的事件循环。 在Redis的事件库的实现中，目前它低层支持4种I/O多路复用机制： select系统调用，这应该是最早出现的一种I/O多路复用机制了，于1983年在4.2BSD Unix中被首次使用。它是POSIX规范的一部分。另外，跟select类似的还有一个poll系统调用，它是1986年在SVR3 Unix系统中首次使用的，也遵循POSIX规范。只要是遵循POSIX规范的操作系统，它就能支持select和poll机制，因此在目前我们常见的系统中这两种I/O事件机制一般都是支持的。 epoll机制。epoll是比select更新的一种I/O多路复用机制，最早出现在Linux内核的2.5.44版本中。它被设计出来是为了代替旧的select和poll，提供一种更高效的I/O机制。注意，epoll是Linux系统所特有的，它不属于POSIX规范。 kqueue机制。kqueue最早是2000年在FreeBSD 4.1上被设计出来的，后来也支持NetBSD、OpenBSD、DragonflyBSD和macOS系统。它和Linux系统上的epoll是类似的。 event ports。这是在illumos系统上特有的一种I/O事件机制。 既然在不同系统上有不同的事件机制，那么Redis在不同系统上编译时采用的是哪个机制呢？由于在上面四种机制中，后三种是更现代，也是比select和poll更高效的方案，因此Redis优先选择使用后三种机制。 通过上面对各种I/O机制所适用的操作系统的总结，我们很容易看出，如果你在macOS上编译Redis，那么它底层会选用kqueue；而如果在Linux上编译则会选择epoll，这也是Redis在实际运行中比较常见的情况。 现在我们回过头来再看一下底层的这些I/O事件机制是如何支持了Redis的事件循环的（下面的描述是对本文前面第一部分中事件循环流程的细化）： 首先，向事件循环中注册I/O事件回调的时候，需要指定哪个回调函数注册到哪个事件上（事件用文件描述符来表示）。事件和回调函数的对应关系，由Redis上层封装的事件驱动程序库来维护。具体参见函数aeCreateFileEvent的代码。 类似地，向事件循环中注册timer事件回调的时候，需要指定多长时间之后执行哪个回调函数。这里需要记录哪个回调函数预期在哪个时刻被调用，这也是由Redis上层封装的事件驱动程序库来维护的。具体参见函数aeCreateTimeEvent的代码。 底层的各种事件机制都会提供一个等待事件的操作，比如epoll提供的epoll_wait API。这个等待操作一般可以指定预期等待的事件列表（事件用文件描述符来表示），并同时可以指定一个超时时间（即最大等待多长时间）。在事件循环中需要等待事件发生的时候，就调用这个等待操作，传入之前注册过的所有I/O事件，并把最近的timer事件所对应的时刻转换成这里需要的超时时间。具体参见函数aeProcessEvents的代码。 从上一步的等待操作中唤醒，有两种情况：如果是I/O事件发生了，那么就根据触发的事件查到I/O回调函数，进行调用；如果是超时了，那么检查所有注册过的timer事件，对于预期调用时刻超过当前时间的回调函数都进行调用。 最后，关于事件机制，还有一些信息值得关注：业界已经有一些比较成熟的开源的事件库了，典型的比如libevent和libev。一般来说，这些开源库屏蔽了非常复杂的底层系统细节，并对不同的系统版本实现做了兼容，是非常有价值的。那为什么Redis的作者还是自己实现了一套呢？在Google Group的一个帖子上，Redis的作者给出了一些原因。帖子地址如下： https://groups.google.com/group/redis-db/browse_thread/thread/b52814e9ef15b8d0/ 原因大致总结起来就是： 不想引入太大的外部依赖。比如libevent太大了，比Redis的代码库还大。 方便做一些定制化的开发。 第三方库有时候会出现一些意想不到的bug。]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSRF攻击与防御]]></title>
    <url>%2F2019%2F04%2F02%2FCSRF%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E5%BE%A1%2F</url>
    <content type="text"><![CDATA[转载至 http://www.cnblogs.com/hyddd/archive/2009/04/09/1432744.html 一、CSRF是什么？CSRF（Cross-site request forgery），中文名称：跨站请求伪造，也被称为：one click attack/session riding，缩写为：CSRF/XSRF。 二、CSRF可以做什么？你这可以这么理解CSRF攻击：攻击者盗用了你的身份，以你的名义发送恶意请求。CSRF能够做的事情包括：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账……造成的问题包括：个人隐私泄露以及财产安全。 三、CSRF漏洞现状CSRF这种攻击方式在2000年已经被国外的安全人员提出，但在国内，直到06年才开始被关注，08年，国内外的多个大型社区和交互网站分别爆出CSRF漏洞，如：NYTimes.com（纽约时报）、Metafilter（一个大型的BLOG网站），YouTube和百度HI……而现在，互联网上的许多站点仍对此毫无防备，以至于安全业界称CSRF为“沉睡的巨人”。 四、CSRF的原理下图简单阐述了CSRF攻击的思想： 图1：CSRF攻击原理 从上图可以看出，要完成一次CSRF攻击，受害者必须依次完成两个步骤： 1.登录受信任网站A，并在本地生成Cookie。 2.在不登出A的情况下，访问危险网站B。 看到这里，你也许会说：“如果我不满足以上两个条件中的一个，我就不会受到CSRF的攻击”。是的，确实如此，但你不能保证以下情况不会发生： 1.你不能保证你登录了一个网站后，不再打开一个tab页面并访问另外的网站。 2.你不能保证你关闭浏览器了后，你本地的Cookie立刻过期，你上次的会话已经结束。（事实上，关闭浏览器不能结束一个会话，但大多数人都会错误的认为关闭浏览器就等于退出登录/结束会话了……） 3.上图中所谓的攻击网站，可能是一个存在其他漏洞的可信任的经常被人访问的网站。 上面大概地讲了一下CSRF攻击的思想，下面我将用几个例子详细说说具体的CSRF攻击，这里我以一个银行转账的操作作为例子（仅仅是例子，真实的银行网站没这么傻:&gt;） 示例1银行网站A，它以GET请求来完成银行转账的操作，如：http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000 危险网站B，它里面有一段HTML的代码如下：1&lt;img src=http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000&gt; 首先，你登录了银行网站A，然后访问危险网站B，噢，这时你会发现你的银行账户少了1000块…… 为什么会这样呢？原因是银行网站A违反了HTTP规范，使用GET请求更新资源。在访问危险网站B的之前，你已经登录了银行网站A，而B中的以GET的方式请求第三方资源（这里的第三方就是指银行网站了，原本这是一个合法的请求，但这里被不法分子利用了），所以你的浏览器会带上你的银行网站A的Cookie发出Get请求，去获取资源”http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000&quot;，结果银行网站服务器收到请求后，认为这是一个更新资源操作（转账操作），所以就立刻进行转账操作...... 示例2为了杜绝上面的问题，银行决定改用POST请求完成转账操作。 银行网站A的WEB表单如下： 12345&lt;form action="Transfer.php" method="POST"&gt; &lt;p&gt;ToBankId: &lt;input type="text" name="toBankId" /&gt;&lt;/p&gt; &lt;p&gt;Money: &lt;input type="text" name="money" /&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="submit" value="Transfer" /&gt;&lt;/p&gt;&lt;/form&gt; 后台处理页面Transfer.php如下： 1234567&lt;?php session_start(); if (isset($_REQUEST['toBankId'] &amp;&amp; isset($_REQUEST['money'])) &#123; buy_stocks($_REQUEST['toBankId'], $_REQUEST['money']); &#125;?&gt; 危险网站B，仍然只是包含那句HTML代码： 1&lt;img src=http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000&gt; 和示例1中的操作一样，你首先登录了银行网站A，然后访问危险网站B，结果…..和示例1一样，你再次没了1000块～T_T，这次事故的原因是：银行后台使用了$_REQUEST去获取请求的数据，而$_REQUEST既可以获取GET请求的数据，也可以获取POST请求的数据，这就造成了在后台处理程序无法区分这到底是GET请求的数据还是POST请求的数据。在PHP中，可以使用$_GET和$_POST分别获取GET请求和POST请求的数据。在JAVA中，用于获取请求数据request一样存在不能区分GET请求数据和POST数据的问题。 示例3： 经过前面2个惨痛的教训，银行决定把获取请求数据的方法也改了，改用$_POST，只获取POST请求的数据，后台处理页面Transfer.php代码如下： 1234567&lt;?php session_start(); if (isset($_POST['toBankId'] &amp;&amp; isset($_POST['money'])) &#123; buy_stocks($_POST['toBankId'], $_POST['money']); &#125;?&gt; 然而，危险网站B与时俱进，它改了一下代码： 1234567891011121314151617181920&lt;html&gt; &lt;head&gt; &lt;script type="text/javascript"&gt; function steal() &#123; iframe = document.frames["steal"]; iframe.document.Submit("transfer"); &#125; &lt;/script&gt; &lt;/head&gt; &lt;body onload="steal()"&gt; &lt;iframe name="steal" display="none"&gt; &lt;form method="POST" name="transfer" action="http://www.myBank.com/Transfer.php"&gt; &lt;input type="hidden" name="toBankId" value="11"&gt; &lt;input type="hidden" name="money" value="1000"&gt; &lt;/form&gt; &lt;/iframe&gt; &lt;/body&gt;&lt;/html&gt; 如果用户仍是继续上面的操作，很不幸，结果将会是再次不见1000块……因为这里危险网站B暗地里发送了POST请求到银行! 总结一下上面3个例子，CSRF主要的攻击模式基本上是以上的3种，其中以第1,2种最为严重，因为触发条件很简单，一个就可以了，而第3种比较麻烦，需要使用JavaScript，所以使用的机会会比前面的少很多，但无论是哪种情况，只要触发了CSRF攻击，后果都有可能很严重。 理解上面的3种攻击模式，其实可以看出，CSRF攻击是源于WEB的隐式身份验证机制！WEB的身份验证机制虽然可以保证一个请求是来自于某个用户的浏览器，但却无法保证该请求是用户批准发送的！ 五.CSRF的防御我总结了一下看到的资料，CSRF的防御可以从服务端和客户端两方面着手，防御效果是从服务端着手效果比较好，现在一般的CSRF防御也都在服务端进行。 1.服务器端进行CSRF防御服务端的CSRF方式方法很多样，但总的思想都是一致的，就是在客户端页面增加伪随机数。 1).Cookie Hashing(所有表单都包含同一个伪随机值)：这可能是最简单的解决方案了，因为攻击者不能获得第三方的Cookie(理论上)，所以表单中的数据也就构造失败了:&gt; 12345&lt;?php //构造加密的Cookie信息 $value = “DefenseSCRF”; setcookie(”cookie”, $value, time()+3600);?&gt; 在表单里增加Hash值，以认证这确实是用户发送的请求。 123456789&lt;?php $hash = md5($_COOKIE['cookie']);?&gt; &lt;form method=”POST” action=”transfer.php”&gt; &lt;input type=”text” name=”toBankId”&gt; &lt;input type=”text” name=”money”&gt; &lt;input type=”hidden” name=”hash” value=”&lt;?=$hash;?&gt;”&gt; &lt;input type=”submit” name=”submit” value=”Submit”&gt; &lt;/form&gt; 然后再服务器端进行Hash值验证 12345678910111213&lt;?php if(isset($_POST['check'])) &#123; $hash = md5($_COOKIE['cookie']); if($_POST['check'] == $hash) &#123; doJob(); &#125; else &#123; //... &#125; else &#123; //... &#125;?&gt; 这个方法个人觉得已经可以杜绝99%的CSRF攻击了，那还有1%呢….由于用户的Cookie很容易由于网站的XSS漏洞而被盗取，这就另外的1%。一般的攻击者看到有需要算Hash值，基本都会放弃了，某些除外，所以如果需要100%的杜绝，这个不是最好的方法。 2).验证码这个方案的思路是：每次的用户提交都需要用户在表单中填写一个图片上的随机字符串，厄….这个方案可以完全解决CSRF，但个人觉得在易用性方面似乎不是太好，还有听闻是验证码图片的使用涉及了一个被称为MHTML的Bug，可能在某些版本的微软IE中受影响。 3).One-Time Tokens(不同的表单包含一个不同的伪随机值)在实现One-Time Tokens时，需要注意一点：就是“并行会话的兼容”。如果用户在一个站点上同时打开了两个不同的表单，CSRF保护措施不应该影响到他对任何表单的提交。考虑一下如果每次表单被装入时站点生成一个伪随机值来覆盖以前的伪随机值将会发生什么情况：用户只能成功地提交他最后打开的表单，因为所有其他的表单都含有非法的伪随机值。必须小心操作以确保CSRF保护措施不会影响选项卡式的浏览或者利用多个浏览器窗口浏览一个站点。 4)slim框架CSRF实现slim框架的csrf预防源码]]></content>
      <tags>
        <tag>web安全</tag>
        <tag>CSRF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[源码文件]]></title>
    <url>%2F2019%2F03%2F29%2F%E6%BA%90%E7%A0%81%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[go文件主要分为下面3类: 图1：go文件]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作区和GOPATH]]></title>
    <url>%2F2019%2F03%2F29%2F%E5%B7%A5%E4%BD%9C%E5%8C%BA%E5%92%8CGOPATH%2F</url>
    <content type="text"><![CDATA[我们学习Go语言时，第一件要做的是，就是根据自己电脑的操作系统和计算架构，从Go语言官网下载对应的二进制包，也就是拿来即用的安装包。 随后，解压安装包、放置到某个目录、配置环境变量，并在命令行输入 go version 来验证是否安装成功。 1234567891011121314151617# 解压[root@www package]# ls go1.12.1.linux-amd64.tar.gz go1.12.1.linux-amd64.tar.gz[root@www package]# tar zxvf go1.12.1.linux-amd64.tar.gz -C /usr/local/# 设置GOROOT、GOPATH、GOBIN环境变量[root@www ~]# vim .bash_profilePATH=$PATH:$HOME/bin:/usr/local/php/bin:/usr/local/go/binexport PATHexport GOROOT=/usr/local/goexport GOPATH=/root/peek-a-bowexport GOBIN=/root/peek-a-bow/bin# 创建工作目录mkdir -p /root/peek-a-bow/&#123;src,bin,pkg&#125; 在整个安装过程中，需要配置3个环境变量，简单介绍一下: GOROOT: Go语言的安装目录 GOPATH: 自定义的工作目录 GOBIN: Go语言生成的可执行文件的目录 可以把GOPATH简单理解成Go语言的工作目录，它的值是一个目录的路径，也可以是多个目录的路径，每个目录都代表Go语言的一个工作区（workspace）。 我们需要利于这些工作区，去放置 Go 语言的源码文件（source file）,以及安装(install)后的归档文件（archive file）和可执行文件（executable file）。 事实上，由于Go语言项目在其生命周期内的所有操作（编码依赖管理、构建、测试、安装等）基本上都是围绕着GOPATH和工作区进行的。它的背后有3个知识点需要注意: 1.Go语言源码的组织是怎样的； 2.你是否了解源码安装后的结果； 3.你是否理解构建和安装Go程序的过程。 1.Go语言源码组织方式Go语言是以代码包为基本组织单位的。所以说，Go语言源码的组织方式就是以环境变量GOPATH、工作区、src目录和代码包为主线的。 2.了解源码安装后的结果源码文件在安装过程中，如果产生了归档文件，就会放进该工作区的pkg子目录；如果产生了可执行文件，就会放进该工作区的bin子目录。 3.理解构建和安装Go程序的过程构建使用 go build,安装使用命令 go install。构建和安装代码包的时候都会执行编译、打包等操作。并且，这些操作产生的任何文件都会先被保存到某个临时的目录中。 如果构建的是库源码文件,那么操作结果只会保存在临时目录中，安装库源码文件，那么它的结果会被搬运到它所在工作区的pkg目录下的某个子目录中。 如果构建的是命令源码文件，那么它的操作结果文件会被搬运到源码文件所在的目录中。如果安装的是命令源码文件，那么结果文件会被搬运到它所在工作区的bin目录中，或者环境变量GOBIN指向的目录中。]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go string 实现原理剖析]]></title>
    <url>%2F2019%2F03%2F28%2FGo-string-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[倒排索引原理]]></title>
    <url>%2F2019%2F03%2F27%2F%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[关于ElasticSearch为什么搜索这么快，大家应该有所了解，主要是利用倒排索引数据结构，下面简单介绍一下倒排索引。 正向索引任何事物都是相对的，有倒排索引(inverted index)，当然也会有正向索引(forward index)。 正向索引结构在搜索引擎中，每个文件(document)对应一个文件id(document id)，文件内容可以看作是一些列关键词的集合(实际上，在搜索引擎库中，关键词也转化为关键词id)。例如“文档1”经过分词，提取了20个关键词，每个关键词都会记录它在文档中的出现次数和出现位置。 得到正向索引结构如下： “文档1”的ID &gt; 关键词1：出现次数，出现位置列表；关键词2：出现次数，出现位置列表；…… 图1：正向索引结构 通过文档，去找关键词。 正向索引查找过程当用户在主页上搜索关键词“华为手机”时，假设只存在正向索引(forward index)，那么就需要扫描索引库中的所有文档，找出所有包含关键词“华为手机”的文档，再根据打分模型进行打分，排出名次后呈现给用户。因为互联网上收录在搜索引擎中的文档的数目是个天文数字，这样的索引结构根本无法满足实时返回排名结果的要求。 倒排索引倒排索引结构由于正向索引无法满足实时返回排名结果的要求，所以，搜索引擎会将正向索引重新构建为倒排索引，即把文件id对应到关键词的映射转化为关键词到文件id的映射，每个关键词对应着一些列文件，这些文件中都出现这个关键词。 得到倒排索引的结构如下： “关键词1” ：“文档1”的id ， “文档2”的id ，……。 图2：倒排索引结构 通过关键词，去找文档。 单词-文档矩阵单词-文档矩阵是表达两者之间所具有的一种包含关系的概念模型。 图3：单词-文档矩阵 从纵向看（即从文档这个维度看），每列代表文档包含了哪些单词，比如文档1包含了词汇1和词汇4，而不包含其它单词。 从横向看（即从单词这个维度看），每行代表了哪些文档包含了这个单词。比如词汇1来说，文档1和文档4中出现过单词1，而其它文档不包含词汇1。 搜索引擎，其实就是实现了 “单词-文档矩阵”的具体数据结构，可以有不同的方式来实现上述概念模型，比如“倒排索引”、“签名文件”、“后缀树”等方式。目前ElasticSearch中是使用“倒排索引”实现单词到文档映射关系。 倒排索引基本概念文档(document):一般搜索引擎的处理对象是互联网网页，而文档这个概念要更宽泛些，代表以文本形式存在的存储对象，相比网页来说，涵盖更多种形式，比如Word，PDF，html，XML等不同格式的文件都可以称之为文档。再比如一封邮件，一条短信，一条微博也可以称之为文档。在本书后续内容，很多情况下会使用文档来表征文本信息。 文档集合(Document Collection)：由若干文档构成的集合称之为文档集合。比如海量的互联网网页或者说大量的电子邮件都是文档集合的具体例子。 文档编号(Document ID):在搜索引擎内部，会将文档集合内每个文档赋予一个唯一的内部编号，以此编号来作为这个文档的唯一标识，这样方便内部处理，每个文档的内部编号即称之为“文档编号”，后文有时会用DocID来便捷地代表文档编号。 单词编号(Word ID):与文档编号类似，搜索引擎内部以唯一的编号来表征某个单词，单词编号可以作为某个单词的唯一表征。 倒排索引(Inverted Index):倒排索引是实现“单词-文档矩阵”的一种具体存储形式，通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。倒排索引主要由两个部分组成：“单词词典”和“倒排文件”。 单词字典(Lexicon)：搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。 倒排列表(PostingList)：倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息，每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。 倒排文件(Inverted File)：所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引的物理文件。 关于这些概念之间的关系，通过图4可以比较清晰的看出来。 图4：倒排列表模型 倒排索引简单实例倒排索引从逻辑结构和基本思路上来讲非常简单。下面我们通过具体实例来进行说明，使得读者能够对倒排索引有一个宏观而直接的感受。 假设文档集合包含五个文档，每个文档内容如图3所示，在图中最左端一栏是每个文档对应的文档编号。我们的任务就是对这个文档集合建立倒排索引。 图5：文档集合 中文和英文等语言不同，单词之间没有明确分隔符号，所以首先要用分词系统将文档自动切分成单词序列。这样每个文档就转换为由单词序列构成的数据流，为了系统后续处理方便，需要对每个不同的单词赋予唯一的单词编号，同时记录下哪些文档包含这个单词，在如此处理结束后，我们可以得到最简单的倒排索引（参考图6）。在图6中，“单词ID”一栏记录了每个单词的单词编号，第二栏是对应的单词，第三栏即每个单词对应的倒排列表。比如单词“谷歌”，其单词编号为1，倒排列表为{1,2,3,4,5}，说明文档集合中每个文档都包含了这个单词。 图6：最简单的倒排索引 之所以说图6所示倒排索引是最简单的，是因为这个索引系统只记载了哪些文档包含某个单词，而事实上，索引系统还可以记录除此之外的更多信息。图7是一个相对复杂些的倒排索引，与图6的基本索引系统比，在单词对应的倒排列表中不仅记录了文档编号，还记载了单词频率信息（TF），即这个单词在某个文档中的出现次数，之所以要记录这个信息，是因为词频信息在搜索结果排序时，计算查询和文档相似度是很重要的一个计算因子，所以将其记录在倒排列表中，以方便后续排序时进行分值计算。在图7的例子里，单词“创始人”的单词编号为7，对应的倒排列表内容为：（3:1），其中的3代表文档编号为3的文档包含这个单词，数字1代表词频信息，即这个单词在3号文档中只出现过1次，其它单词对应的倒排列表所代表含义与此相同。 图7：带有单词频率信息的倒排索引 实用的倒排索引还可以记载更多的信息，图8所示索引系统除了记录文档编号和单词频率信息外，额外记载了两类信息，即每个单词对应的“文档频率信息”（对应图8的第三栏）以及在倒排列表中记录单词在某个文档出现的位置信息。 “文档频率信息”代表了在文档集合中有多少个文档包含某个单词，之所以要记录这个信息，其原因与单词频率信息一样，这个信息在搜索结果排序计算中是非常重要的一个因子。而单词在某个文档中出现的位置信息并非索引系统一定要记录的，在实际的索引系统里可以包含，也可以选择不包含这个信息，之所以如此，因为这个信息对于搜索系统来说并非必需的，位置信息只有在支持“短语查询”的时候才能够派上用场。 以单词“拉斯”为例，其单词编号为8，文档频率为2，代表整个文档集合中有两个文档包含这个单词，对应的倒排列表为：{(3;1;)，(5;1;)},其含义为在文档3和文档5出现过这个单词，单词频率都为1，单词“拉斯”在两个文档中的出现位置都是4，即文档中第四个单词是“拉斯”。 图7所示倒排索引已经是一个非常完备的索引系统，实际搜索系统的索引结构基本如此，区别无非是采取哪些具体的数据结构来实现上述逻辑结构。 有了这个索引系统，搜索引擎可以很方便地响应用户的查询，比如用户输入查询词“Facebook”，搜索系统查找倒排索引，从中可以读出包含这个单词的文档，这些文档就是提供给用户的搜索结果，而利用单词频率信息、文档频率信息即可以对这些候选搜索结果进行排序，计算文档和查询的相似性，按照相似性得分由高到低排序输出，此即为搜索系统的部分内部流程。 单词词典单词词典是倒排索引中非常重要的组成部分，它用来维护文档集合中出现过的所有单词的相关信息，同时用来记载某个单词对应的倒排列表在倒排文件中的位置信息。在支持搜索时，根据用户的查询词，去单词词典里查询，就能够获得相应的倒排列表，并以此作为后续排序的基础。 对于一个规模很大的文档集合来说，可能包含几十万甚至上百万的不同单词，能否快速定位某个单词，这直接影响搜索时的响应速度，所以需要高效的数据结构来对单词词典进行构建和查找，常用的数据结构包括哈希加链表结构和树形词典结构。 哈希加链表图8是这种词典结构的示意图。这种词典结构主要由两个部分构成： 主体部分是哈希表，每个哈希表项保存一个指针，指针指向冲突链表，在冲突链表里，相同哈希值的单词形成链表结构。之所以会有冲突链表，是因为两个不同单词获得相同的哈希值，如果是这样，在哈希方法里被称做是一次冲突，可以将相同哈希值的单词存储在链表里，以供后续查找。 图8：哈希加链表结构 在建立索引的过程中，词典结构也会相应地被构建出来。比如在解析一个新文档的时候，对于某个在文档中出现的单词T，首先利用哈希函数获得其哈希值，之后根据哈希值对应的哈希表项读取其中保存的指针，就找到了对应的冲突链表。如果冲突链表里已经存在这个单词，说明单词在之前解析的文档里已经出现过。如果在冲突链表里没有发现这个单词，说明该单词是首次碰到，则将其加入冲突链表里。通过这种方式，当文档集合内所有文档解析完毕时，相应的词典结构也就建立起来了。 在响应用户查询请求时，其过程与建立词典类似，不同点在于即使词典里没出现过某个单词，也不会添加到词典内。以图8为例，假设用户输入的查询请求为单词3，对这个单词进行哈希，定位到哈希表内的2号槽，从其保留的指针可以获得冲突链表，依次将单词3和冲突链表内的单词比较，发现单词3在冲突链表内，于是找到这个单词，之后可以读出这个单词对应的倒排列表来进行后续的工作，如果没有找到这个单词，说明文档集合内没有任何文档包含单词，则搜索结果为空。 树形结构 B树（或者B+树）是另外一种高效查找结构。B树与哈希方式查找不同，需要字典项能够按照大小排序（数字或者字符序），而哈希方式则无须数据满足此项要求。 B树形成了层级查找结构，中间节点用于指出一定顺序范围的词典项目存储在哪个子树中，起到根据词典项比较大小进行导航的作用，最底层的叶子节点存储单词的地址信息，根据这个地址就可以提取出单词字符串。 总结图9：文档集合 图10：倒排索引结构 单词ID：记录每个单词的单词编号； 单词：对应的单词； 文档频率：代表文档集合中有多少个文档包含某个单词 倒排列表：包含单词ID及其他必要信息 DocId：单词出现的文档id TF：单词在某个文档中出现的次数 POS：单词在文档中出现的位置 以单词“加盟”为例，其单词编号为6，文档频率为3，代表整个文档集合中有三个文档包含这个单词，对应的倒排列表为{(2;1;),(3;1;),(5;1;)}，含义是在文档2，3，5出现过这个单词，在每个文档的出现过1次，单词“加盟”在第一个文档的POS是4，即文档的第四个单词是“加盟”，其他的类似。 这个倒排索引已经是一个非常完备的索引系统，实际搜索系统的索引结构基本如此。]]></content>
      <tags>
        <tag>倒排索引</tag>
      </tags>
  </entry>
</search>
